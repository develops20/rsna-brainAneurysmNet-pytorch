{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"},{"sourceId":13227044,"sourceType":"datasetVersion","datasetId":8238970},{"sourceId":13227074,"sourceType":"datasetVersion","datasetId":8238986},{"sourceId":13227099,"sourceType":"datasetVersion","datasetId":8239003},{"sourceId":13549222,"sourceType":"datasetVersion","datasetId":8605156},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656,"modelId":312},{"sourceId":3730,"sourceType":"modelInstanceVersion","modelInstanceId":2657,"modelId":312},{"sourceId":3732,"sourceType":"modelInstanceVersion","modelInstanceId":2659,"modelId":312},{"sourceId":599416,"sourceType":"modelInstanceVersion","modelInstanceId":449026,"modelId":465429}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# CELL 1: IMPORTS & CONFIG\n# ====================================================\nimport os\n# Mitigate CUDA memory fragmentation (must be set before torch import)\nos.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\nimport shutil\nimport math\nimport time\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport timm\nimport cv2\nimport pydicom\nimport nibabel as nib\nfrom scipy import ndimage\nfrom scipy.ndimage import label, center_of_mass\nfrom PIL import Image\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\nfrom sklearn.metrics import roc_auc_score\nimport kaggle_evaluation.rsna_inference_server\nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\n\n\n# Thread limits for Kaggle (idempotent & safe)\ntry:\n    import cv2 as _cv2_for_threads\n    try:\n        _cv2_for_threads.setNumThreads(2)\n    except Exception:\n        pass\nexcept Exception:\n    pass\ntry:\n    os.environ.setdefault('OMP_NUM_THREADS', '1')\n    os.environ.setdefault('MKL_NUM_THREADS', '1')\n    torch.set_num_threads(1)\nexcept Exception:\n    pass\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:35:34.037286Z","iopub.execute_input":"2025-11-04T19:35:34.037607Z","iopub.status.idle":"2025-11-04T19:36:19.204984Z","shell.execute_reply.started":"2025-11-04T19:35:34.037576Z","shell.execute_reply":"2025-11-04T19:36:19.204380Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Competition Configuration\nclass Config:\n    # Paths\n    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n    \n    # Stage 2 Configuration\n    ROI_SIZE = (224, 224)\n    ROIS_PER_SERIES = 5\n    BATCH_SIZE = 16  # Smaller batch = more gradient updates per epoch (434 vs 217 steps)\n    VAL_BATCH_SIZE = 8  # Match training batch size\n    GRAD_ACCUM_STEPS = 3  # Effective batch size: 8 √ó 6 = 48 (maintain throughput)\n    VAL_MAX_ENCODER_TOKENS = 384\n    EPOCHS = 10  # QUICK TEST: Verify predictions are varying before full run\n    LEARNING_RATE = 2e-4  # EVEN HIGHER: Strong signal to break uniform predictions\n    N_FOLDS = 5  # SINGLE FOLD TEST: Fast verification (~40 min)\n    \n    # Competition constants\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n    \n    # Device and training\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    MIXED_PRECISION = True\n    MICRO_BATCH_SIZE = 8  # MATCH batch size\n    AUTO_TUNE_MICRO = False  # DISABLED: Can cause hanging with DataLoader workers\n    SLICE_SUBSAMPLE_TRAIN = 0  # DISABLED: Model expects fixed 32 slices (24 causes shape mismatch)\n    STAGE2_CACHE_DIR = '/kaggle/working/stage2_cache'\n    DEBUG_MODE = False\n    DEBUG_SAMPLES = 0\n    REUSE_EXISTING_ROIS = True  # if cached training_df exists, reuse to skip long ROI extraction\n    DIRECT_VOLUME_MODE = True   # Direct volume mode (top_example-style) using Stage 0 32x384x384 volumes\n    # STAGE0_PREBUILT_ROOT = '/kaggle/input/rsna2025-v2-intracranial-aneurysm-detection-nb153/stage1_AneurysmNet_prebuilt_v2'\n    NUM_WORKERS = None  # Lower workers to reduce CPU RAM and contention\n    PREFETCH_FACTOR = 2  # Smaller prefetch to avoid large in-flight batches\n    PIN_MEMORY = False  # Disable pinning to reduce host memory usage\n    PERSISTENT_WORKERS = False\n    CACHE_VOLUMES = True\n    USE_SHARD_LOADER = False  # DISABLED: Load .npz shards directly, not via shard_loader.py wrapper\n    CACHE_DIR = ''  # disable single-dir cache\n    CACHE_DIRS = [\n        '/kaggle/input/rsna2025-shard0-fp16nb153/stage2_cache_vols',\n        '/kaggle/input/rsna2025-shard1-fp16nb153/stage2_cache_vols',\n        '/kaggle/input/rsna2025-shard2-fp16nb153/stage2_cache_vols',\n    ]\n    CACHE_DTYPE = 'float16'  # use higher-fidelity cache\n    CACHE_VERBOSE = False  # set True to log cache hits/writes/skips\n    CACHE_LOG_EVERY_N = 100\n\n    # Coarse-to-fine ROI (vesselness-based) - approximates nnU-Net ROI focusing\n    USE_VESSELNESS_ROI = True\n    ROI_MODE = 'mask'              # 'mask' or 'crop'\n    ROI_TARGET_SIZE = (384, 384)   # used when ROI_MODE='crop'\n    ROI_BOX = (256, 256)           # (h, w) crop box when cropping\n    ROI_PAD = 32                   # padding around crop center\n    VESSEL_THR = 0.15              # threshold for vessel mask when \n\n    # Coarse-to-fine ROI (nnUNet-inspired, offline approximation)\n    # Per-mode toggles\n    CTF_ENABLE_TRAIN = True\n    CTF_ENABLE_VAL = True\n    CTF_ENABLE = True\n    CTF_COARSE_DOWNSCALE = 2            # compute coarse vesselness at 384/CTF_COARSE_DOWNSCALE\n    CTF_COARSE_THR = 0.25               # threshold on coarse vesselness\n    CTF_DBSCAN_EPS = 3.0                # pixels (after downscale)\n    CTF_DBSCAN_MIN_SAMPLES = 20\n    CTF_COARSE_BOX_PX = 192             # initial crop box (square) in pixels at full-res\n    CTF_FINE_THR_BAL = 0.35             # balanced threshold\n    CTF_FINE_THR_RECALL = 0.20          # recall-focused threshold\n    CTF_FINE_MORPH_K = 3                # morph kernel size\n    CTF_FINE_MARGIN = 24                # margin (pixels) around tight bbox\n    CTF_FINE_DOWNSCALE = 2              # compute fine vesselness at 384/CTF_FINE_DOWNSCALE       \n    CTF_OUTPUT_SIZE = (384, 384)        # final (H,W) for cropped ROI/mask    \n    \n    # Shard loading configuration\n    SHARD_CHANNEL_MODE = 'cta'  # 'cta' for rsna2p5d, 'best3' for mil2p5d\n    SHARD_DEPTH_SAMPLING = 'uniform'  # 'uniform', 'center_weighted', 'interpolate'\n    SHARD_TARGET_SPATIAL = (384, 384)  # Will be overridden to (320, 320) for mil2p5d\n    MODEL_DIRS = [ \n        '/kaggle/working',  # Where models are saved during training        \n        #'/kaggle/input/rsna2025-stage2-5fold-32ch-f16/pytorch/default/3'\n    ]\n    # Control training in local/dev mode\n    TRAIN_ON_START = True\n    # Early stopping\n    EARLY_STOPPING_PATIENCE = 3\n\n    # Validation schedule (fast vs full)\n    FAST_VAL = True\n    FAST_VAL_EVERY = 1\n    FULL_VAL_EVERY = 3\n    RUN_FULL_ON_EPOCH_1 = False\n    FAST_VAL_SUBSET_FRAC = 0.33\n    FAST_VAL_MAX_TOKENS = 256\n    FAST_VAL_IMPROVE_EPS = 0.002\n\n    # Intensity normalization (approximate nnU-Net per-volume z-score when selected)\n    INTENSITY_NORM_MODE = 'ct_window'  # 'ct_window' (current default) or 'zscore'\n    ZSCORE_CLIP_SIGMA = 5.0\n\n    # Optional NIfTI export (disabled by default)\n    EXPORT_NIFTI = False\n    NIFTI_DIR = '/kaggle/working/nifti'\n\n    # Inference TTA controls\n    INF_TTA_HFLIP = False  # disable L/R mirroring to preserve asymmetry\n\n    # Architecture selection: 'rsna2p5d' or 'mil2p5d' or 'simple2d'\n    MODEL_ARCH = 'simple2d'  # SESSION 1: RSNA2P5D Training\n\n    # MIL transformer params - OPTIMIZED FOR SPEED\n    # Competition-winning approach: Balance speed vs quality\n    MIL_BACKBONE = 'tf_efficientnet_b0'  # B0 is 3-4x faster than B3, minimal quality loss\n    MIL_SPATIAL_SIZE = 224  # Reduced from 320 to 224 (2x faster, medical models tolerate this)\n    MIL_D_MODEL = 512  # Reduced from 768 (faster attention, still competitive)\n    MIL_NHEAD = 8\n    MIL_N_LAYERS = 2  # Keep at 2 for balance\n    MIL_USE_GRAD_CHECKPOINT = False  # Saves VRAM, allows larger batches\n    MIL_COMPILE_ENCODER = False  # Set True if PyTorch >= 2.0 available\n\n    # Training extras\n    USE_WEIGHTED_SAMPLER = False\n    USE_EMA = False \n    EMA_DECAY = 0.999\n\n    # Hierarchical consistency loss (sites <= \"Aneurysm Present\")\n    ENABLE_HIER_LOSS = False\n    HIER_LOSS_LAMBDA = 0.2\n\n    # Asymmetric Loss (ASL) for site logits\n    USE_ASL = False\n    ASL_GAMMA_POS = 0.0\n    ASL_GAMMA_NEG = 4.0\n    ASL_CLIP = 0.05\n    ASL_WEIGHT_SITES = 1.0\n    MAIN_BCE_WEIGHT = 1.0\n    \n    # Class weight cap (prevent extreme weights like 93.5)\n    CLASS_WEIGHT_CAP = 20.0  # ENABLED: Allow class weights for imbalanced data (capped at 30)\n    # This lets pos_weight reflect true imbalance (rare sites + 13√ó \"Aneurysm Present\")\n\nprint(f\"‚úÖ Configuration loaded - Device: {Config.DEVICE}\")\n\n# Speed-friendly backend settings\ntry:\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.set_float32_matmul_precision('high')\nexcept Exception:\n    pass\n\n\ndef _vesselness_2d(img: np.ndarray) -> np.ndarray:\n    # img in [0,1]\n    scales = [1.0, 2.0]\n    beta = 0.5\n    cval = 15.0\n    eps = 1e-6\n    H, W = img.shape\n    v_max = np.zeros((H, W), dtype=np.float32)\n    for s in scales:\n        ksize = int(max(3, round(s * 3) * 2 + 1))\n        g = cv2.GaussianBlur(img, (ksize, ksize), s)\n        Ixx = cv2.Sobel(g, cv2.CV_32F, 2, 0, ksize=3)\n        Iyy = cv2.Sobel(g, cv2.CV_32F, 0, 2, ksize=3)\n        Ixy = cv2.Sobel(g, cv2.CV_32F, 1, 1, ksize=3)\n        tr = Ixx + Iyy\n        det = Ixx * Iyy - Ixy * Ixy\n        disc = np.maximum(tr * tr - 4.0 * det, 0.0)\n        root = np.sqrt(disc)\n        lam1 = 0.5 * (tr - root)\n        lam2 = 0.5 * (tr + root)\n        swap = (np.abs(lam1) > np.abs(lam2))\n        l1 = lam1.copy(); l2 = lam2.copy()\n        l1[swap] = lam2[swap]; l2[swap] = lam1[swap]\n        cond = (l2 < 0)\n        Rb = np.zeros_like(l1)\n        Rb[cond] = (np.abs(l1[cond]) / (np.abs(l2[cond]) + eps))\n        S = np.sqrt(l1 * l1 + l2 * l2)\n        V = np.zeros_like(l1, dtype=np.float32)\n        V[cond] = np.exp(-(Rb[cond] ** 2) / (2.0 * beta * beta)) * (1.0 - np.exp(-(S[cond] ** 2) / (2.0 * cval * cval)))\n        v_max = np.maximum(v_max, V.astype(np.float32))\n    vmax = float(v_max.max())\n    if vmax > eps:\n        v_max = v_max / vmax\n    return v_max.astype(np.float32)\n\ndef _coarse_vesselness_roi(vol32: np.ndarray):\n    # vol32: (D,H,W)\n    D, H, W = vol32.shape\n    vstack = []\n    for z in range(D):\n        v = _vesselness_2d(vol32[z].astype(np.float32))\n        vstack.append(v)\n    v3d = np.stack(vstack, axis=0)\n    vproj = v3d.mean(axis=0)\n    yx = np.unravel_index(np.argmax(vproj), vproj.shape)\n    return v3d, (int(yx[0]), int(yx[1]))\n\ndef apply_vesselness_roi(vol32: np.ndarray) -> np.ndarray:\n    # vol32: (D,H,W) [0,1]\n    v3d, (cy, cx) = _coarse_vesselness_roi(vol32)\n    mode = getattr(Config, 'ROI_MODE', 'mask')\n    if mode == 'mask':\n        m = (v3d.mean(axis=0) >= float(getattr(Config, 'VESSEL_THR', 0.15))).astype(np.float32)\n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n        m = cv2.dilate(m, kernel, iterations=2)\n        m = np.clip(m, 0, 1)\n        if float(m.mean()) < 0.01:\n            return vol32\n        return vol32 * m[None]\n    else:\n        bh, bw = getattr(Config, 'ROI_BOX', (256,256))\n        pad = int(getattr(Config, 'ROI_PAD', 32))\n        y1 = max(0, cy - bh//2 - pad); y2 = min(vol32.shape[1], cy + bh//2 + pad)\n        x1 = max(0, cx - bw//2 - pad); x2 = min(vol32.shape[2], cx + bw//2 + pad)\n        crop = vol32[:, y1:y2, x1:x2]\n        th, tw = getattr(Config, 'ROI_TARGET_SIZE', (384,384))\n        out = np.empty((vol32.shape[0], th, tw), dtype=np.float32)\n        for z in range(vol32.shape[0]):\n            out[z] = cv2.resize(crop[z].astype(np.float32), (tw, th))\n        return out\n\ndef apply_coarse_to_fine_roi(vol32: np.ndarray) -> tuple:\n    \"\"\"nnUNet-inspired coarse-to-fine ROI using vesselness and simple clustering.\n    Returns (roi_vol32, fine_mask32) where fine_mask32 is a [0,1] mask with vessel emphasis.\n    \"\"\"\n    D, H, W = vol32.shape\n    # Coarse: downscale for speed\n    ds = max(1, int(getattr(Config, 'CTF_COARSE_DOWNSCALE', 2)))\n    h2, w2 = H // ds, W // ds\n    v_coarse = np.empty((D, h2, w2), dtype=np.float32)\n    for z in range(D):\n        v_coarse[z] = cv2.resize(vol32[z].astype(np.float32), (w2, h2))\n    # Vesselness on downscaled and aggregate\n    vstack = [ _vesselness_2d(v_coarse[z]) for z in range(D) ]\n    v3d_c = np.stack(vstack, axis=0)\n    vproj = v3d_c.mean(axis=0)\n    # Threshold & cluster (DBSCAN-like via connected components)\n    thr = float(getattr(Config, 'CTF_COARSE_THR', 0.25))\n    bin2 = (vproj >= thr).astype(np.uint8)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n    bin2 = cv2.morphologyEx(bin2, cv2.MORPH_CLOSE, kernel, iterations=1)\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bin2, connectivity=8)\n    if num_labels <= 1:\n        # fallback to global vesselness centroid\n        yx = np.unravel_index(np.argmax(vproj), vproj.shape)\n        cy2, cx2 = int(yx[0]), int(yx[1])\n    else:\n        # choose largest component\n        areas = stats[1:, cv2.CC_STAT_AREA]\n        lid = 1 + int(np.argmax(areas))\n        c = centroids[lid]\n        cy2, cx2 = int(c[1]), int(c[0])\n    # map centroid back to full-res\n    cy = int(cy2 * ds); cx = int(cx2 * ds)\n    # Initial coarse crop box\n    box = int(getattr(Config, 'CTF_COARSE_BOX_PX', 192))\n    y1 = max(0, cy - box//2); y2 = min(H, cy + box//2)\n    x1 = max(0, cx - box//2); x2 = min(W, cx + box//2)\n    crop = vol32[:, y1:y2, x1:x2]\n    # Fine masks (balanced and recall) computed at downscaled res, then upsampled for bbox/mask\n    fd = max(1, int(getattr(Config, 'CTF_FINE_DOWNSCALE', 1)))\n    hh, ww = (H // fd), (W // fd)\n    v_full_ds = np.stack([\n        _vesselness_2d(cv2.resize(vol32[z].astype(np.float32), (ww, hh)))\n        for z in range(D)\n    ], axis=0)\n    v_bal = (v_full_ds >= float(getattr(Config, 'CTF_FINE_THR_BAL', 0.35))).astype(np.uint8)\n    v_rec = (v_full_ds >= float(getattr(Config, 'CTF_FINE_THR_RECALL', 0.20))).astype(np.uint8)\n    ksz = int(getattr(Config, 'CTF_FINE_MORPH_K', 3))\n    kern = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksz, ksz))\n    for z in range(D):\n        v_bal[z] = cv2.morphologyEx(v_bal[z], cv2.MORPH_OPEN, kern)\n        v_rec[z] = cv2.morphologyEx(v_rec[z], cv2.MORPH_OPEN, kern)\n    # Upsample masks to full-res for bbox computation and final mask crop\n    v_bal = np.stack([cv2.resize(v_bal[z], (W, H), interpolation=cv2.INTER_NEAREST) for z in range(D)], axis=0)\n    v_rec = np.stack([cv2.resize(v_rec[z], (W, H), interpolation=cv2.INTER_NEAREST) for z in range(D)], axis=0)\n    # Tight bbox from balanced mask\n    ys, xs = np.where(v_bal.sum(axis=0) > 0)\n    if ys.size > 0:\n        y1f = max(0, ys.min() - int(getattr(Config, 'CTF_FINE_MARGIN', 24)))\n        y2f = min(H, ys.max() + int(getattr(Config, 'CTF_FINE_MARGIN', 24)))\n        x1f = max(0, xs.min() - int(getattr(Config, 'CTF_FINE_MARGIN', 24)))\n        x2f = min(W, xs.max() + int(getattr(Config, 'CTF_FINE_MARGIN', 24)))\n        crop = vol32[:, y1f:y2f, x1f:x2f]\n        mask_fine = v_rec[:, y1f:y2f, x1f:x2f].astype(np.float32)\n    else:\n        mask_fine = v_rec[:, y1:y2, x1:x2].astype(np.float32)\n    # Resize both crop and mask to fixed output size for batching\n    th, tw = getattr(Config, 'CTF_OUTPUT_SIZE', (384, 384))\n    out_vol = np.empty((D, th, tw), dtype=np.float32)\n    out_msk = np.empty((D, th, tw), dtype=np.float32)\n    for z in range(D):\n        out_vol[z] = cv2.resize(crop[z].astype(np.float32), (tw, th))\n        out_msk[z] = cv2.resize(mask_fine[z].astype(np.float32), (tw, th), interpolation=cv2.INTER_NEAREST)\n    return out_vol, np.clip(out_msk, 0.0, 1.0)\n\n    \n# ====================================================\n# CELL 1.1: LIGHTWEIGHT DICOM PREPROCESSOR (32x384x384)\n# ====================================================\n\nclass DICOMPreprocessorKaggle:\n    \"\"\"Minimal, memory-safe DICOM ‚Üí (32,384,384) volume preprocessor (offline, no deps).\"\"\"\n    def __init__(self, target_shape=(32, 384, 384)):\n        self.target_depth, self.target_height, self.target_width = target_shape\n\n    def process_series(self, series_path: str) -> np.ndarray:\n        sid = os.path.basename(series_path.rstrip('/'))\n        \n        # Load .npz shards directly (64, 384, 384, 4) uint8\n        if getattr(Config, 'CACHE_VOLUMES', False):\n            for cache_dir in getattr(Config, 'CACHE_DIRS', []):\n                if not isinstance(cache_dir, str) or not len(cache_dir):\n                    continue\n                npz_path = os.path.join(cache_dir, f\"{sid}.npz\")\n                if os.path.exists(npz_path):\n                    try:\n                        # Load compressed .npz (memory-mapped for speed)\n                        data = np.load(npz_path)\n                        vol_u8 = data['vol']  # (64, 384, 384, 4) uint8\n                        \n                        # Extract CTA channel (channel 0) for rsna2p5d\n                        vol_u8_cta = vol_u8[..., 0]  # (64, 384, 384)\n                        \n                        # Downsample from 64 to 32 slices (uniform sampling)\n                        indices = np.linspace(0, vol_u8_cta.shape[0] - 1, self.target_depth).astype(np.int32)\n                        vol_u8_32 = vol_u8_cta[indices]  # (32, 384, 384)\n                        \n                        # Convert uint8 [0,255] to float [0,1]\n                        if getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16':\n                            vol = (vol_u8_32.astype(np.float16)) / 255.0\n                        else:\n                            vol = (vol_u8_32.astype(np.float32)) / 255.0\n                        \n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[NPZ] Loaded {sid} from {os.path.basename(cache_dir)}\")\n                        \n                        return vol\n                    except Exception as e:\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[NPZ] Error loading {npz_path}: {e}\")\n                        continue\n    \n        # Collect DICOMs\n        dicoms = []\n        for root, _, files in os.walk(series_path):\n            for f in files:\n                if f.endswith('.dcm'):\n                    try:\n                        ds = pydicom.dcmread(os.path.join(root, f), force=True)\n                        if hasattr(ds, 'PixelData'):\n                            dicoms.append(ds)\n                    except Exception:\n                        continue\n        if len(dicoms) == 0:\n            return np.zeros((self.target_depth, self.target_height, self.target_width), dtype=np.float32)\n\n        # Prepass: compute majority (Rows,Cols) and PixelSpacing, orientation normal and z per-slice\n        try:\n            orient = np.array(dicoms[0].ImageOrientationPatient, dtype=np.float32)\n            rowv, colv = orient[:3], orient[3:]\n            normal = np.cross(rowv, colv)\n        except Exception:\n            normal = np.array([0,0,1], dtype=np.float32)\n\n        # Count majority configs\n        rc_count = {}\n        ps_count = {}\n        z_list = []\n        for ds in dicoms:\n            r = int(getattr(ds, 'Rows', 0)); c = int(getattr(ds, 'Columns', 0))\n            rc_count[(r,c)] = rc_count.get((r,c), 0) + 1\n            try:\n                ps = getattr(ds, 'PixelSpacing', None)\n                if ps is not None and len(ps) >= 2:\n                    ps_pair = (round(float(ps[0]), 3), round(float(ps[1]), 3))\n                    ps_count[ps_pair] = ps_count.get(ps_pair, 0) + 1\n            except Exception:\n                pass\n            try:\n                ipp = np.array(getattr(ds, 'ImagePositionPatient', [0,0,0]), dtype=np.float32)\n                z_list.append(float(np.dot(ipp, normal)))\n            except Exception:\n                z_list.append(None)\n\n        maj_rc, maj_rc_n = None, 0\n        total_rc = 0\n        for k, n in rc_count.items():\n            total_rc += n\n            if n > maj_rc_n:\n                maj_rc, maj_rc_n = k, n\n        maj_ps, maj_ps_n = None, 0\n        total_ps = 0\n        for k, n in ps_count.items():\n            total_ps += n\n            if n > maj_ps_n:\n                maj_ps, maj_ps_n = k, n\n\n        # Sort dicoms by ascending z using normal; fallback to InstanceNumber\n        try:\n            def sort_key(ds):\n                ipp = np.array(getattr(ds, 'ImagePositionPatient', [0,0,0]), dtype=np.float32)\n                return float(np.dot(ipp, normal))\n            dicoms = sorted(dicoms, key=sort_key)\n        except Exception:\n            dicoms = sorted(dicoms, key=lambda ds: getattr(ds, 'InstanceNumber', 0))\n\n        base_h = int(getattr(dicoms[0], 'Rows', 256))\n        base_w = int(getattr(dicoms[0], 'Columns', 256))\n        c, w = 50.0, 350.0\n        lo, hi = c - w/2.0, c + w/2.0\n        modality = (getattr(dicoms[0], 'Modality', '') or '').upper()\n\n        slices = []\n        # Build keep-list based on majority config and inter-slice spacing outliers\n        # Compute z per-ds again in sorted order\n        z_vals = []\n        for ds in dicoms:\n            try:\n                ipp = np.array(getattr(ds, 'ImagePositionPatient', [0,0,0]), dtype=np.float32)\n                z_vals.append(float(np.dot(ipp, normal)))\n            except Exception:\n                z_vals.append(None)\n        dz_keep = [True] * len(dicoms)\n        try:\n            z_num = np.array([z for z in z_vals if z is not None], dtype=np.float32)\n            if z_num.size >= 2:\n                dz = np.diff(z_num)\n                dz_abs = np.abs(dz)\n                dz_med = float(np.median(dz_abs)) if dz_abs.size else 1.0\n                # mark nonpositive or >3x median as outliers (skip next slice)\n                j = 0\n                for i in range(1, len(dicoms)):\n                    if z_vals[i-1] is None or z_vals[i] is None:\n                        j += 1\n                        continue\n                    d = z_vals[i] - z_vals[i-1]\n                    if d <= 0 or abs(d) > 3.0 * max(dz_med, 1e-6):\n                        dz_keep[i] = False\n                    j += 1\n        except Exception:\n            pass\n\n        def config_ok(ds):\n            try:\n                if maj_rc is not None:\n                    if (int(getattr(ds, 'Rows', 0)), int(getattr(ds, 'Columns', 0))) != maj_rc:\n                        return False\n                if maj_ps is not None:\n                    ps = getattr(ds, 'PixelSpacing', None)\n                    if ps is None or len(ps) < 2:\n                        return False\n                    pair = (round(float(ps[0]),3), round(float(ps[1]),3))\n                    if pair != maj_ps:\n                        return False\n                return True\n            except Exception:\n                return True\n\n        for i, ds in enumerate(dicoms):\n            if not dz_keep[i]:\n                continue\n            if not config_ok(ds):\n                continue\n            try:\n                fr = ds.pixel_array\n            except Exception:\n                continue\n            if fr.ndim >= 3:\n                h, w2 = fr.shape[-2], fr.shape[-1]\n                frames = fr.reshape(int(np.prod(fr.shape[:-2])), h, w2)\n            else:\n                frames = fr[np.newaxis, ...]\n            for sl in frames:\n                sl = sl.astype(np.float32)\n                if getattr(ds, 'PhotometricInterpretation', 'MONOCHROME2') == 'MONOCHROME1':\n                    sl = sl.max() - sl\n                slope = float(getattr(ds, 'RescaleSlope', 1.0)); intercept = float(getattr(ds, 'RescaleIntercept', 0.0))\n                sl = sl * slope + intercept\n                if sl.shape != (base_h, base_w):\n                    sl = cv2.resize(sl, (base_w, base_h))\n                if getattr(Config, 'INTENSITY_NORM_MODE', 'ct_window') == 'zscore':\n                    mean = float(sl.mean()); std = float(sl.std() + 1e-6)\n                    s = (sl - mean) / std\n                    zc = float(getattr(Config, 'ZSCORE_CLIP_SIGMA', 5.0))\n                    s = np.clip(s, -zc, zc)\n                    s = (s + zc) / (2.0 * zc)\n                else:\n                    if modality == 'CT':\n                        s = np.clip(sl, lo, hi)\n                        s = (s - lo) / (hi - lo + 1e-6)\n                    else:\n                        mean = float(sl.mean()); std = float(sl.std() + 1e-6)\n                        s = (sl - mean) / std; zc = 3.0\n                        s = np.clip(s, -zc, zc); s = (s + zc) / (2.0*zc)\n                slices.append(s.astype(np.float32))\n\n        volf = np.stack(slices, axis=0) if slices else np.zeros((1, base_h, base_w), dtype=np.float32)\n        # Trilinear depth+inplane resampling to (D,H,W)\n        try:\n            v = torch.from_numpy(volf)[None, None].to(dtype=torch.float32)  # (1,1,D,H,W)\n            v = F.interpolate(\n                v,\n                size=(self.target_depth, self.target_height, self.target_width),\n                mode='trilinear',\n                align_corners=False,\n            )\n            out = v[0, 0].numpy().astype(np.float32)\n        except Exception:\n            # Fallback to previous per-slice resize if torch not available\n            D = volf.shape[0]\n            idx = np.linspace(0, max(D-1,0), num=self.target_depth).astype(int) if D>0 else np.zeros(self.target_depth, dtype=int)\n            vT = volf[idx]\n            out = np.empty((self.target_depth, self.target_height, self.target_width), dtype=np.float32)\n            for i in range(self.target_depth):\n                out[i] = cv2.resize(vT[i], (self.target_width, self.target_height))\n        if getattr(Config, 'INTENSITY_NORM_MODE', 'ct_window') == 'zscore':\n            mean = float(out.mean()); std = float(out.std() + 1e-6)\n            out = (out - mean) / std\n            zc = float(getattr(Config, 'ZSCORE_CLIP_SIGMA', 5.0))\n            out = np.clip(out, -zc, zc)\n            out = (out + zc) / (2.0 * zc)\n        else:\n            p1, p99 = np.percentile(out, [1, 99])\n            if p99 > p1:\n                out = np.clip(out, p1, p99)\n                out = (out - p1) / (p99 - p1 + 1e-8)\n        out = np.nan_to_num(out, nan=0.0, posinf=1.0, neginf=0.0)\n        # Save cache using configured dtype\n        try:\n            if getattr(Config, 'CACHE_VOLUMES', False):\n                # Respect soft size cap\n                try:\n                    total_bytes = 0\n                    for f in os.listdir(Config.CACHE_DIR):\n                        fp = os.path.join(Config.CACHE_DIR, f)\n                        try:\n                            total_bytes += os.path.getsize(fp)\n                        except Exception:\n                            pass\n                    if total_bytes > Config.CACHE_MAX_GB * (1024**3):\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(\"[CACHE] size cap reached; skip saving\")\n                        raise RuntimeError('Cache size cap reached, skip saving')\n                except Exception:\n                    pass\n                # Ensure cache dir exists and choose dtype and filename suffix\n                os.makedirs(Config.CACHE_DIR, exist_ok=True)\n                sid = os.path.basename(series_path.rstrip('/'))\n                cache_base = os.path.join(Config.CACHE_DIR, f\"{sid}_32x384x384\")\n                dtype_choice = getattr(Config, 'CACHE_DTYPE', 'float16')\n                if dtype_choice == 'uint8':\n                    # Quantize to 8-bit [0,255] after normalization\n                    arr8 = (out * 255.0).round().astype(np.uint8)\n                    # Optional quick verification to ensure acceptable quantization error\n                    try:\n                        diff_max = float(np.max(np.abs(out - (arr8.astype(np.float32) / 255.0))))\n                        if diff_max > 0.02:  # fallback threshold for safety\n                            # Fallback to float16 if quantization too lossy\n                            np.save(cache_base + '_f16.npy', out.astype(np.float16), allow_pickle=False)\n                            if getattr(Config, 'CACHE_VERBOSE', False):\n                                print(f\"[CACHE] wrote f16 (fallback): {os.path.basename(cache_base)}_f16.npy\")\n                        else:\n                            np.save(cache_base + '_u8.npy', arr8, allow_pickle=False)\n                            if getattr(Config, 'CACHE_VERBOSE', False):\n                                print(f\"[CACHE] wrote u8: {os.path.basename(cache_base)}_u8.npy (max_err={diff_max:.4f})\")\n                    except Exception:\n                        np.save(cache_base + '_u8.npy', arr8, allow_pickle=False)\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[CACHE] wrote u8 (no-check): {os.path.basename(cache_base)}_u8.npy\")\n                else:\n                    np.save(cache_base + '_f16.npy', out.astype(np.float16), allow_pickle=False)\n                    if getattr(Config, 'CACHE_VERBOSE', False):\n                        print(f\"[CACHE] wrote f16: {os.path.basename(cache_base)}_f16.npy\")\n        except Exception:\n            pass\n        # Return dtype aligned with cache preference for lower CPU bandwidth\n        if getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16':\n            return out.astype(np.float16)\n        else:\n            return out.astype(np.float32)\n\ndef process_dicom_series_safe(series_path: str, target_shape=(32,384,384)) -> np.ndarray:\n    pre = DICOMPreprocessorKaggle(target_shape)\n    return pre.process_series(series_path)\n\n\n# ====================================================\n# CELL 2: DATA LOADING & ROI EXTRACTION\n# ====================================================\n\nclass Simple3DSegmentationNet(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        self.dummy = nn.Identity()\n    def forward(self, x):\n        return self.dummy(x)\n\nclass Stage1Predictor:\n    def __init__(self, *args, **kwargs):\n        pass\n    def predict_segmentation_with_volume(self, series_path):\n        # Not used in direct-volume path; kept minimal for compatibility\n        return np.zeros((1,1,1), dtype=np.float32), np.zeros((32,384,384), dtype=np.float32)\n\nclass SimpleDICOMProcessor:\n    def __init__(self, *args, **kwargs):\n        pass\n        \nclass ROIExtractor:\n    \"\"\"Research-backed ROI extraction with adaptive count and quality filtering\"\"\"\n    def __init__(self, stage1_predictor, roi_size=(224, 224)):\n        self.stage1_predictor = stage1_predictor\n        self.roi_size = roi_size\n        self.processor = SimpleDICOMProcessor()\n\n        # Research-backed thresholds\n        # Relaxed thresholds to avoid over-pruning when Stage 1 is weak\n        self.min_confidence_threshold = 0.15\n        self.high_confidence_threshold = 0.5\n        self.max_rois_per_series = getattr(Config, 'ROIS_PER_SERIES', 3)\n        # Post-process controls\n        self.border_margin = 2            # suppress edge activations near skull\n        self.min_region_size = 6         # minimum connected component size (pixels)\n        self.morph_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n\n    def extract_top3_rois(self, series_path):\n        \"\"\"Extract 0-5 ROIs based on segmentation quality (research-backed)\"\"\"\n        # Cache ROI results per series to avoid recomputation\n        try:\n            # Prefer external cache dir when available\n            cache_root = getattr(Config, 'STAGE2_CACHE_EXTERNAL_DIR', '')\n            if not isinstance(cache_root, str) or not os.path.isdir(cache_root):\n                cache_root = Config.STAGE2_CACHE_DIR\n            os.makedirs(cache_root, exist_ok=True)\n            sid = os.path.basename(series_path)\n            cache_path = os.path.join(cache_root, f\"{sid}_rois.npy\")\n            if os.path.exists(cache_path):\n                arr = np.load(cache_path, allow_pickle=True)\n                return list(arr)\n        except Exception:\n            cache_path = None\n        rois = self.extract_adaptive_rois(series_path)\n        try:\n            if cache_path is not None:\n                np.save(cache_path, np.array(rois, dtype=object), allow_pickle=True)\n        except Exception:\n            pass\n        return rois\n\n    def extract_adaptive_rois(self, series_path):\n        \"\"\"Extract 0-5 ROIs based on segmentation quality (research-backed)\"\"\"\n        try:\n            print(f\"üîç DEBUG: Quality-based ROI extraction for {os.path.basename(series_path)}\")\n            \n            # Get Stage 1 seg mask and the preprocessed volume (avoid reloading original DICOMs here)\n            seg_mask, original_volume = self.stage1_predictor.predict_segmentation_with_volume(series_path)\n            print(f\"üîç DEBUG: Segmentation mask shape: {seg_mask.shape}; Volume shape: {original_volume.shape}\")\n            \n            # STEP 1: Assess overall segmentation quality\n            seg_quality = self._assess_segmentation_quality(seg_mask)\n            print(f\"üîç DEBUG: Segmentation quality score: {seg_quality:.3f}\")\n            \n            # STEP 2: If segmentation is poor, still attempt candidate extraction; fallback only if none\n            low_quality = seg_quality < self.min_confidence_threshold\n            if low_quality:\n                print(f\"üîç DEBUG: Low segmentation quality ({seg_quality:.3f} < {self.min_confidence_threshold}), attempting candidate extraction anyway\")\n            \n            # STEP 4: Extract ROIs with confidence-based filtering\n            roi_candidates = self._find_quality_based_rois(seg_mask, original_volume)\n            \n            if low_quality and not roi_candidates:\n                print(\"üîç DEBUG: No candidates under low-quality mask, using volume-based fallback\")\n                return self._get_quality_fallback_rois_from_volume(original_volume, self.max_rois_per_series)\n\n            # STEP 5: Adaptive ROI count\n            selected_rois = self._select_adaptive_rois(roi_candidates, seg_quality, original_volume)\n            \n            print(f\"üîç DEBUG: Selected {len(selected_rois)} ROIs based on quality assessment\")\n            return selected_rois\n            \n        except Exception as e:\n            print(f\"‚ùå Error in quality-based ROI extraction: {e}\")\n            return self._get_emergency_fallback_rois()\n    \n    def _assess_segmentation_quality(self, seg_mask):\n        \"\"\"Assess segmentation quality using connected components and border penalties.\"\"\"\n        try:\n            D, H, W = seg_mask.shape\n            largest_area_frac = 0.0\n            largest_mean_conf = 0.0\n            total_components = 0\n            border_touch_penalty = 0.0\n\n            for z in range(D):\n                sm = seg_mask[z]\n                # suppress borders\n                sm_proc = sm.copy()\n                sm_proc[:self.border_margin, :] = 0\n                sm_proc[-self.border_margin:, :] = 0\n                sm_proc[:, :self.border_margin] = 0\n                sm_proc[:, -self.border_margin:] = 0\n\n               # Adaptive thresholding based on actual max values\n                max_val = float(sm_proc.max())\n                if max_val > 0.3:\n                    thr = max(0.05, 0.3 * max_val)\n                elif max_val > 0.1:\n                    thr = max(0.03, 0.4 * max_val)\n                else:\n                    thr = max(0.02, 0.5 * max_val)\n                binmask = (sm_proc > thr).astype(np.uint8)\n                if binmask.max() == 0:\n                    continue\n                # small opening to remove speckle\n                binmask = cv2.morphologyEx(binmask, cv2.MORPH_OPEN, self.morph_kernel)\n\n                labeled, n = label(binmask)\n                if n == 0:\n                    continue\n                total_components += int(n)\n\n                # evaluate components\n                for comp_id in range(1, n + 1):\n                    comp = (labeled == comp_id)\n                    comp_size = int(comp.sum())\n                    if comp_size < self.min_region_size:\n                        continue\n                    mean_conf = float(sm[comp].mean())\n                    area_frac = comp_size / float(H * W)\n                    if area_frac > largest_area_frac:\n                        largest_area_frac = area_frac\n                    if mean_conf > largest_mean_conf:\n                        largest_mean_conf = mean_conf\n\n                    # simple border-touch penalty if component abuts image edge\n                    ys, xs = np.where(comp)\n                    if ys.size > 0:\n                        if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                            xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                            border_touch_penalty += 0.02\n\n            # compose quality score\n            area_score = min(largest_area_frac / 0.02, 1.0)  # cap around ~2% of slice (aneurysm-sized)\n            comp_penalty = min(0.1, 0.0015 * total_components) + min(0.1, border_touch_penalty)\n            quality_score = max(0.0, 0.6 * largest_mean_conf + 0.4 * area_score - comp_penalty)\n\n            # robust floor based on global mask stats to avoid spurious 0.0 quality\n            max_val = float(seg_mask.max())\n            mean_val = float(seg_mask.mean())\n            if max_val >= 0.55:\n                quality_score = max(quality_score, 0.35)\n            elif max_val >= 0.45:\n                quality_score = max(quality_score, 0.25)\n            elif mean_val >= 0.25:\n                quality_score = max(quality_score, 0.22)\n\n            return float(quality_score)\n        except Exception:\n            return 0.1\n    \n    def _find_quality_based_rois(self, seg_mask, original_volume):\n        \"\"\"Find ROI candidates with confidence scores (no hardcoded count)\"\"\"\n        print(\"üîç DEBUG: Finding quality-based ROI candidates...\")\n        \n        # Resize segmentation mask to match original volume\n        if seg_mask.shape != original_volume.shape:\n            print(\"üîç DEBUG: Resizing segmentation mask with cv2...\")\n            seg_mask_resized = np.zeros(original_volume.shape, dtype=np.float32)\n            for i in range(min(seg_mask.shape[0], original_volume.shape[0])):\n                if i < seg_mask.shape[0]:\n                    resized_slice = cv2.resize(\n                        seg_mask[i],\n                        (original_volume.shape[2], original_volume.shape[1])\n                    )\n                    seg_mask_resized[i] = resized_slice\n        else:\n            seg_mask_resized = seg_mask\n        \n        # 3D peak proposals first (relative peak logic; does not lower thresholds)\n        roi_candidates = self._proposals_from_3d_peaks(seg_mask_resized)\n        if len(roi_candidates) == 0:\n            # Fall back to 2D slice-wise CC method\n            roi_candidates = []\n        \n        H, W = original_volume.shape[1], original_volume.shape[2]\n        for slice_idx in range(seg_mask_resized.shape[0]):\n            slice_mask = seg_mask_resized[slice_idx].copy()\n\n            # Suppress borders to avoid skull/edge activations\n            slice_mask[:self.border_margin, :] = 0\n            slice_mask[-self.border_margin:, :] = 0\n            slice_mask[:, :self.border_margin] = 0\n            slice_mask[:, -self.border_margin:] = 0\n\n            # Adaptive dynamic threshold tied to local max (aligned with quality assessment)\n            max_val = float(slice_mask.max())\n            if max_val > 0.2:\n                thr = max(self.min_confidence_threshold, 0.25 * max_val)\n            elif max_val > 0.1:\n                thr = max(0.03, 0.30 * max_val)\n            else:\n                thr = max(0.02, 0.25 * max_val)\n            high_conf_regions = (slice_mask > thr).astype(np.uint8)\n            if high_conf_regions.max() == 0:\n                # Percentile-based fallback with small dilation to form blobs\n                p90 = float(np.percentile(slice_mask, 90))\n                if p90 > 0:\n                    mask_peaks = (slice_mask >= p90).astype(np.uint8)\n                    # small dilation to merge nearby high pixels\n                    mask_peaks = cv2.dilate(mask_peaks, self.morph_kernel, iterations=1)\n                    labeled_regions, num_regions = label(mask_peaks)\n                    for region_id in range(1, num_regions + 1):\n                        region_mask = (labeled_regions == region_id)\n                        region_size = int(region_mask.sum())\n                        if region_size < 3:\n                            continue\n                        ys, xs = np.where(region_mask)\n                        if ys.size == 0:\n                            continue\n                        # Skip borders\n                        if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                            xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                            continue\n                        com = center_of_mass(region_mask)\n                        y, x = int(com[0]), int(com[1])\n                        region_confidence = float(slice_mask[region_mask].mean())\n                        roi_candidates.append({\n                            'slice_idx': slice_idx,\n                            'y': y,\n                            'x': x,\n                            'confidence': region_confidence,\n                            'region_size': region_size\n                        })\n                continue\n            # Apply opening only if region is sufficiently large; avoid eroding tiny blobs\n            if int(high_conf_regions.sum()) > 50:\n                high_conf_regions = cv2.morphologyEx(high_conf_regions, cv2.MORPH_OPEN, self.morph_kernel)\n\n            labeled_regions, num_regions = label(high_conf_regions)\n            for region_id in range(1, num_regions + 1):\n                region_mask = (labeled_regions == region_id)\n                region_size = int(region_mask.sum())\n                if region_size < self.min_region_size:\n                    continue\n                ys, xs = np.where(region_mask)\n                if ys.size == 0:\n                    continue\n                # Skip border-touching components\n                if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                    xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                    continue\n\n                com = center_of_mass(region_mask)\n                y, x = int(com[0]), int(com[1])\n                region_confidence = float(slice_mask[region_mask].mean())\n\n                roi_candidates.append({\n                    'slice_idx': slice_idx,\n                    'y': y,\n                    'x': x,\n                    'confidence': region_confidence,\n                    'region_size': region_size\n                })\n        \n        # Sort by confidence (descending)\n        if not roi_candidates:\n            # Volume-wise peak fallback: pick top maxima per slice (excluding borders)\n            print(\"üîç DEBUG: No ROI components found; using volume-wise peak fallback\")\n            D = seg_mask_resized.shape[0]\n            peak_candidates = []\n            for z in range(D):\n                m = seg_mask_resized[z].copy()\n                # suppress borders\n                m[:self.border_margin, :] = 0\n                m[-self.border_margin:, :] = 0\n                m[:, :self.border_margin] = 0\n                m[:, -self.border_margin:] = 0\n                yx = np.unravel_index(np.argmax(m), m.shape)\n                y, x = int(yx[0]), int(yx[1])\n                conf = float(m[y, x])\n                if conf > 0:\n                    peak_candidates.append({\n                        'slice_idx': z,\n                        'y': y,\n                        'x': x,\n                        'confidence': conf,\n                        'region_size': 1\n                    })\n            # Keep strongest few peaks across volume\n            peak_candidates.sort(key=lambda c: c['confidence'], reverse=True)\n            roi_candidates.extend(peak_candidates[: max( self.max_rois_per_series * 3, 6)])\n\n        roi_candidates.sort(key=lambda x: x['confidence'], reverse=True)\n        \n        print(f\"üîç DEBUG: Found {len(roi_candidates)} ROI candidates\")\n        return roi_candidates\n\n    def _proposals_from_3d_peaks(self, seg_mask_zyx: np.ndarray):\n        \"\"\"3D local-max proposals with seeded relative growth (no absolute threshold lowering).\"\"\"\n        try:\n            D, H, W = seg_mask_zyx.shape\n            # Light 3D smoothing to stabilize local maxima\n            try:\n                sm = ndimage.gaussian_filter(seg_mask_zyx.astype(np.float32), sigma=0.75)\n            except Exception:\n                sm = seg_mask_zyx.astype(np.float32)\n            # 3D local maxima via maximum filter\n            footprint = np.ones((3,3,3), dtype=np.uint8)\n            max_f = ndimage.maximum_filter(sm, footprint=footprint, mode='nearest')\n            peaks = (sm == max_f)\n            # Suppress borders\n            b = self.border_margin\n            if b > 0:\n                peaks[:, :b, :] = False; peaks[:, -b:, :] = False\n                peaks[:, :, :b] = False; peaks[:, :, -b:] = False\n            coords = np.argwhere(peaks)\n            if coords.shape[0] == 0:\n                return []\n            # Rank peaks by value and keep top-K to control cost\n            values = sm[peaks]\n            order = np.argsort(values)[::-1]\n            top_k = min(64, order.size)\n            selected = coords[order[:top_k]]\n            # Non-maximum suppression by 3D distance\n            kept = []\n            min_dist = 4.0\n            for (cz, cy, cx) in selected:\n                if any(((cz-kz)**2 + (cy-ky)**2 + (cx-kx)**2) ** 0.5 < min_dist for kz,ky,kx in kept):\n                    continue\n                kept.append((int(cz), int(cy), int(cx)))\n                if len(kept) >= 64:\n                    break\n            # Seeded relative growth\n            proposals = []\n            for cz, cy, cx in kept:\n                peak = float(sm[cz, cy, cx])\n                if peak <= 0:\n                    continue\n                rel_thr = max(0.6*peak, 1e-6)  # relative to each peak\n                # collect voxels that descend from the peak (thresholded region)\n                region = sm >= rel_thr\n                labeled, num = ndimage.label(region)\n                cid = int(labeled[cz, cy, cx])\n                if cid == 0:\n                    continue\n                comp = (labeled == cid)\n                size = int(comp.sum())\n                if size < self.min_region_size:\n                    continue\n                # score = peak * mean(comp)\n                conf = peak * float(sm[comp].mean() + 1e-6)\n                # project to a representative slice (peak slice)\n                ys, xs = np.where(comp[cz])\n                if ys.size == 0:\n                    # fallback to COM over full comp\n                    zc, yc, xc = ndimage.center_of_mass(comp)\n                    zc = int(round(zc)); yc = int(round(yc)); xc = int(round(xc))\n                    if yc <= self.border_margin or yc >= H - self.border_margin - 1 or xc <= self.border_margin or xc >= W - self.border_margin - 1:\n                        continue\n                    proposals.append({\n                        'slice_idx': int(zc),\n                        'y': int(yc),\n                        'x': int(xc),\n                        'confidence': float(conf),\n                        'region_size': size,\n                    })\n                else:\n                    y = int(ys.mean()); x = int(xs.mean())\n                    if y <= self.border_margin or y >= H - self.border_margin - 1 or x <= self.border_margin or x >= W - self.border_margin - 1:\n                        continue\n                    proposals.append({\n                        'slice_idx': int(cz),\n                        'y': y,\n                        'x': x,\n                        'confidence': float(conf),\n                        'region_size': size,\n                    })\n            proposals.sort(key=lambda c: c['confidence'], reverse=True)\n            return proposals\n        except Exception:\n            return []\n    \n    def _select_adaptive_rois(self, roi_candidates, seg_quality, original_volume):\n        \"\"\"Adaptively select ROIs based on segmentation quality (research-backed)\"\"\"\n        if not roi_candidates:\n            print(\"üîç DEBUG: No candidates found, using fallback\")\n            return self._get_quality_fallback_rois_from_volume(original_volume)\n        \n        # Adaptive selection based on segmentation quality\n        if seg_quality >= self.high_confidence_threshold:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.3\n        elif seg_quality >= self.min_confidence_threshold + 0.2:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.2\n        else:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.05\n        \n        # Filter and select ROIs\n        filtered = [c for c in roi_candidates if c['confidence'] >= min_confidence]\n        selected_candidates = filtered[:max_rois]\n        # If not enough, top-off with next best candidates\n        if len(selected_candidates) < max_rois:\n            for c in roi_candidates:\n                if c in selected_candidates:\n                    continue\n                selected_candidates.append(c)\n                if len(selected_candidates) >= max_rois:\n                    break\n        \n        # Convert to ROI format\n        rois = []\n        for i, candidate in enumerate(selected_candidates):\n            roi_patch = self._extract_roi_patch(\n                original_volume,\n                candidate['slice_idx'], \n                candidate['y'], \n                candidate['x']\n            )\n            \n            rois.append({\n                'roi_image': roi_patch,\n                'slice_idx': candidate['slice_idx'],\n                'coordinates': (candidate['y'], candidate['x']),\n                'confidence': candidate['confidence'],\n                'roi_id': i\n            })\n        # Ensure at least max_rois via center-based fallback if still short\n        if len(rois) < self.max_rois_per_series:\n            needed = self.max_rois_per_series - len(rois)\n            center_fallbacks = self._get_quality_fallback_rois_from_volume(original_volume, needed)\n            rois.extend(center_fallbacks)\n        print(f\"üîç DEBUG: Adaptively selected {len(rois)} ROIs (quality: {seg_quality:.3f})\")\n        return rois[: self.max_rois_per_series]\n    \n    def _get_quality_fallback_rois(self, series_path, seg_mask):\n        \"\"\"Fallback for poor segmentation quality: generate multiple center-based ROIs\"\"\"\n        print(\"üîç DEBUG: Using quality-aware fallback (multi-center ROIs)\")\n        original_volume = self._load_efficient_volume(series_path)\n        return self._get_quality_fallback_rois_from_volume(original_volume, self.max_rois_per_series)\n\n    def _get_quality_fallback_rois_from_volume(self, original_volume, count: int = 3):\n        D, H, W = original_volume.shape\n        # Choose slice indices: center and quartiles\n        slices = sorted(set([D // 2, max(0, D // 4), min(D - 1, 3 * D // 4)]))\n        # Ensure desired count\n        while len(slices) < count:\n            # Add random slices if needed\n            slices.append(np.random.randint(0, D))\n            slices = list(dict.fromkeys(slices))\n        rois = []\n        cy, cx = H // 2, W // 2\n        for i, s in enumerate(slices[:count]):\n            roi_patch = self._extract_roi_patch(original_volume, s, cy, cx)\n            rois.append({\n                'roi_image': roi_patch,\n                'slice_idx': s,\n                'coordinates': (cy, cx),\n                'confidence': 0.2,\n                'roi_id': i\n            })\n        return rois\n    \n    def _get_simple_fallback_rois(self):\n        \"\"\"Simple fallback when no quality ROIs found\"\"\"\n        print(\"üîç DEBUG: Using simple fallback (single center ROI)\")\n        dummy_roi = np.random.random((*Config.ROI_SIZE, 3)).astype(np.float32)\n        return [{\n            'roi_image': dummy_roi,\n            'slice_idx': 25,\n            'coordinates': (128, 128),\n            'confidence': 0.1,\n            'roi_id': 0\n        }]\n    \n    def _get_emergency_fallback_rois(self):\n        \"\"\"Emergency fallback when everything fails\"\"\"\n        print(\"üîç DEBUG: Using emergency fallback ROI\")\n        dummy_roi = np.random.random((*Config.ROI_SIZE, 3)).astype(np.float32)\n        return [{\n            'roi_image': dummy_roi,\n            'slice_idx': 0,\n            'coordinates': (128, 128),\n            'confidence': 0.1,\n            'roi_id': 0\n        }]\n\n    \n    def _load_efficient_volume(self, series_path):\n        \"\"\"Load volume with smart distributed sampling to cover entire brain\"\"\"\n        try:\n            # Cache original volume slices to reduce repeated I/O\n            os.makedirs(Config.STAGE2_CACHE_DIR, exist_ok=True)\n            sid = os.path.basename(series_path)\n            vcache = os.path.join(Config.STAGE2_CACHE_DIR, f\"{sid}_vol.npy\")\n            if os.path.exists(vcache):\n                return np.load(vcache, allow_pickle=False)\n            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n            pixel_arrays = []\n            \n            # SMART SAMPLING: Distribute 50 slices across entire volume\n            total_files = len(dicom_files)\n            if total_files > 50:\n                # Calculate step size to distribute slices evenly\n                step = total_files / 50\n                selected_indices = [int(i * step) for i in range(50)]\n                selected_files = [dicom_files[i] for i in selected_indices]\n                print(f\"üîç DEBUG: Smart sampling - selected {len(selected_files)} files from {total_files} total (every {step:.1f})\")\n            else:\n                selected_files = dicom_files\n                print(f\"üîç DEBUG: Using all {len(selected_files)} files (less than 50)\")\n            \n            for f in selected_files:\n                try:\n                    ds = pydicom.dcmread(os.path.join(series_path, f), force=True)\n                    if hasattr(ds, 'pixel_array'):\n                        arr = ds.pixel_array\n                        if arr.ndim == 2:\n                            pixel_arrays.append(arr)\n                except:\n                    continue\n            \n            if pixel_arrays:\n                # SMALLER target shape to reduce memory usage\n                target_shape = (256, 256)  # Reduced from (512, 512)\n                \n                resized_arrays = []\n                for arr in pixel_arrays:\n                    # Use cv2.resize instead of ndimage.zoom (more reliable)\n                    if arr.shape != target_shape:\n                        resized_arr = cv2.resize(arr.astype(np.float32), target_shape)\n                        resized_arrays.append(resized_arr)\n                    else:\n                        resized_arrays.append(arr.astype(np.float32))\n                \n                volume = np.stack(resized_arrays, axis=0)\n                \n                # Simple normalization\n                p1, p99 = np.percentile(volume, [1, 99])\n                volume = np.clip(volume, p1, p99)\n                volume = (volume - p1) / (p99 - p1 + 1e-8)\n                \n                try:\n                    np.save(vcache, volume.astype(np.float32), allow_pickle=False)\n                except Exception:\n                    pass\n                return volume\n            \n        except Exception as e:\n            print(f\"Error loading efficient volume: {e}\")\n        \n        # Fallback volume (matches our smart sampling approach)\n        return np.random.random((50, 256, 256)).astype(np.float32)\n\n    \n    def _extract_roi_patch(self, volume, slice_idx, center_y, center_x):\n        \"\"\"Extract ROI with adjacent-slice context as RGB channels (s-1, s, s+1).\"\"\"\n        D, H, W = volume.shape\n        s_indices = [max(0, slice_idx - 1), slice_idx, min(D - 1, slice_idx + 1)]\n        channels = []\n        half_size = Config.ROI_SIZE[0] // 2\n        for s in s_indices:\n            slice_data = volume[s]\n            h, w = slice_data.shape\n            y1 = max(0, center_y - half_size)\n            y2 = min(h, center_y + half_size)\n            x1 = max(0, center_x - half_size)\n            x2 = min(w, center_x + half_size)\n            patch = slice_data[y1:y2, x1:x2]\n            patch_resized = cv2.resize(patch, Config.ROI_SIZE)\n            channels.append(patch_resized)\n        patch_3ch = np.stack(channels, axis=2)\n        return patch_3ch\n    \n\ndef create_training_data(df, stage1_predictor):\n    \"\"\"Create training data. If DIRECT_VOLUME_MODE, bypass ROI extraction and use Stage0 32x384x384 volumes.\"\"\"\n    print(\"üîÑ Extracting ROIs for training data...\")\n    \n    # Direct volume mode: build dataframe pointing to Stage0 32x384x384 volumes\n    if getattr(Config, 'DIRECT_VOLUME_MODE', False):\n        print(\"‚úÖ DIRECT_VOLUME_MODE: using Stage 0 32x384x384 volumes (no ROI extraction)\")\n        # On-the-fly generation: do not depend on prebuilt volumes; dataset will read DICOMs\n        records = []\n        for _, row in df.iterrows():\n            sid = str(row[Config.ID_COL])\n            rec = {\n                'roi_id': f\"{sid}_vol32\",\n                'roi_path': '',\n                'series_id': sid,\n                'roi_confidence': 1.0,\n                'slice_idx': -1,\n            }\n            for col in Config.LABEL_COLS:\n                rec[col] = row[col]\n            records.append(rec)\n        training_df = pd.DataFrame(records)\n        print(f\"‚úÖ DIRECT_VOLUME_MODE: built {len(training_df)} samples from {len(df)} series\")\n        return training_df\n\n    # Reuse cached ROIs/training dataframe if available\n    cache_dir = 'rois'\n    os.makedirs(cache_dir, exist_ok=True)\n    cached_df_path_parquet = os.path.join(cache_dir, 'training_df.parquet')\n    external_cached_df_path = os.path.join(getattr(Config, 'ROIS_EXTERNAL_DIR', ''), 'training_df.parquet')\n    if Config.REUSE_EXISTING_ROIS:\n        # Prefer working cache\n        if os.path.exists(cached_df_path_parquet):\n            try:\n                cached = pl.read_parquet(cached_df_path_parquet).to_pandas()\n                if len(cached) > 0 and all(c in cached.columns for c in ['roi_path', 'roi_id', 'series_id'] + Config.LABEL_COLS):\n                    print(f\"‚úÖ Reusing cached training ROIs (working): {len(cached)} samples from {cached['series_id'].nunique()} series\")\n                    return cached\n            except Exception:\n                pass\n        # Fallback to external cache\n        if isinstance(external_cached_df_path, str) and len(external_cached_df_path) and os.path.exists(external_cached_df_path):\n            try:\n                cached = pl.read_parquet(external_cached_df_path).to_pandas()\n                if len(cached) > 0 and all(c in cached.columns for c in ['roi_path', 'roi_id', 'series_id'] + Config.LABEL_COLS):\n                    print(f\"‚úÖ Reusing cached training ROIs (external): {len(cached)} samples from {cached['series_id'].nunique()} series\")\n                    # Optionally copy into working for faster subsequent access\n                    try:\n                        pl.from_pandas(cached).write_parquet(cached_df_path_parquet)\n                    except Exception:\n                        pass\n                    return cached\n            except Exception:\n                pass\n        # If external parquet is missing but external ROI images exist, auto-build parquet\n        ext_dir = getattr(Config, 'ROIS_EXTERNAL_DIR', '')\n        if isinstance(ext_dir, str) and os.path.isdir(ext_dir):\n            try:\n                candidates = [f for f in os.listdir(ext_dir) if f.lower().endswith('.png')]\n                if len(candidates) > 0:\n                    print(f\"üß© Building training_df from external ROI images: {len(candidates)} files\")\n                    records = []\n                    label_cols = list(Config.LABEL_COLS)\n                    # Map labels by series_id for fast join\n                    df_labels = df[[Config.ID_COL] + label_cols].copy()\n                    df_labels[Config.ID_COL] = df_labels[Config.ID_COL].astype(str)\n                    label_map = df_labels.set_index(Config.ID_COL).to_dict('index')\n                    for fname in candidates:\n                        base = os.path.splitext(fname)[0]\n                        # Expect pattern: {series_id}_roi_{k}\n                        # Robust parse: split on '_roi_'\n                        if '_roi_' not in base:\n                            continue\n                        sid_part, roi_part = base.split('_roi_', 1)\n                        series_id = sid_part\n                        try:\n                            roi_id_int = int(roi_part)\n                        except Exception:\n                            roi_id_int = 0\n                        rec = {\n                            'roi_id': f\"{series_id}_roi_{roi_id_int}\",\n                            'roi_path': os.path.join(ext_dir, fname),\n                            'series_id': series_id,\n                            'roi_confidence': 0.2,\n                            'slice_idx': -1,\n                        }\n                        # Attach labels\n                        labs = label_map.get(series_id)\n                        if labs is None:\n                            # skip if label missing (should not happen for train)\n                            continue\n                        for col in label_cols:\n                            rec[col] = labs[col]\n                        records.append(rec)\n                    if records:\n                        training_df_ext = pd.DataFrame(records)\n                        print(f\"‚úÖ Reconstructed training ROIs (external): {len(training_df_ext)} samples from {training_df_ext['series_id'].nunique()} series\")\n                        try:\n                            pl.from_pandas(training_df_ext).write_parquet(cached_df_path_parquet)\n                        except Exception:\n                            pass\n                        return training_df_ext\n            except Exception:\n                pass\n    roi_extractor = ROIExtractor(stage1_predictor)\n    training_data = []\n    \n    os.makedirs('rois', exist_ok=True)\n    \n    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting ROIs\"):\n        series_id = row[Config.ID_COL]\n        series_path = os.path.join(Config.SERIES_DIR, series_id)\n        \n        if not os.path.exists(series_path):\n            continue\n        \n        # Extract ROIs\n        rois = roi_extractor.extract_top3_rois(series_path)\n        \n        # Create training samples\n        for roi_data in rois:\n            roi_filename = f\"rois/{series_id}_roi_{roi_data['roi_id']}.png\"\n            \n            # Save ROI image\n            roi_image = (roi_data['roi_image'] * 255).astype(np.uint8)\n            Image.fromarray(roi_image).save(roi_filename)\n            \n            # Create training record\n            sample = {\n                'roi_id': f\"{series_id}_roi_{roi_data['roi_id']}\",\n                'roi_path': roi_filename,\n                'series_id': series_id,\n                'roi_confidence': roi_data['confidence'],\n                'slice_idx': roi_data['slice_idx']\n            }\n            \n            # Add all label columns\n            for col in Config.LABEL_COLS:\n                sample[col] = row[col]\n            \n            training_data.append(sample)\n    \n    training_df = pd.DataFrame(training_data)\n    print(f\"‚úÖ Created {len(training_df)} training samples from {len(df)} series\")\n    # Save for reuse next runs\n    try:\n        pl.from_pandas(training_df).write_parquet(cached_df_path_parquet)\n        print(f\"üíæ Saved training ROI dataframe ‚Üí {cached_df_path_parquet}\")\n    except Exception:\n        pass\n    \n    return training_df\n\nprint(\"‚úÖ Data loading and ROI extraction functions loaded\")\n\n\n\n# ====================================================\n# CELL 3: MODEL DEFINITION\n# ====================================================\n\nclass AneurysmClassificationDataset(Dataset):\n    \"\"\"Dataset for classification. In direct volume mode, builds 32x384x384 on-the-fly from DICOMs.\"\"\"\n    def __init__(self, df, mode='train'):\n        self.df = df\n        self.mode = mode\n        self.direct_volume = getattr(Config, 'DIRECT_VOLUME_MODE', False)\n        if self.direct_volume:\n            self.preprocessor = DICOMPreprocessorKaggle(target_shape=(32, 384, 384))\n            self.alb_transform = None  # Skip Albumentations in direct-volume path\n        else:\n            # ROI image pipeline (3-channel PNGs) - keep minimal and albumentations-based\n            if mode == 'train':\n                self.alb_transform = A.Compose([\n                    A.HorizontalFlip(p=0.5),\n                    A.VerticalFlip(p=0.5),\n                    A.Rotate(limit=15, p=0.5),\n                    A.ColorJitter(brightness=0.2, contrast=0.2, p=0.5),\n                    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n                    ToTensorV2(transpose_mask=False),\n                ])\n            else:\n                self.alb_transform = A.Compose([\n                    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n                    ToTensorV2(transpose_mask=False),\n                ])\n    \n    def __len__(self):\n        return len(self.df)\n    \ndef __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        if self.direct_volume:\n            # Build volume directly from series path (already normalized [0,1])\n            series_id = str(row['series_id'])\n            series_path = os.path.join(Config.SERIES_DIR, series_id)\n            arr = process_dicom_series_safe(series_path, target_shape=(32,384,384))  # (32,384,384) fp16/fp32\n            # Coarse-to-fine ROI focusing (nnUNet-inspired) with on-disk caching (per-series)\n            roi_mask = None\n            ctf_on = bool(getattr(Config, 'CTF_ENABLE', True))\n            try:\n                if self.mode == 'train' and hasattr(Config, 'CTF_ENABLE_TRAIN'):\n                    ctf_on = bool(getattr(Config, 'CTF_ENABLE_TRAIN', ctf_on))\n                elif self.mode != 'train' and hasattr(Config, 'CTF_ENABLE_VAL'):\n                    ctf_on = bool(getattr(Config, 'CTF_ENABLE_VAL', ctf_on))\n            except Exception:\n                pass\n            if ctf_on:\n                try:\n                    arr32 = arr.astype(np.float32)\n                    arr, out_msk = apply_coarse_to_fine_roi(arr32)\n                    roi_mask = torch.as_tensor(out_msk, dtype=torch.float32)\n                except Exception:\n                    roi_mask = None\n            # Train-time slice subsample: keep quality by using full slices at val/test\n            if self.mode == 'train':\n                k = int(getattr(Config, 'SLICE_SUBSAMPLE_TRAIN', 0) or 0)\n                if k and arr.shape[0] > k:\n                    idx_keep = np.sort(np.random.choice(arr.shape[0], size=k, replace=False))\n                    arr = arr[idx_keep]\n            # Always return float32 to avoid dtype mismatches with timm convs under autocast\n            image = torch.as_tensor(arr, dtype=torch.float32)\n            try:\n                del arr\n            except Exception:\n                pass\n        else:\n            # Load ROI image\n            roi_path = row['roi_path']\n            try:\n                pil_img = Image.open(roi_path).convert('RGB')\n            except:\n                pil_img = Image.fromarray(np.random.randint(0, 255, (*Config.ROI_SIZE, 3), dtype=np.uint8))\n            np_img = np.array(pil_img)\n            try:\n                pil_img.close()\n            except Exception:\n                pass\n            out = self.alb_transform(image=np_img)\n            image = out['image']\n            try:\n                del np_img\n            except Exception:\n                pass\n        \n        # Get labels\n        labels = torch.tensor([row[col] for col in Config.LABEL_COLS], dtype=torch.float32)\n        \n        sample = {\n            'image': image,\n            'labels': labels,\n            'roi_id': row['roi_id'],\n            'confidence': torch.tensor(row['roi_confidence'], dtype=torch.float32)\n        }\n        if roi_mask is not None:\n            sample['roi_mask'] = roi_mask\n        return sample\n\n\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, clip=0.05, eps=1e-8):\n        super().__init__()\n        self.gp = float(gamma_pos)\n        self.gn = float(gamma_neg)\n        self.clip = float(clip) if clip is not None else None\n        self.eps = float(eps)\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        x = torch.sigmoid(logits)\n        xs = x\n        if self.clip is not None and self.clip > 0:\n            xs = torch.clamp(x, self.clip, 1.0 - self.clip)\n        pos = targets\n        neg = 1.0 - targets\n        loss_pos = -pos * torch.log(xs + self.eps) * ((1.0 - x) ** self.gp)\n        loss_neg = -neg * torch.log(1.0 - xs + self.eps) * (x ** self.gn)\n        return (loss_pos + loss_neg).mean()\n\n# ====================================================\n# MIL 2.5D MODEL: Shared 2D encoder per slice + Transformer over depth\n# ====================================================\nclass PositionalEncoding1D(nn.Module):\n    def __init__(self, d_model, max_len=128):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer('pe', pe[None])  # (1, L, C)\n    def forward(self, x):  # x: (B, L, C)\n        return x + self.pe[:, :x.size(1)]\n\nclass SliceTriChannel(nn.Module):\n    \"\"\"Make each token a tri-slice [z-1, z, z+1] to inject tiny depth context per slice.\"\"\"\n    def forward(self, x):  # x: (B, D, H, W)\n        # Pad depth by 1 on each side, then slice and stack\n        xp = F.pad(x, (0, 0, 0, 0, 1, 1), mode='replicate')  # (B, D+2, H, W)\n        tri = torch.stack([xp[:, :-2], xp[:, 1:-1], xp[:, 2:]], dim=2)  # (B, D, 3, H, W)\n        return tri\n\nclass MIL2p5D(nn.Module):\n    \"\"\"\n    OPTIMIZED: Shared 2D ImageNet encoder per slice -> Transformer over tokens -> gated attention pooling -> logits.\n    Speed optimizations:\n      - Smaller backbone (B0 instead of B3): 3-4x faster\n      - Reduced spatial resolution (224 instead of 320): 2x faster\n      - Gradient checkpointing: Allows larger batches\n      - Optional encoder compilation (PyTorch 2.0+)\n    \"\"\"\n    def __init__(self, num_classes=len(Config.LABEL_COLS), \n                 backbone=None, d_model=None, nhead=None, n_layers=None, \n                 spatial_size=None, use_grad_checkpoint=None):\n        super().__init__()\n        # Use Config defaults if not provided\n        backbone = backbone or getattr(Config, 'MIL_BACKBONE', 'tf_efficientnet_b0')\n        d_model = d_model or getattr(Config, 'MIL_D_MODEL', 512)\n        nhead = nhead or getattr(Config, 'MIL_NHEAD', 8)\n        n_layers = n_layers or getattr(Config, 'MIL_N_LAYERS', 2)\n        self.spatial_size = spatial_size or getattr(Config, 'MIL_SPATIAL_SIZE', 224)\n        use_grad_checkpoint = use_grad_checkpoint if use_grad_checkpoint is not None else getattr(Config, 'MIL_USE_GRAD_CHECKPOINT', True)\n        \n        self.tri = SliceTriChannel()\n        # Shared 2D encoder (lightweight for speed)\n        self.encoder = timm.create_model(backbone, pretrained=False, in_chans=3, num_classes=0, global_pool='avg')\n        \n        # Try to load offline weights (support B0, B1, B3)\n        weights_map = {\n            'tf_efficientnet_b0': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth',\n            'tf_efficientnet_b1': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b1/1/tf_efficientnet_b1_aa-ea7a7bb7.pth',\n            'tf_efficientnet_b3': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b3/1/tf_efficientnet_b3_aa-84b4657e.pth',\n        }\n        weights_path = weights_map.get(backbone, None)\n        if weights_path and os.path.exists(weights_path):\n            try:\n                print(f\"üîÑ Loading offline {backbone} weights from: {weights_path}\")\n                state = torch.load(weights_path, map_location=\"cpu\")\n                if isinstance(state, dict) and \"state_dict\" in state:\n                    state = state[\"state_dict\"]\n                clean = {}\n                for k, v in state.items():\n                    if isinstance(k, str):\n                        if k.startswith(\"module.\"): k = k[7:]\n                        if k.startswith(\"model.\"):  k = k[6:]\n                        clean[k] = v\n                missing, unexpected = self.encoder.load_state_dict(clean, strict=False)\n                print(f\"‚úÖ Weights loaded. Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error loading weights: {e}\")\n        \n        # Enable gradient checkpointing for encoder (saves VRAM)\n        if use_grad_checkpoint and hasattr(self.encoder, 'set_grad_checkpointing'):\n            try:\n                self.encoder.set_grad_checkpointing(True)\n                print(f\"‚úÖ Gradient checkpointing enabled for {backbone}\")\n            except Exception:\n                pass\n        \n        # Optional: Compile encoder for speed (PyTorch 2.0+)\n        if getattr(Config, 'MIL_COMPILE_ENCODER', False):\n            try:\n                self.encoder = torch.compile(self.encoder, mode='max-autotune')\n                print(\"‚úÖ Encoder compiled with torch.compile\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è torch.compile not available: {e}\")\n        \n        feat_dim = int(getattr(self.encoder, 'num_features'))\n        self.proj = nn.Linear(feat_dim, d_model)\n        self.pe   = PositionalEncoding1D(d_model, max_len=128)\n        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True,\n                                               dim_feedforward=4*d_model, norm_first=True)\n        self.tx   = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Tanh(), nn.Linear(d_model, 1))\n        self.head = nn.Linear(d_model, num_classes)\n        \n        print(f\"üèóÔ∏è  MIL2p5D: backbone={backbone}, spatial={self.spatial_size}, d_model={d_model}, layers={n_layers}\")\n\n    def forward(self, x, mask: torch.Tensor = None):  # x: (B, D, H, W) in [0,1]\n        B, D, H, W = x.shape\n        x = self.tri(x)\n        # Apply vessel mask as a spatial gate per slice if provided\n        if mask is not None and isinstance(mask, torch.Tensor):\n            try:\n                m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(2)  # (B,D,1,H,W)\n                m = m.expand(-1, -1, 3, -1, -1)                          # (B,D,3,H,W)\n                x = x * torch.clamp(m, 0, 1)\n            except Exception:\n                pass# (B, D, 3, H, W)\n        x = x.view(B*D, 3, H, W)\n        x = x.to(memory_format=torch.channels_last)\n        # Downscale to target spatial size for speed\n        if x.shape[-2] != self.spatial_size or x.shape[-1] != self.spatial_size:\n            x = F.interpolate(x, size=(self.spatial_size, self.spatial_size), mode='bilinear', align_corners=False)\n        feats = self.encoder(x)              # (B*D, feat_dim)\n        feats = feats.view(B, D, -1)         # (B, D, feat_dim)\n        z = self.proj(feats)                 # (B, D, d_model)\n        z = self.pe(z)\n        z = self.tx(z)                       # (B, D, d_model)\n        a = torch.softmax(self.gate(z), dim=1)  # (B, D, 1)\n        bag = (a * z).sum(dim=1)             # (B, d_model)\n        logits = self.head(bag)              # (B, C)\n        return logits\n\n\n# Using original EfficientNet approach\n\ndef calculate_class_weights(df):\n    \"\"\"Calculate class weights with 13x multiplier for Aneurysm Present\"\"\"\n    pos_counts = df[Config.LABEL_COLS].sum()\n    neg_counts = len(df) - pos_counts\n    \n    # Standard frequency-based weights\n    class_weights = neg_counts / (pos_counts + 1e-8)\n    \n    # Apply weight cap if configured (prevents extreme weights like 93.5)\n    weight_cap = getattr(Config, 'CLASS_WEIGHT_CAP', 100.0)\n    class_weights = np.minimum(class_weights, weight_cap)\n    \n    # Apply 13x multiplier to \"Aneurysm Present\" (matches competition metric)\n    # But also respect the cap\n    class_weights.iloc[-1] = min(class_weights.iloc[-1] * 13.0, weight_cap)\n    \n    return torch.tensor(class_weights.values, dtype=torch.float32)\n\ntry:\n    torch.backends.cudnn.benchmark = True  # speed: autotune best cudnn algorithms for fixed input sizes\nexcept Exception:\n    pass\nprint(\"‚úÖ Model definition loaded\")\n\n# ====================================================\n# CELL 4: TRAINING PIPELINE\n# ====================================================\n\ndef compute_hierarchical_penalty(logits: torch.Tensor) -> torch.Tensor:\n    \"\"\"Penalty to enforce sites' probabilities <= main (Aneurysm Present).\n    logits: (B, C=14) with last index being 'Aneurysm Present'.\n    Returns a scalar tensor on the same device/dtype.\n    \"\"\"\n    try:\n        if logits.ndim != 2 or logits.size(1) < 2:\n            return torch.zeros((), device=logits.device, dtype=logits.dtype)\n        sites = logits[:, :-1]\n        main = logits[:, -1:]\n        p_sites = torch.sigmoid(sites)\n        p_main = torch.sigmoid(main)\n        return F.relu(p_sites - p_main).mean()\n    except Exception:\n        # Safe fallback: no penalty if anything goes wrong\n        return torch.zeros((), device=logits.device, dtype=logits.dtype)\n\ndef compute_primary_loss(logits: torch.Tensor, labels: torch.Tensor, bce_criterion: nn.Module) -> torch.Tensor:\n    \"\"\"Compute supervised loss: ASL for site logits + BCE for main logit, or fallback to BCE for all.\n    Assumes last class is 'Aneurysm Present'.\n    \"\"\"\n    try:\n        if getattr(Config, 'USE_ASL', False) and logits.size(1) >= 2:\n            # ASL for site logits (all except last)\n            asl = AsymmetricLoss(\n                gamma_pos=getattr(Config, 'ASL_GAMMA_POS', 0.0),\n                gamma_neg=getattr(Config, 'ASL_GAMMA_NEG', 4.0),\n                clip=getattr(Config, 'ASL_CLIP', 0.05),\n            )\n            sites_logits = logits[:, :-1]\n            sites_targets = labels[:, :-1]\n            loss_sites = asl(sites_logits, sites_targets)\n            # BCE for main logit (last column), keep pos_weight emphasis\n            main_logits = logits[:, -1]\n            main_targets = labels[:, -1]\n            try:\n                pw_main = None\n                if hasattr(bce_criterion, 'pos_weight') and bce_criterion.pos_weight is not None:\n                    pw_main = bce_criterion.pos_weight[-1].to(main_logits.device)\n                if pw_main is not None:\n                    loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets, pos_weight=pw_main)\n                else:\n                    loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets)\n            except Exception:\n                loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets)\n            w_sites = float(getattr(Config, 'ASL_WEIGHT_SITES', 1.0))\n            w_main  = float(getattr(Config, 'MAIN_BCE_WEIGHT', 1.0))\n            return w_sites * loss_sites + w_main * loss_main\n        else:\n            return bce_criterion(logits, labels)\n    except Exception:\n        return bce_criterion(logits, labels)\n\n\ndef _val_forward_in_chunks(model, images, *, max_tokens:int, mixed_precision:bool):\n    \"\"\"\n    images:\n      ‚Ä¢ mil2p5d: (B, D, H, W) before tri-stacking in the model\n      ‚Ä¢ 2D ROI: (B, C, H, W)\n    We compute a chunk size so that (b_chunk * D) <= max_tokens for mil2p5d,\n    or (b_chunk) <= max_tokens for 2D ROI, and concatenate outputs.\n    \"\"\"\n    import torch\n    from torch import nn\n\n    if images.dim() == 4:\n        B = images.size(0)\n        second = images.size(1)\n        D = 1 if second in (1, 3) else second\n    elif images.dim() == 5:\n        B = images.size(0)\n        D = images.size(1)\n    else:\n        B, D = images.size(0), 1\n\n    b_chunk = max(1, int(max_tokens // max(D, 1)))\n    outs = []\n    for i in range(0, B, b_chunk):\n        x = images[i:i + b_chunk]\n        with torch.cuda.amp.autocast(enabled=mixed_precision):\n            outs.append(model(x))\n    return torch.cat(outs, dim=0)\n\n\n\ndef compute_validation_auc(logits: torch.Tensor, labels: torch.Tensor) -> float:\n    \"\"\"Compute weighted AUC (13x on 'Aneurysm Present') mirroring validate_epoch behavior.\"\"\"\n    try:\n        probs = torch.sigmoid(logits).float().cpu().numpy()\n        y_true = labels.float().cpu().numpy()\n        auc_scores = []\n        valid_aucs = 0\n        for i in range(len(Config.LABEL_COLS)):\n            if len(np.unique(y_true[:, i])) > 1:\n                auc = roc_auc_score(y_true[:, i], probs[:, i])\n                auc_scores.append(auc)\n                valid_aucs += 1                \n            else:\n                auc_scores.append(0.5)\n\n        # DEBUG: Print stats on first validation\n        if not hasattr(compute_validation_auc, '_debug_printed'):\n            print(f\"üîç AUC DEBUG - Valid classes: {valid_aucs}/{len(Config.LABEL_COLS)}\")\n            print(f\"üîç AUC DEBUG - Pred range: [{probs.min():.3f}, {probs.max():.3f}]\")\n            print(f\"üîç AUC DEBUG - Pred mean: {probs.mean():.3f}\")\n            print(f\"üîç AUC DEBUG - Positive rate: {y_true.mean():.3f}\")\n            compute_validation_auc._debug_printed = True\n            \n        weights = [1.0] * (len(Config.LABEL_COLS) - 1) + [13.0]\n        weighted_auc = float(np.average(auc_scores, weights=weights))\n        return weighted_auc\n    except Exception as e:\n        print(f\"‚ö†Ô∏è AUC computation failed: {e}\")\n        return 0.5\n\n\ndef _run_validation(model, loader, criterion, device, *, max_tokens:int):\n    import torch\n    model.eval()\n    # Temporarily disable encoder/backbone grad-checkpointing for eval (if available)\n    core = model.module if isinstance(model, nn.DataParallel) else model\n    enc_ref = getattr(core, 'encoder', None)\n    if enc_ref is None:\n        enc_ref = getattr(core, 'backbone', None)\n    restore_gc = None\n    if enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n        try:\n            restore_gc = True\n            enc_ref.set_grad_checkpointing(False)\n        except Exception:\n            restore_gc = None\n\n    total_loss = 0.0\n    num_batches = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.inference_mode():\n        for batch in tqdm(loader, desc=\"Validating (proxy)\" if int(max_tokens) < int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384)) else \"Validating (full)\"):\n            if isinstance(batch, dict):\n                images = batch['image'].to(device, non_blocking=True)\n                labels = batch['labels'].to(device, non_blocking=True)\n            else:\n                images, labels = batch\n                images = images.to(device, non_blocking=True)\n                labels = labels.to(device, non_blocking=True)\n\n            logits = _val_forward_in_chunks(\n                model,\n                images,\n                max_tokens=int(max_tokens),\n                mixed_precision=bool(getattr(Config, 'MIXED_PRECISION', True)),\n            )\n            # Compute supervised loss (same routine as training)\n            primary_loss = compute_primary_loss(logits, labels, criterion)\n            if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                hier_pen = compute_hierarchical_penalty(logits)\n                batch_loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n            else:\n                batch_loss = primary_loss\n            total_loss += float(batch_loss.detach().cpu())\n            num_batches += 1\n\n            # Collect predictions for AUC on CPU\n            all_preds.append(torch.sigmoid(logits).float().cpu())\n            all_labels.append(labels.float().cpu())\n\n    if restore_gc and enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n        try:\n            enc_ref.set_grad_checkpointing(True)\n        except Exception:\n            pass\n\n    logits_cat = torch.cat(all_preds, dim=0)\n    labels_cat = torch.cat(all_labels, dim=0)\n    val_loss = total_loss / max(1, num_batches)\n    val_auc = compute_validation_auc(logits_cat, labels_cat)\n    return val_loss, val_auc\n\n\ndef autotune_micro_batch(model, train_loader, criterion, device):\n    \"\"\"\n    Try a few micro-batch sizes on a single mini-iteration to find the largest safe one.\n    No weights are updated. Returns chosen micro size.\n    \"\"\"\n    import torch\n    model.eval()\n    \n    # Safety: Try to get batch with timeout protection\n    try:\n        print(\"[AutoTune] Fetching test batch...\", flush=True)\n        batch = next(iter(train_loader))\n        if isinstance(batch, dict):\n            imgs = batch['image']\n            labels = batch['labels']\n        else:\n            imgs, labels = batch\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        print(f\"[AutoTune] Test batch loaded: {imgs.shape}\", flush=True)\n    except Exception as e:\n        print(f\"[AutoTune] ERROR loading batch: {e}\", flush=True)\n        print(\"[AutoTune] Falling back to default MICRO_BATCH_SIZE\", flush=True)\n        return getattr(Config, 'MICRO_BATCH_SIZE', 12)\n\n    candidates = [16, 14, 12, 10, 8, 6, 4]\n    chosen = None\n    scaler_local = torch.cuda.amp.GradScaler(enabled=getattr(Config, 'MIXED_PRECISION', True))\n\n    for mb in candidates:\n        try:\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n            accum = max(1, int((getattr(Config, 'BATCH_SIZE', 24) + mb - 1) // mb))\n            model.zero_grad(set_to_none=True)\n            for i in range(accum):\n                i0 = i * mb\n                i1 = min((i + 1) * mb, imgs.size(0))\n                if i0 >= i1:\n                    break\n                x = imgs[i0:i1].to(memory_format=torch.channels_last)\n                y = labels[i0:i1]\n                with torch.cuda.amp.autocast(enabled=getattr(Config, 'MIXED_PRECISION', True)):\n                    logits = model(x)\n                    loss = criterion(logits, y) / accum\n                scaler_local.scale(loss).backward()\n            # Clear grads (no optimizer step)\n            for p in model.parameters():\n                if p.grad is not None:\n                    p.grad = None\n            chosen = mb\n            break\n        except RuntimeError as e:\n            if 'CUDA out of memory' not in str(e):\n                raise\n        finally:\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n\n    model.train()\n    if chosen is None:\n        chosen = max(1, int(getattr(Config, 'MICRO_BATCH_SIZE', 12)))\n    return chosen\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    \n    for batch in tqdm(loader, desc=\"Training\"):\n        images = batch['image'].to(device, non_blocking=True)\n        labels = batch['labels'].to(device, non_blocking=True)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        # Forward pass\n        with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n            images = images.to(memory_format=torch.channels_last)\n            # Optional mask routing: if dataset provided ROI mask, pass along\n            roi_mask = batch.get('roi_mask') if isinstance(batch, dict) else None\n            logits = model(images, mask=roi_mask)\n        primary_loss = compute_primary_loss(logits, labels, criterion)\n        if getattr(Config, 'ENABLE_HIER_LOSS', False):\n            hier_pen = compute_hierarchical_penalty(logits)\n            loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n        else:\n            loss = primary_loss\n        \n        # Backward pass\n        if Config.MIXED_PRECISION:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    return total_loss / num_batches\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    num_batches = 0\n    \n    with torch.inference_mode():\n        for batch in tqdm(loader, desc=\"Validating\"):\n            images = batch['image'].to(device, non_blocking=True)\n            labels = batch['labels'].to(device, non_blocking=True)\n            \n            with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n                images = images.to(memory_format=torch.channels_last)\n\n            # For val, run in chunks; pass mask if present\n            if isinstance(batch, dict) and 'roi_mask' in batch:\n                # Simple non-chunked path if mask exists (rarely too big)\n                logits = model(images, mask=batch['roi_mask'].to(images.device))\n            else:\n                logits = _val_forward_in_chunks(\n                    model,\n                    images,\n                    max_tokens=int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384)),\n                    mixed_precision=bool(getattr(Config, 'MIXED_PRECISION', True)),\n                )\n            primary_loss = compute_primary_loss(logits, labels, criterion)\n            if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                hier_pen = compute_hierarchical_penalty(logits)\n                loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n            else:\n                loss = primary_loss\n            \n            total_loss += loss.item()\n            num_batches += 1\n            \n            # Collect predictions for AUC on CPU only and free GPU tensors promptly\n            probs = torch.sigmoid(logits).float().cpu()\n            all_preds.append(probs.numpy())\n            all_labels.append(labels.cpu().numpy())\n            del logits, probs, images, labels\n    \n    # Calculate AUC (overall + per-class)\n    if len(all_preds) > 0:\n        all_preds = np.vstack(all_preds)\n        all_labels = np.vstack(all_labels)\n        \n        try:\n            auc_scores = []\n            for i in range(len(Config.LABEL_COLS)):\n                if len(np.unique(all_labels[:, i])) > 1:\n                    auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n                    auc_scores.append(auc)\n                else:\n                    auc_scores.append(0.5)\n\n            # DEBUG: Print stats EVERY fold to track prediction behavior\n            print(f\"üîç AUC DEBUG - Valid classes: {valid_aucs}/{len(Config.LABEL_COLS)}\")\n            print(f\"üîç AUC DEBUG - Pred range: [{probs.min():.3f}, {probs.max():.3f}]\")\n            print(f\"üîç AUC DEBUG - Pred mean: {probs.mean():.3f}\")\n            print(f\"üîç AUC DEBUG - Positive rate: {y_true.mean():.3f}\")\n            \n            # Weighted AUC (13x weight for Aneurysm Present)\n            weights = [1.0] * (len(Config.LABEL_COLS) - 1) + [13.0]\n            weighted_auc = np.average(auc_scores, weights=weights)\n\n            # Per-class AUC logging (rounded)\n            per_class_auc = {Config.LABEL_COLS[i]: (round(auc_scores[i], 4) if not np.isnan(auc_scores[i]) else None)\n                             for i in range(len(Config.LABEL_COLS))}\n            print(\"Per-class AUC:\", per_class_auc)\n        except:\n            weighted_auc = 0.5\n    else:\n        weighted_auc = 0.5\n    \n    return total_loss / num_batches, weighted_auc\n\ndef main_training():\n    print(\"üöÄ STAGE 2: ANEURYSM CLASSIFICATION\")\n    print(\"üì¶ Data: Loading .npz shards directly (64x384x384x4 uint8)\")\n    \n    # Load data\n    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n    \n    if Config.DEBUG_MODE:\n        train_df = train_df.head(Config.DEBUG_SAMPLES)\n    \n    # Apply external exclusions only (generated by quality_scan.py)\n\n    # Apply external exclusions if available (one-time precomputed by quality_scan.py)\n    try:\n        excl_candidates = [\n            '/kaggle/input/excluded-series/exclusions.csv',\n        ]\n        used_path = None\n        excl_df = None\n        for p in excl_candidates:\n            if os.path.exists(p):\n                used_path = p\n                try:\n                    excl_df = pd.read_csv(p)\n                except Exception:\n                    excl_df = None\n                if excl_df is not None:\n                    break\n        if excl_df is not None and 'series_id' in excl_df.columns:\n            before_n = len(train_df)\n            excl_set = set(excl_df['series_id'].astype(str).tolist())\n            train_df = train_df[~train_df[Config.ID_COL].astype(str).isin(excl_set)].reset_index(drop=True)\n            print(f\"‚úÖ Applied exclusions from {used_path}: removed {before_n - len(train_df)} series; using {len(train_df)}\")\n    except Exception as _e:\n        print(f\"‚ö†Ô∏è Could not apply exclusions: {_e}\")\n\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Aneurysm cases: {train_df['Aneurysm Present'].sum()}\")\n    \n    # Build training index (DIRECT_VOLUME_MODE: no ROIs)\n    records = []\n    for _, r in train_df.iterrows():\n        rec = {\n            'series_id': str(r[Config.ID_COL]),\n            'roi_id': f\"{str(r[Config.ID_COL])}_vol32\",\n            'roi_path': '',\n            'roi_confidence': 1.0,\n            'slice_idx': -1,\n        }\n        for col in Config.LABEL_COLS:\n            rec[col] = r[col]\n        records.append(rec)\n    training_df = pd.DataFrame(records)\n    \n    # Calculate class weights\n    class_weights = calculate_class_weights(training_df)\n    print(f\"Class weights: {class_weights}\")\n    \n    # Create criterion with class weights\n    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(Config.DEVICE)\n    \n    # Mixed precision scaler\n    global scaler\n    scaler = torch.cuda.amp.GradScaler(enabled=Config.MIXED_PRECISION)\n    \n    # Cross-validation or single split\n    # Use Aneurysm Present for stratification\n    fold_scores = []\n    if Config.N_FOLDS <= 1:\n        idx_all = np.arange(len(training_df))\n        train_idx, val_idx = train_test_split(\n            idx_all,\n            test_size=0.2,\n            stratify=training_df['Aneurysm Present'],\n            random_state=42,\n        )\n        fold_splits = [(train_idx, val_idx)]\n    else:\n        skf = StratifiedKFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=42)\n        fold_splits = list(skf.split(training_df, training_df['Aneurysm Present']))\n    \n    for fold, (train_idx, val_idx) in enumerate(fold_splits):\n        print(f\"\\n{'='*50}\")\n        print(f\"FOLD {fold + 1}/{Config.N_FOLDS}\")\n        print(f\"{'='*50}\")\n        \n        # Split data\n        train_fold_df = training_df.iloc[train_idx].reset_index(drop=True)\n        val_fold_df = training_df.iloc[val_idx].reset_index(drop=True)\n        \n        print(f\"Train samples: {len(train_fold_df)}, Val samples: {len(val_fold_df)}\")\n        \n        # Create datasets\n        train_dataset = AneurysmClassificationDataset(train_fold_df, mode='train')\n        val_dataset = AneurysmClassificationDataset(val_fold_df, mode='val')\n\n\n        # DEBUG: Verify data sanity (safe, non-blocking)\n        if fold == 0:\n            print(f\"üîç DATASET TYPE: {type(train_dataset).__name__}\")\n            try:\n                test_sample = train_dataset[0]\n                print(f\"üîç DATA CHECK - Image shape: {test_sample['image'].shape}, dtype: {test_sample['image'].dtype}\")\n                print(f\"üîç DATA CHECK - Image range: [{test_sample['image'].min():.3f}, {test_sample['image'].max():.3f}]\")\n                print(f\"üîç DATA CHECK - Image mean: {test_sample['image'].mean():.3f}, std: {test_sample['image'].std():.3f}\")\n                print(f\"üîç DATA CHECK - Non-zero voxels: {(test_sample['image'] > 0).sum()}/{test_sample['image'].numel()}\")\n                print(f\"üîç DATA CHECK - Labels shape: {test_sample['labels'].shape}, sum: {test_sample['labels'].sum()}\")\n            except Exception as e:\n                print(f\"üîç DATA CHECK SKIPPED (direct index failed): {e}\")\n                \n            # Check class distribution\n            aneurysm_present = train_fold_df['Aneurysm Present'].sum()\n            total_samples = len(train_fold_df)\n            print(f\"üîç CLASS DISTRIBUTION - Aneurysm Present: {aneurysm_present}/{total_samples} ({100*aneurysm_present/total_samples:.1f}%)\")\n            \n            # Check all label columns\n            for col in Config.LABEL_COLS:\n                if col in train_fold_df.columns:\n                    pos = train_fold_df[col].sum()\n                    print(f\"  {col}: {pos} positives\")\n\n        # WeightedRandomSampler to emphasize positives (Aneurysm Present)\n        sampler = None\n        if getattr(Config, 'USE_WEIGHTED_SAMPLER', True):\n            try:\n                pos = train_fold_df['Aneurysm Present'].values.astype(np.int64)\n                class_sample_count = np.array([np.sum(pos == 0), np.sum(pos == 1)])\n                weight = 1.0 / (class_sample_count + 1e-8)\n                samples_weight = weight[pos]\n                samples_weight = torch.from_numpy(samples_weight).double()\n                sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n            except Exception:\n                sampler = None\n        \n        # Create loaders (tuned for throughput)\n        if int(getattr(Config, 'NUM_WORKERS', 0) or 0) == 0:\n            train_loader = DataLoader(\n                train_dataset,\n                batch_size=Config.BATCH_SIZE,\n                shuffle=(sampler is None),\n                sampler=sampler,\n                num_workers=0,\n                pin_memory=Config.PIN_MEMORY,\n                drop_last=True,\n            )\n            val_loader = DataLoader(\n                val_dataset,\n                batch_size=getattr(Config, 'VAL_BATCH_SIZE', 64),\n                shuffle=False,\n                num_workers=0,\n                pin_memory=Config.PIN_MEMORY,\n            )\n        else:\n            train_loader = DataLoader(\n                train_dataset,\n                batch_size=Config.BATCH_SIZE,\n                shuffle=(sampler is None),\n                sampler=sampler,\n                num_workers=Config.NUM_WORKERS,\n                pin_memory=Config.PIN_MEMORY,\n                persistent_workers=Config.PERSISTENT_WORKERS,\n                prefetch_factor=Config.PREFETCH_FACTOR,\n                drop_last=True,\n            )\n            val_loader = DataLoader(\n                val_dataset,\n                batch_size=getattr(Config, 'VAL_BATCH_SIZE', 64),\n                shuffle=False,\n                num_workers=Config.NUM_WORKERS,\n                pin_memory=Config.PIN_MEMORY,\n                persistent_workers=Config.PERSISTENT_WORKERS,\n                prefetch_factor=Config.PREFETCH_FACTOR,\n            )\n        print(\n            f\"DataLoader settings -> workers={Config.NUM_WORKERS}, prefetch={Config.PREFETCH_FACTOR}, \"\n            f\"pin_memory={Config.PIN_MEMORY}, persistent={Config.PERSISTENT_WORKERS}\"\n        )\n        \n        def build_fast_val_loader(val_dataset):\n            import numpy as _np\n            from torch.utils.data import DataLoader as _DL, Subset as _Subset\n            frac = float(getattr(Config, 'FAST_VAL_SUBSET_FRAC', 0.33))\n            n = len(val_dataset)\n            k = max(1, int(n * frac))\n            rng = _np.random.RandomState(getattr(Config, 'SEED', 42))\n            idx = rng.choice(n, size=k, replace=False)\n            subset = _Subset(val_dataset, idx.tolist())\n            if int(getattr(Config, 'NUM_WORKERS', 0) or 0) == 0:\n                return _DL(\n                    subset,\n                    batch_size=getattr(Config, 'VAL_BATCH_SIZE', 32),\n                    shuffle=False,\n                    num_workers=0,\n                    pin_memory=getattr(Config, 'PIN_MEMORY', True),\n                )\n            else:\n                return _DL(\n                    subset,\n                    batch_size=getattr(Config, 'VAL_BATCH_SIZE', 32),\n                    shuffle=False,\n                    num_workers=getattr(Config, 'NUM_WORKERS', 4),\n                    pin_memory=getattr(Config, 'PIN_MEMORY', True),\n                    persistent_workers=getattr(Config, 'PERSISTENT_WORKERS', True),\n                    prefetch_factor=getattr(Config, 'PREFETCH_FACTOR', 2),\n                )\n        val_loader_full = val_loader\n        val_loader_fast = build_fast_val_loader(val_dataset) if getattr(Config, 'FAST_VAL', True) else None\n        \n        # Initialize MIL2p5D model unconditionally (pipeline cleanup)\n        Config.MODEL_ARCH = 'mil2p5d'\n        Config.SHARD_CHANNEL_MODE = 'best3'  # CTA + soft + vesselness\n        Config.SHARD_TARGET_SPATIAL = (\n            getattr(Config, 'MIL_SPATIAL_SIZE', 256), getattr(Config, 'MIL_SPATIAL_SIZE', 256)\n        )\n        print(\n            f\"üîß MIL2p5D mode: shard channels={Config.SHARD_CHANNEL_MODE}, spatial={Config.SHARD_TARGET_SPATIAL}\"\n        )\n        model = MIL2p5D(num_classes=len(Config.LABEL_COLS)).to(Config.DEVICE)\n        try:\n            model = model.to(memory_format=torch.channels_last)\n        except Exception:\n            pass\n        \n        # Optimizer - MIL2p5D only (constant LR)\n        lr = Config.LEARNING_RATE  # 2e-4\n        optimizer = optim.AdamW([\n            {'params': model.encoder.parameters(), 'lr': lr},\n            {'params': model.proj.parameters(), 'lr': lr},\n            {'params': model.tx.parameters(), 'lr': lr},\n            {'params': model.gate.parameters(), 'lr': lr},\n            {'params': model.head.parameters(), 'lr': lr},\n        ])\n\n        # Optional: 1-epoch freeze warmup for backbone\n        freeze_backbone_for_epoch0 = True\n        # EMA (CPU, float32) to avoid extra VRAM usage\n        use_ema = bool(getattr(Config, 'USE_EMA', True))\n        ema_decay = float(getattr(Config, 'EMA_DECAY', 0.999))\n        ema_state = (\n            {\n                k: v.detach().float().cpu().clone()\n                for k, v in model.state_dict().items()\n                if isinstance(v, torch.Tensor) and torch.is_floating_point(v)\n            }\n            if use_ema else None\n        )\n        \n        # Multi-GPU if available\n        if torch.cuda.device_count() > 1:\n            model = nn.DataParallel(model)\n\n\n        # Enable grad checkpointing on encoder/backbone if supported (saves VRAM)\n        core_for_gc = model.module if isinstance(model, nn.DataParallel) else model\n        enc_ref = getattr(core_for_gc, 'encoder', None)\n        if enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n            try:\n                enc_ref.set_grad_checkpointing(True)\n            except Exception:\n                pass\n        \n        # Auto-tune micro-batch size once before epoch 1\n        if getattr(Config, 'AUTO_TUNE_MICRO', False):  # DISABLED by default to prevent hanging\n            print(\"[AutoTune] Probing micro-batch size... this may take a few minutes on the first run\", flush=True)\n            try:\n                mb = autotune_micro_batch(model, train_loader, criterion, Config.DEVICE)\n                if mb != Config.MICRO_BATCH_SIZE:\n                    print(f\"[AutoTune] MICRO_BATCH_SIZE {Config.MICRO_BATCH_SIZE} -> {mb}\", flush=True)\n                else:\n                    print(f\"[AutoTune] MICRO_BATCH_SIZE remains {mb}\", flush=True)\n                Config.MICRO_BATCH_SIZE = mb\n            except Exception as e:\n                print(f\"[AutoTune] ERROR: {e}\", flush=True)\n                print(f\"[AutoTune] Using default MICRO_BATCH_SIZE={Config.MICRO_BATCH_SIZE}\", flush=True)\n        else:\n            print(f\"[AutoTune] Skipped (disabled). Using MICRO_BATCH_SIZE={Config.MICRO_BATCH_SIZE}\", flush=True)\n        # Training loop\n        best_auc = 0\n        patience = max(1, int(getattr(Config, 'EARLY_STOPPING_PATIENCE', 2)))\n        no_improve = 0\n        best_full_auc = -1.0\n        full_val_metrics = None\n        \n        for epoch in range(Config.EPOCHS):\n            print(f\"\\nEpoch {epoch+1}/{Config.EPOCHS}\")\n            t0 = time.time()  \n            \n            # GPU utilization tracking\n            gpu_idle_time = 0\n            gpu_active_time = 0\n            last_gpu_check = time.time()\n\n            if freeze_backbone_for_epoch0:\n                core = model.module if isinstance(model, nn.DataParallel) else model\n                backbone_ref = getattr(core, 'encoder', None)\n                if backbone_ref is not None:\n                    if epoch == 0:\n                        for p in backbone_ref.parameters():\n                            p.requires_grad = False\n                    elif epoch == 1:\n                        for p in backbone_ref.parameters():\n                            p.requires_grad = True\n            \n            # Train\n            train_loss = 0.0\n            model.train()\n            grad_accum_steps = getattr(Config, 'GRAD_ACCUM_STEPS', 1)\n            \n            for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n                iter_start = time.time()\n                \n                # Track GPU idle time (time waiting for data)\n                if batch_idx > 0:\n                    data_wait_time = iter_start - last_gpu_check\n                    gpu_idle_time += data_wait_time\n                    \n                images = batch['image'].to(Config.DEVICE, non_blocking=True)\n                labels = batch['labels'].to(Config.DEVICE, non_blocking=True)\n                           \n                # Zero grad only at start of accumulation cycle\n                if batch_idx % grad_accum_steps == 0:\n                    optimizer.zero_grad(set_to_none=True)\n                \n                # Forward pass with gradient accumulation scaling\n                with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n                    logits = model(images)\n\n                    # Debug: verify ImageNet normalization on first batch of first epoch\n                    if epoch == 0 and batch_idx == 0:\n                        print(f\"üîç NORM CHECK - Input to model: range [{images.min():.3f}, {images.max():.3f}], mean {images.float().mean():.3f}\")\n                        # Extract 3 center slices like the model does\n                        center = images.shape[1] // 2\n                        x_3ch = images[:, center-1:center+2, :, :]\n                        # Apply ImageNet normalization (3 channels RGB)\n                        mean = torch.tensor([0.485, 0.456, 0.406], device=images.device).view(1, 3, 1, 1)\n                        std = torch.tensor([0.229, 0.224, 0.225], device=images.device).view(1, 3, 1, 1)\n                        x_norm = (x_3ch.float() - mean) / std\n                        print(f\"üîç NORM CHECK - After ImageNet norm (3-ch RGB): range [{x_norm.min():.3f}, {x_norm.max():.3f}], mean {x_norm.float().mean():.3f}\")\n                    \n                    primary_loss = compute_primary_loss(logits, labels, criterion)\n                    if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                        hier_pen = compute_hierarchical_penalty(logits)\n                        loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n                    else:\n                        loss = primary_loss\n                    \n                    # Scale loss for gradient accumulation\n                    loss = loss / grad_accum_steps\n\n                # Backward pass\n                if Config.MIXED_PRECISION:\n                    scaler.scale(loss).backward()\n                else:\n                    loss.backward()\n\n                # Optimizer step only after accumulating gradients\n                if (batch_idx + 1) % grad_accum_steps == 0:\n                    if Config.MIXED_PRECISION:\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        optimizer.step()\n                    \n\n                train_loss += loss.item() * grad_accum_steps  # Unscale for logging\n                \n                # Track GPU active time\n                iter_end = time.time()\n                gpu_active_time += (iter_end - iter_start)\n                last_gpu_check = iter_end\n            train_loss /= max(1, len(train_loader))\n            t_train = time.time() - t0                         \n            \n            # GPU utilization report\n            total_time = gpu_active_time + gpu_idle_time\n            if total_time > 0:\n                gpu_util_pct = (gpu_active_time / total_time) * 100\n                print(f\"‚ö° GPU Utilization: {gpu_util_pct:.1f}% | Active: {gpu_active_time/60:.1f}min | Idle: {gpu_idle_time/60:.1f}min\")\n\n            # DEBUG: Check if model is learning\n            print(f\"üîç DEBUG - Epoch {epoch+1}: Train Loss = {train_loss:.4f}\")\n            \n            # Validation: run either fast or full (not both)\n            current_state = None\n            if use_ema and ema_state is not None:\n                current_state = {k: (v.detach().cpu() if torch.is_tensor(v) else v) for k, v in model.state_dict().items()}\n                try:\n                    model.load_state_dict(ema_state, strict=False)\n                except Exception:\n                    pass\n\n            do_full = False\n            if getattr(Config, 'RUN_FULL_ON_EPOCH_1', False) and (epoch == 0):\n                do_full = True\n            elif (epoch + 1) % int(getattr(Config, 'FULL_VAL_EVERY', 3)) == 0:\n                do_full = True\n\n            # Disable encoder/backbone checkpointing for eval (faster)\n            had_gc = False\n            core_tmp = model.module if isinstance(model, nn.DataParallel) else model\n            enc_tmp = getattr(core_tmp, 'encoder', None)\n            if enc_tmp is None:\n                enc_tmp = getattr(core_tmp, 'backbone', None)\n            if enc_tmp is not None and hasattr(enc_tmp, 'set_grad_checkpointing'):\n                try:\n                    enc_tmp.set_grad_checkpointing(False)\n                    had_gc = True\n                except Exception:\n                    had_gc = False\n\n            if do_full:\n                val_loss, val_auc = _run_validation(\n                    model, val_loader_full, criterion, Config.DEVICE,\n                    max_tokens=int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384))\n                )\n                full_val_metrics = (val_loss, val_auc)\n            else:\n                if val_loader_fast is None:\n                    val_loader_fast = build_fast_val_loader(val_dataset)\n                val_loss, val_auc = _run_validation(\n                    model, val_loader_fast, criterion, Config.DEVICE,\n                    max_tokens=int(getattr(Config, 'FAST_VAL_MAX_TOKENS', 256))\n                )\n\n            # Restore encoder/backbone checkpointing\n            if had_gc and enc_tmp is not None and hasattr(enc_tmp, 'set_grad_checkpointing'):\n                try:\n                    enc_tmp.set_grad_checkpointing(True)\n                except Exception:\n                    pass\n\n            # Restore non-EMA weights\n            if current_state is not None:\n                try:\n                    model.load_state_dict(current_state, strict=False)\n                except Exception:\n                    pass\n\n            t_total = time.time() - t0            \n            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n            print(f\"[Timing] epoch={epoch+1} | train={t_train/60:.2f} min | val_type={'full' if do_full else 'fast'} | epoch_total={t_total/60:.2f} min\")            \n            \n            # Save best model + early stopping (CPU-only tensors). Track best FULL AUC.\n            if (do_full and (val_auc > best_full_auc)) or (not do_full and best_full_auc < 0 and val_auc > best_auc):\n                if do_full:\n                    best_full_auc = val_auc\n                best_auc = val_auc\n                no_improve = 0\n                if use_ema and ema_state is not None:\n                    best_state_cpu = {k: v.detach().cpu().clone() for k, v in ema_state.items()}\n                else:\n                    best_state_cpu = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n                # MIL-only naming and robust atomic save under /kaggle/working\n                arch_name = 'mil'\n                model_filename = f'stage2_{arch_name}_fold_{fold}_best.pth'\n                save_dir = '/kaggle/working'\n                try:\n                    os.makedirs(save_dir, exist_ok=True)\n                except Exception:\n                    pass\n                final_path = os.path.join(save_dir, model_filename)\n                # Save full checkpoint (Model + optimizer + mnetadata)\n                ckpt = {\n                    'model_state_dict': best_state_cpu,\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'val_auc': val_auc,\n                    'epoch': epoch,\n                    'fold': fold,\n                    'architecture': 'mil2p5d',\n                }\n                try:\n                    with open(final_path, 'wb') as f:\n                        torch.save(ckpt, f, _use_new_zipfile_serialization=False)\n                    print(f\"üíæ Saved best model: {final_path} (AUC: {val_auc:.4f})\")\n                except Exception as e:\n                    print(f\"‚ùå Checkpoint save failed: {e}\")\n            else:\n                no_improve += 1\n                if do_full and no_improve >= patience:\n                    print(f\"‚èπÔ∏è Early stopping (patience={patience}) at epoch {epoch+1}\")\n                    break\n\n            # EMA update (compute on CPU tensors)\n            if use_ema and ema_state is not None:\n                with torch.no_grad():\n                    for k, v in model.state_dict().items():\n                        if k in ema_state and isinstance(v, torch.Tensor) and torch.is_floating_point(v):\n                            tgt = ema_state[k]\n                            ema_state[k] = tgt.mul(ema_decay).add(\n                                v.detach().float().cpu(),\n                                alpha=(1.0 - ema_decay),\n                            )\n            train_loss /= max(1, len(train_loader))\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n        \n        fold_scores.append(best_auc)\n        print(f\"Fold {fold + 1} best AUC: {best_auc:.4f}\")\n    \n    # Final results\n    mean_cv_score = np.mean(fold_scores)\n    print(f\"\\n‚úÖ Cross-validation complete!\")\n    print(f\"Mean CV AUC: {mean_cv_score:.4f} ¬± {np.std(fold_scores):.4f}\")\n    print(f\"Individual fold scores: {fold_scores}\")\n\nprint(\"‚úÖ Training pipeline loaded\")\n\n# ====================================================\n# CELL 5: INFERENCE & SUBMISSION\n# ====================================================\n\nclass InferenceConfig:\n    \"\"\"Configuration for inference server\"\"\"\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n\n\n# ===============================\n# Inference-time TTA helpers\nNAME_TO_IDX = {name: i for i, name in enumerate(Config.LABEL_COLS)}\nLR_PAIRS = [\n    (\"Left Infraclinoid Internal Carotid Artery\", \"Right Infraclinoid Internal Carotid Artery\"),\n    (\"Left Supraclinoid Internal Carotid Artery\", \"Right Supraclinoid Internal Carotid Artery\"),\n    (\"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\"),\n    (\"Left Anterior Cerebral Artery\", \"Right Anterior Cerebral Artery\"),\n    (\"Left Posterior Communicating Artery\", \"Right Posterior Communicating Artery\"),\n]\nUNI_CLASSES = [\n    \"Anterior Communicating Artery\", \"Basilar Tip\", \"Other Posterior Circulation\", \"Aneurysm Present\"\n]\n\ndef swap_lr_logits(logits: torch.Tensor) -> torch.Tensor:\n    # logits: (B, C)\n    logits = logits.clone()\n    for L, R in LR_PAIRS:\n        li, ri = NAME_TO_IDX[L], NAME_TO_IDX[R]\n        tmp = logits[..., li].clone()\n        logits[..., li] = logits[..., ri]\n        logits[..., ri] = tmp\n    return logits\n\ndef predict_with_tta(models: list, x: torch.Tensor, model_weights: list = None) -> torch.Tensor:\n    # x: (B,32,H,W) in [0,1]\n    # model_weights: optional list of weights for weighted ensemble\n    # Enable TTA: optionally horizontal flip\n    logits_models = []\n    amp_enabled = bool(getattr(Config, 'MIXED_PRECISION', True) and x.is_cuda)\n    with torch.no_grad(), torch.cuda.amp.autocast(enabled=amp_enabled):\n        for m in models:\n            # Original image\n            z_orig = m(x.to(memory_format=torch.channels_last))\n            if getattr(Config, 'INF_TTA_HFLIP', False):\n                # Horizontal flip TTA\n                x_flip = torch.flip(x, dims=[-1])  # flip width\n                z_flip = m(x_flip.to(memory_format=torch.channels_last))\n                z_flip = swap_lr_logits(z_flip)  # swap L/R predictions back\n                z = (z_orig + z_flip) / 2.0\n            else:\n                z = z_orig\n            logits_models.append(z)\n    \n    # Weighted or simple averaging\n    if model_weights and len(model_weights) == len(logits_models):\n        # Weighted ensemble\n        weights_tensor = torch.tensor(model_weights, device=x.device, dtype=torch.float32)\n        weights_tensor = weights_tensor / weights_tensor.sum()  # Normalize to sum to 1\n        logits = sum(w * logit for w, logit in zip(weights_tensor, logits_models))\n    else:\n        # Simple average (equal weights)\n        logits = torch.stack(logits_models, dim=0).mean(0)\n    \n    return torch.sigmoid(logits)\n\n\nclass ModelEnsemble:\n    \"\"\"Ensemble of Stage 2 models for inference\"\"\"\n    def __init__(self, model_paths, device):\n        self.device = device\n        self.models = []\n        self.model_weights = []  # Track weights for weighted ensemble\n        \n        for path in model_paths:\n            try:\n                # MIL2p5D-only ensemble\n                model = MIL2p5D(num_classes=len(Config.LABEL_COLS), spatial_size=256).to(device)\n                weight = 1.0\n                checkpoint = torch.load(path, map_location=device, weights_only=False)\n                # Robustly extract state dict\n                state_dict = None\n                if isinstance(checkpoint, dict):\n                    for key in ('model', 'model_state_dict', 'state_dict'):\n                        if key in checkpoint and isinstance(checkpoint[key], dict):\n                            state_dict = checkpoint[key]\n                            break\n                    if state_dict is None:\n                        # Some checkpoints save raw weights at top-level\n                        if all(isinstance(v, torch.Tensor) for v in checkpoint.values()):\n                            state_dict = checkpoint\n                if state_dict is None:\n                    raise RuntimeError('Unsupported checkpoint format')\n                \n                # Handle DataParallel wrapper\n                if any(key.startswith('module.') for key in state_dict.keys()):\n                    state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n                # Strict load first; if it fails, relax\n                try:\n                    model.load_state_dict(state_dict, strict=True)\n                except Exception:\n                    model.load_state_dict(state_dict, strict=False)\n                model.eval()\n                try:\n                    model = model.to(memory_format=torch.channels_last)\n                except Exception:\n                    pass\n                self.models.append(model)\n                self.model_weights.append(weight)\n                print(f\"Loaded model: {path} (type=MIL2p5D, weight={weight})\")\n            except Exception as e:\n                print(f\"Error loading {path}: {e}\")\n        \n        # Print ensemble summary\n        print(f\"Loaded {len(self.models)} models for ensemble\")\n        if self.model_weights:\n            total_weight = sum(self.model_weights)\n            print(f\"Total ensemble weight: {total_weight:.1f}\")\n    \n    def predict_single(self, series_path):\n        \"\"\"Predict by building a 32x384x384 volume directly from DICOMs using shared preprocessor.\"\"\"\n        vol = process_dicom_series_safe(series_path, target_shape=(32,384,384))\n        x = torch.from_numpy(vol).unsqueeze(0)  # [1,32,384,384]\n        # Ensure dtype matches FP32 weights; AMP will downcast compute where safe\n        x = x.to(device=self.device, dtype=torch.float32, non_blocking=True)\n        try:\n            x = x.to(memory_format=torch.channels_last)\n        except Exception:\n            pass\n        # Vectorized TTA across models (logit averaging with L<->R swap for H-flip)\n        probs = predict_with_tta(self.models, x).cpu().numpy()[0]\n        return probs\n\nclass InferenceDICOMProcessor:\n    \"\"\"DICOM processor for inference\"\"\"\n    def __init__(self):\n        pass\n\n# Global variables for model ensemble\nmodel_ensemble = None\nprocessor = None\n\ndef initialize_models():\n    \"\"\"Initialize models - called once at startup\"\"\"\n    global model_ensemble, processor\n    \n    print(\"Initializing models...\")\n    \n    # Restrict candidates to provided MODEL_DIRS only\n    # Support both old and new naming conventions\n    candidate_names = [\n        'stage2_mil_fold_0_best.pth', 'stage2_mil_fold_1_best.pth',\n        'stage2_mil_fold_2_best.pth', 'stage2_mil_fold_3_best.pth',\n        'stage2_mil_fold_4_best.pth',\n    ]\n    available_models = []\n    for d in getattr(Config, 'MODEL_DIRS', []):\n        if not isinstance(d, str) or not len(d):\n            continue\n        for name in candidate_names:\n            p = os.path.join(d, name)\n            if os.path.exists(p):\n                available_models.append(p)\n    \n    if not available_models:\n        print(\"Warning: No trained models found! Using dummy predictions.\")\n        model_ensemble = None\n    else:\n        try:\n            model_ensemble = ModelEnsemble(available_models, InferenceConfig.DEVICE)\n            print(\"Models initialized successfully!\")\n        except Exception as e:\n            print(f\"Error initializing models: {e}\")\n            model_ensemble = None\n    \n    processor = InferenceDICOMProcessor()\n\ndef predict(series_path: str) -> pl.DataFrame:\n    \"\"\"Make predictions for the competition API\"\"\"\n    global model_ensemble, processor\n    \n    # Initialize models on first call (lazy loading)\n    if model_ensemble is None and processor is None:\n        initialize_models()\n    \n    series_id = os.path.basename(series_path)\n    \n    try:\n        if model_ensemble is not None:\n            # Use trained ensemble\n            predictions = model_ensemble.predict_single(series_path)\n        else:\n            # Fallback: extract metadata and make informed dummy predictions\n            print(f\"Using fallback prediction for {series_id}\")\n            \n            # Load DICOM metadata\n            all_filepaths = []\n            for root, _, files in os.walk(series_path):\n                for file in files:\n                    if file.endswith('.dcm'):\n                        all_filepaths.append(os.path.join(root, file))\n            \n            if all_filepaths:\n                ds = pydicom.dcmread(all_filepaths[0], force=True)\n                modality = getattr(ds, 'Modality', 'UNKNOWN')\n                \n                # Slightly better informed predictions based on modality\n                if modality in ['CTA', 'MRA']:\n                    # Vascular imaging - slightly higher probability\n                    base_prob = 0.1\n                else:\n                    # Other modalities - lower baseline\n                    base_prob = 0.05\n                \n                # Add some noise to make predictions more realistic\n                predictions = np.random.normal(base_prob, 0.02, len(InferenceConfig.LABEL_COLS))\n                predictions = np.clip(predictions, 0.001, 0.999)\n            else:\n                # No DICOM files found\n                predictions = np.full(len(InferenceConfig.LABEL_COLS), 0.5)\n\n        # Ensure predictions is numpy array and convert to list safely\n        if not isinstance(predictions, np.ndarray):\n            predictions = np.array(predictions)\n        \n        # Create prediction DataFrame\n        prediction_df = pl.DataFrame(\n            data=[[series_id] + predictions.tolist()],\n            schema=[InferenceConfig.ID_COL, *InferenceConfig.LABEL_COLS],\n            orient='row',\n        )\n        \n    except Exception as e:\n        print(f\"Error processing {series_id}: {e}\")\n        # Return safe default predictions\n        prediction_df = pl.DataFrame(\n            data=[[series_id] + [0.5] * len(InferenceConfig.LABEL_COLS)],\n            schema=[InferenceConfig.ID_COL, *InferenceConfig.LABEL_COLS],\n            orient='row',\n        )\n    \n    # IMPORTANT: Remove SeriesInstanceUID before returning (API requirement)\n    prediction_df = prediction_df.drop(InferenceConfig.ID_COL)\n    \n    # IMPORTANT: Disk cleanup to prevent \"out of disk space\" errors\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    \n    return prediction_df\n\n\n# ====================================================\n# SERVER EXECUTION\n# ====================================================\n\n# Initialize the inference server\ninference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nprint(\"‚úÖ Inference and submission pipeline loaded\")\n\n# ====================================================\n# CELL 6: MAIN EXECUTION\n# ====================================================\n\nif __name__ == \"__main__\":\n    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n        # Production mode - serve the API\n        print(\"Starting inference server...\")\n        inference_server.serve()\n    else:\n        # Local/dev mode - default to inference only unless explicitly enabled\n        print(\"Ready for Stage 2 training!\")\n        print(\"Set Config.TRAIN_ON_START=True to run training.\")\n        if getattr(Config, 'TRAIN_ON_START', False):\n            main_training()\n        \n        # Or run local testing\n        print(\"Running local gateway for testing...\")\n        inference_server.run_local_gateway()\n        \n        # Display results if available + sanity checks + CSV\n        results_path = '/kaggle/working/submission.parquet'\n        if os.path.exists(results_path):\n            results_df = pl.read_parquet(results_path)\n\n            # GO / NO-GO checks\n            import pandas as pd\n            pdf = results_df.to_pandas()\n            expected_label_cols = list(Config.LABEL_COLS)\n            id_col = getattr(Config, 'ID_COL', 'SeriesInstanceUID')\n            if id_col in pdf.columns:\n                expected_cols = [id_col] + expected_label_cols\n                # Reorder to expected order if needed\n                pdf = pdf[expected_cols]\n            else:\n                expected_cols = expected_label_cols\n            assert list(pdf.columns) == expected_cols, (\n                f\"Column mismatch.\\nExpected ({len(expected_cols)}): {expected_cols}\\n\"\n                f\"Got ({len(pdf.columns)}): {list(pdf.columns)}\"\n            )\n            # Validate only label columns for NaNs and range\n            label_pdf = pdf[expected_label_cols]\n            assert not label_pdf.isna().any().any(), \"Submission contains NaNs.\"\n            vmin, vmax = label_pdf.to_numpy().min(), label_pdf.to_numpy().max()\n            assert 0.0 <= vmin <= 1.0 and 0.0 <= vmax <= 1.0, (\n                f\"Out-of-range probabilities: min={vmin}, max={vmax}\"\n            )\n            test_meta = '/kaggle/working/test_series.parquet'\n            if os.path.exists(test_meta):\n                test_n = int(pl.read_parquet(test_meta).height)\n                assert len(pdf) == test_n, f\"Row count mismatch: got {len(pdf)}, expected {test_n}\"\n\n            print(\"Submission preview:\")\n            print(results_df.head())\n            out_csv = '/kaggle/working/submission.csv'\n            pdf.to_csv(out_csv, index=False)\n            print(f\"üíæ Saved: {out_csv}\")\n        else:\n            print(\"‚ö†Ô∏è submission.parquet not found. Did inference write it?\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:59:00.971961Z","iopub.execute_input":"2025-11-04T19:59:00.972251Z","iopub.status.idle":"2025-11-04T19:59:11.978361Z","shell.execute_reply.started":"2025-11-04T19:59:00.972228Z","shell.execute_reply":"2025-11-04T19:59:11.977457Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Configuration loaded - Device: cuda\n‚úÖ Data loading and ROI extraction functions loaded\n‚úÖ Model definition loaded\n‚úÖ Training pipeline loaded\n‚úÖ Inference and submission pipeline loaded\nReady for Stage 2 training!\nSet Config.TRAIN_ON_START=True to run training.\nüöÄ STAGE 2: ANEURYSM CLASSIFICATION\nüì¶ Data: Loading .npz shards directly (64x384x384x4 uint8)\n‚úÖ Applied exclusions from /kaggle/input/excluded-series/exclusions.csv: removed 398 series; using 3950\nTraining samples: 3950\nAneurysm cases: 1755\nClass weights: tensor([20.0000, 20.0000, 11.6603, 14.0190, 18.4581, 13.2599, 10.4162, 20.0000,\n        20.0000, 20.0000, 20.0000, 20.0000, 20.0000, 16.2593])\n\n==================================================\nFOLD 1/5\n==================================================\nTrain samples: 3160, Val samples: 790\nüîç DATASET TYPE: AneurysmClassificationDataset\nüîç DATA CHECK SKIPPED (direct index failed): Subclasses of Dataset should implement __getitem__.\nüîç CLASS DISTRIBUTION - Aneurysm Present: 1404/3160 (44.4%)\n  Left Infraclinoid Internal Carotid Artery: 61 positives\n  Right Infraclinoid Internal Carotid Artery: 80 positives\n  Left Supraclinoid Internal Carotid Artery: 247 positives\n  Right Supraclinoid Internal Carotid Artery: 200 positives\n  Left Middle Cerebral Artery: 167 positives\n  Right Middle Cerebral Artery: 219 positives\n  Anterior Communicating Artery: 284 positives\n  Left Anterior Cerebral Artery: 34 positives\n  Right Anterior Cerebral Artery: 46 positives\n  Left Posterior Communicating Artery: 65 positives\n  Right Posterior Communicating Artery: 76 positives\n  Basilar Tip: 74 positives\n  Other Posterior Circulation: 89 positives\n  Aneurysm Present: 1404 positives\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/461818973.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2747\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Set Config.TRAIN_ON_START=True to run training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TRAIN_ON_START'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2749\u001b[0;31m             \u001b[0mmain_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2751\u001b[0m         \u001b[0;31m# Or run local testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/461818973.py\u001b[0m in \u001b[0;36mmain_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m         \u001b[0;31m# Create loaders (tuned for throughput)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m         train_loader = DataLoader(\n\u001b[0m\u001b[1;32m   2120\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python.data_loader\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             raise ValueError(\n\u001b[1;32m    262\u001b[0m                 \u001b[0;34m\"num_workers option should be non-negative; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"],"ename":"TypeError","evalue":"'<' not supported between instances of 'NoneType' and 'int'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}