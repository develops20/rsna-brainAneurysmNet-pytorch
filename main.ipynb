{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"},{"sourceId":13227044,"sourceType":"datasetVersion","datasetId":8238970},{"sourceId":13227074,"sourceType":"datasetVersion","datasetId":8238986},{"sourceId":13227099,"sourceType":"datasetVersion","datasetId":8239003},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656,"modelId":312},{"sourceId":3730,"sourceType":"modelInstanceVersion","modelInstanceId":2657,"modelId":312},{"sourceId":3732,"sourceType":"modelInstanceVersion","modelInstanceId":2659,"modelId":312},{"sourceId":599416,"sourceType":"modelInstanceVersion","modelInstanceId":449026,"modelId":465429}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# CELL 1: IMPORTS & CONFIG\n# ====================================================\n\nimport os\n# Mitigate CUDA memory fragmentation (must be set before torch import)\nos.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\nimport shutil\nimport math\nimport time\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport timm\nimport cv2\nimport pydicom\nimport nibabel as nib\nfrom scipy import ndimage\nfrom scipy.ndimage import label, center_of_mass\nfrom PIL import Image\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\nfrom sklearn.metrics import roc_auc_score\nimport kaggle_evaluation.rsna_inference_server\nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\n\n# Thread limits for Kaggle (idempotent & safe)\ntry:\n    import cv2 as _cv2_for_threads\n    try:\n        _cv2_for_threads.setNumThreads(0)\n    except Exception:\n        pass\nexcept Exception:\n    pass\ntry:\n    os.environ.setdefault('OMP_NUM_THREADS', '1')\n    os.environ.setdefault('MKL_NUM_THREADS', '1')\n    torch.set_num_threads(1)\nexcept Exception:\n    pass\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Competition Configuration\nclass Config:\n    # Paths\n    TRAIN_CSV_PATH = '/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\n    SERIES_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/'\n    SEGMENTATION_DIR = '/kaggle/input/rsna-intracranial-aneurysm-detection/segmentations/'\n    \n    # Stage 2 Configuration\n    ROI_SIZE = (224, 224)\n    ROIS_PER_SERIES = 5\n    BATCH_SIZE = 8  # Smaller batch = more gradient updates per epoch (434 vs 217 steps)\n    VAL_BATCH_SIZE = 8  # Match training batch size\n    GRAD_ACCUM_STEPS = 6  # Effective batch size: 8 × 6 = 48 (maintain throughput)\n    VAL_MAX_ENCODER_TOKENS = 384\n    EPOCHS = 3  # QUICK TEST: Verify predictions are varying before full run\n    LEARNING_RATE = 2e-4  # EVEN HIGHER: Strong signal to break uniform predictions\n    N_FOLDS = 1  # SINGLE FOLD TEST: Fast verification (~40 min)\n    \n    # Competition constants\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n    \n    # Device and training\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    MIXED_PRECISION = True\n    MICRO_BATCH_SIZE = 8  # MATCH batch size\n    AUTO_TUNE_MICRO = False  # DISABLED: Can cause hanging with DataLoader workers\n    SLICE_SUBSAMPLE_TRAIN = 0  # DISABLED: Model expects fixed 32 slices (24 causes shape mismatch)\n    STAGE2_CACHE_DIR = '/kaggle/working/stage2_cache'\n    DEBUG_MODE = False\n    DEBUG_SAMPLES = 0\n    REUSE_EXISTING_ROIS = True  # if cached training_df exists, reuse to skip long ROI extraction\n    DIRECT_VOLUME_MODE = True   # Direct volume mode (top_example-style) using Stage 0 32x384x384 volumes\n    # STAGE0_PREBUILT_ROOT = '/kaggle/input/rsna2025-v2-intracranial-aneurysm-detection-nb153/stage1_AneurysmNet_prebuilt_v2'\n    NUM_WORKERS = 4 #12\n    PREFETCH_FACTOR = 2 #8\n    PIN_MEMORY = True\n    PERSISTENT_WORKERS = True\n    CACHE_VOLUMES = True\n    USE_SHARD_LOADER = False  # DISABLED: Load .npz shards directly, not via shard_loader.py wrapper\n    CACHE_DIR = ''  # disable single-dir cache\n    CACHE_DIRS = [\n        '/kaggle/input/rsna2025-shard0-fp16nb153/stage2_cache_vols',\n        '/kaggle/input/rsna2025-shard1-fp16nb153/stage2_cache_vols',\n        '/kaggle/input/rsna2025-shard2-fp16nb153/stage2_cache_vols',\n    ]\n    CACHE_DTYPE = 'float16'  # use higher-fidelity cache\n    CACHE_VERBOSE = False  # set True to log cache hits/writes/skips\n    CACHE_LOG_EVERY_N = 100\n\n    # Shard loading configuration\n    SHARD_CHANNEL_MODE = 'cta'  # 'cta' for rsna2p5d, 'best3' for mil2p5d\n    SHARD_DEPTH_SAMPLING = 'uniform'  # 'uniform', 'center_weighted', 'interpolate'\n    SHARD_TARGET_SPATIAL = (384, 384)  # Will be overridden to (320, 320) for mil2p5d\n    MODEL_DIRS = [ \n        '/kaggle/working',  # Where models are saved during training        \n        #'/kaggle/input/rsna2025-stage2-5fold-32ch-f16/pytorch/default/3'\n    ]\n    # Control training in local/dev mode\n    TRAIN_ON_START = True\n    # Early stopping\n    EARLY_STOPPING_PATIENCE = 3\n\n    # Validation schedule (fast vs full)\n    FAST_VAL = True\n    FAST_VAL_EVERY = 1\n    FULL_VAL_EVERY = 3\n    RUN_FULL_ON_EPOCH_1 = False\n    FAST_VAL_SUBSET_FRAC = 0.33\n    FAST_VAL_MAX_TOKENS = 256\n    FAST_VAL_IMPROVE_EPS = 0.002\n\n    # Architecture selection: 'rsna2p5d' or 'mil2p5d'\n    MODEL_ARCH = 'mil2p5d'  # SESSION 1: RSNA2P5D Training\n\n    # MIL transformer params - OPTIMIZED FOR SPEED\n    # Competition-winning approach: Balance speed vs quality\n    MIL_BACKBONE = 'tf_efficientnet_b0'  # B0 is 3-4x faster than B3, minimal quality loss\n    MIL_SPATIAL_SIZE = 224  # Reduced from 320 to 224 (2x faster, medical models tolerate this)\n    MIL_D_MODEL = 512  # Reduced from 768 (faster attention, still competitive)\n    MIL_NHEAD = 8\n    MIL_N_LAYERS = 2  # Keep at 2 for balance\n    MIL_USE_GRAD_CHECKPOINT = True  # Saves VRAM, allows larger batches\n    MIL_COMPILE_ENCODER = False  # Set True if PyTorch >= 2.0 available\n\n    # Training extras\n    USE_WEIGHTED_SAMPLER = False\n    USE_EMA = False \n    EMA_DECAY = 0.999\n\n    # Hierarchical consistency loss (sites <= \"Aneurysm Present\")\n    ENABLE_HIER_LOSS = False\n    HIER_LOSS_LAMBDA = 0.2\n\n    # Asymmetric Loss (ASL) for site logits\n    USE_ASL = False\n    ASL_GAMMA_POS = 0.0\n    ASL_GAMMA_NEG = 4.0\n    ASL_CLIP = 0.05\n    ASL_WEIGHT_SITES = 1.0\n    MAIN_BCE_WEIGHT = 1.0\n    \n    # Class weight cap (prevent extreme weights like 93.5)\n    CLASS_WEIGHT_CAP = 20.0  # ENABLED: Allow class weights for imbalanced data (capped at 30)\n    # This lets pos_weight reflect true imbalance (rare sites + 13× \"Aneurysm Present\")\n\nprint(f\"✅ Configuration loaded - Device: {Config.DEVICE}\")\n\n# Speed-friendly backend settings\ntry:\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.set_float32_matmul_precision('high')\nexcept Exception:\n    pass\n    \n# ====================================================\n# CELL 1.1: LIGHTWEIGHT DICOM PREPROCESSOR (32x384x384)\n# ====================================================\n\nclass DICOMPreprocessorKaggle:\n    \"\"\"Minimal, memory-safe DICOM → (32,384,384) volume preprocessor (offline, no deps).\"\"\"\n    def __init__(self, target_shape=(32, 384, 384)):\n        self.target_depth, self.target_height, self.target_width = target_shape\n\n    def process_series(self, series_path: str) -> np.ndarray:\n        sid = os.path.basename(series_path.rstrip('/'))\n        \n        # Load .npz shards directly (64, 384, 384, 4) uint8\n        if getattr(Config, 'CACHE_VOLUMES', False):\n            for cache_dir in getattr(Config, 'CACHE_DIRS', []):\n                if not isinstance(cache_dir, str) or not len(cache_dir):\n                    continue\n                npz_path = os.path.join(cache_dir, f\"{sid}.npz\")\n                if os.path.exists(npz_path):\n                    try:\n                        # Load compressed .npz (memory-mapped for speed)\n                        data = np.load(npz_path)\n                        vol_u8 = data['vol']  # (64, 384, 384, 4) uint8\n                        \n                        # Extract CTA channel (channel 0) for rsna2p5d\n                        vol_u8_cta = vol_u8[..., 0]  # (64, 384, 384)\n                        \n                        # Downsample from 64 to 32 slices (uniform sampling)\n                        indices = np.linspace(0, vol_u8_cta.shape[0] - 1, self.target_depth).astype(np.int32)\n                        vol_u8_32 = vol_u8_cta[indices]  # (32, 384, 384)\n                        \n                        # Convert uint8 [0,255] to float [0,1]\n                        if getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16':\n                            vol = (vol_u8_32.astype(np.float16)) / 255.0\n                        else:\n                            vol = (vol_u8_32.astype(np.float32)) / 255.0\n                        \n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[NPZ] Loaded {sid} from {os.path.basename(cache_dir)}\")\n                        \n                        return vol\n                    except Exception as e:\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[NPZ] Error loading {npz_path}: {e}\")\n                        continue\n        \n        # OLD: Fallback to legacy _f16.npy cache format\n        if getattr(Config, 'CACHE_VOLUMES', False):\n            try:\n                # Build a read list: prefer shard dirs then single CACHE_DIR\n                read_dirs = []\n                if isinstance(getattr(Config, 'CACHE_DIRS', []), list) and len(Config.CACHE_DIRS) > 0:\n                    read_dirs.extend([d for d in Config.CACHE_DIRS if isinstance(d, str) and len(d)])\n                if isinstance(getattr(Config, 'CACHE_DIR', ''), str) and len(Config.CACHE_DIR):\n                    read_dirs.append(Config.CACHE_DIR)\n                # For each dir, try float16 only (no uint8 fallback)\n                hit_count = getattr(self, '_cache_hit_count', 0)\n                for d in read_dirs:\n                    cache_base = os.path.join(d, f\"{sid}_32x384x384\")\n                    cache_path_try = cache_base + '_f16.npy'\n                    if os.path.exists(cache_path_try):\n                        cached = np.load(cache_path_try, mmap_mode='r')\n                        # Keep FP16 on CPU to reduce bandwidth\n                        if cached.dtype == np.float16 or getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16':\n                            vol = cached.astype(np.float16)\n                        else:\n                            vol = cached.astype(np.float32)\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            hit_count += 1\n                            self._cache_hit_count = hit_count\n                            if hit_count % max(1, getattr(Config, 'CACHE_LOG_EVERY_N', 50)) == 0:\n                                print(f\"[CACHE] hit: {d}/{os.path.basename(cache_path_try)}\")\n                        return vol\n            except Exception:\n                cache_path = None\n        # Collect DICOMs\n        dicoms = []\n        for root, _, files in os.walk(series_path):\n            for f in files:\n                if f.endswith('.dcm'):\n                    try:\n                        ds = pydicom.dcmread(os.path.join(root, f), force=True)\n                        if hasattr(ds, 'PixelData'):\n                            dicoms.append(ds)\n                    except Exception:\n                        continue\n        if len(dicoms) == 0:\n            return np.zeros((self.target_depth, self.target_height, self.target_width), dtype=np.float32)\n\n        # Sort by patient-space normal if possible, else by InstanceNumber\n        try:\n            orient = np.array(dicoms[0].ImageOrientationPatient, dtype=np.float32)\n            rowv, colv = orient[:3], orient[3:]\n            normal = np.cross(rowv, colv)\n            def sort_key(ds):\n                ipp = np.array(getattr(ds, 'ImagePositionPatient', [0,0,0]), dtype=np.float32)\n                return float(np.dot(ipp, normal))\n            dicoms = sorted(dicoms, key=sort_key)\n        except Exception:\n            dicoms = sorted(dicoms, key=lambda ds: getattr(ds, 'InstanceNumber', 0))\n\n        base_h = int(getattr(dicoms[0], 'Rows', 256))\n        base_w = int(getattr(dicoms[0], 'Columns', 256))\n        c, w = 50.0, 350.0\n        lo, hi = c - w/2.0, c + w/2.0\n        modality = (getattr(dicoms[0], 'Modality', '') or '').upper()\n\n        slices = []\n        for ds in dicoms:\n            try:\n                fr = ds.pixel_array\n            except Exception:\n                continue\n            if fr.ndim >= 3:\n                h, w2 = fr.shape[-2], fr.shape[-1]\n                frames = fr.reshape(int(np.prod(fr.shape[:-2])), h, w2)\n            else:\n                frames = fr[np.newaxis, ...]\n            for sl in frames:\n                sl = sl.astype(np.float32)\n                if getattr(ds, 'PhotometricInterpretation', 'MONOCHROME2') == 'MONOCHROME1':\n                    sl = sl.max() - sl\n                slope = float(getattr(ds, 'RescaleSlope', 1.0)); intercept = float(getattr(ds, 'RescaleIntercept', 0.0))\n                sl = sl * slope + intercept\n                if sl.shape != (base_h, base_w):\n                    sl = cv2.resize(sl, (base_w, base_h))\n                if modality == 'CT':\n                    s = np.clip(sl, lo, hi)\n                    s = (s - lo) / (hi - lo + 1e-6)\n                else:\n                    mean = float(sl.mean()); std = float(sl.std() + 1e-6)\n                    s = (sl - mean) / std; zc = 3.0\n                    s = np.clip(s, -zc, zc); s = (s + zc) / (2.0*zc)\n                slices.append(s.astype(np.float32))\n\n        volf = np.stack(slices, axis=0) if slices else np.zeros((1, base_h, base_w), dtype=np.float32)\n        # Trilinear depth+inplane resampling to (D,H,W)\n        try:\n            v = torch.from_numpy(volf)[None, None].to(dtype=torch.float32)  # (1,1,D,H,W)\n            v = F.interpolate(\n                v,\n                size=(self.target_depth, self.target_height, self.target_width),\n                mode='trilinear',\n                align_corners=False,\n            )\n            out = v[0, 0].numpy().astype(np.float32)\n        except Exception:\n            # Fallback to previous per-slice resize if torch not available\n            D = volf.shape[0]\n            idx = np.linspace(0, max(D-1,0), num=self.target_depth).astype(int) if D>0 else np.zeros(self.target_depth, dtype=int)\n            vT = volf[idx]\n            out = np.empty((self.target_depth, self.target_height, self.target_width), dtype=np.float32)\n            for i in range(self.target_depth):\n                out[i] = cv2.resize(vT[i], (self.target_width, self.target_height))\n        p1, p99 = np.percentile(out, [1, 99])\n        if p99 > p1:\n            out = np.clip(out, p1, p99)\n            out = (out - p1) / (p99 - p1 + 1e-8)\n        out = np.nan_to_num(out, nan=0.0, posinf=1.0, neginf=0.0)\n        # Save cache using configured dtype\n        try:\n            if getattr(Config, 'CACHE_VOLUMES', False):\n                # Respect soft size cap\n                try:\n                    total_bytes = 0\n                    for f in os.listdir(Config.CACHE_DIR):\n                        fp = os.path.join(Config.CACHE_DIR, f)\n                        try:\n                            total_bytes += os.path.getsize(fp)\n                        except Exception:\n                            pass\n                    if total_bytes > Config.CACHE_MAX_GB * (1024**3):\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(\"[CACHE] size cap reached; skip saving\")\n                        raise RuntimeError('Cache size cap reached, skip saving')\n                except Exception:\n                    pass\n                # Ensure cache dir exists and choose dtype and filename suffix\n                os.makedirs(Config.CACHE_DIR, exist_ok=True)\n                sid = os.path.basename(series_path.rstrip('/'))\n                cache_base = os.path.join(Config.CACHE_DIR, f\"{sid}_32x384x384\")\n                dtype_choice = getattr(Config, 'CACHE_DTYPE', 'float16')\n                if dtype_choice == 'uint8':\n                    # Quantize to 8-bit [0,255] after normalization\n                    arr8 = (out * 255.0).round().astype(np.uint8)\n                    # Optional quick verification to ensure acceptable quantization error\n                    try:\n                        diff_max = float(np.max(np.abs(out - (arr8.astype(np.float32) / 255.0))))\n                        if diff_max > 0.02:  # fallback threshold for safety\n                            # Fallback to float16 if quantization too lossy\n                            np.save(cache_base + '_f16.npy', out.astype(np.float16), allow_pickle=False)\n                            if getattr(Config, 'CACHE_VERBOSE', False):\n                                print(f\"[CACHE] wrote f16 (fallback): {os.path.basename(cache_base)}_f16.npy\")\n                        else:\n                            np.save(cache_base + '_u8.npy', arr8, allow_pickle=False)\n                            if getattr(Config, 'CACHE_VERBOSE', False):\n                                print(f\"[CACHE] wrote u8: {os.path.basename(cache_base)}_u8.npy (max_err={diff_max:.4f})\")\n                    except Exception:\n                        np.save(cache_base + '_u8.npy', arr8, allow_pickle=False)\n                        if getattr(Config, 'CACHE_VERBOSE', False):\n                            print(f\"[CACHE] wrote u8 (no-check): {os.path.basename(cache_base)}_u8.npy\")\n                else:\n                    np.save(cache_base + '_f16.npy', out.astype(np.float16), allow_pickle=False)\n                    if getattr(Config, 'CACHE_VERBOSE', False):\n                        print(f\"[CACHE] wrote f16: {os.path.basename(cache_base)}_f16.npy\")\n        except Exception:\n            pass\n        # Return dtype aligned with cache preference for lower CPU bandwidth\n        if getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16':\n            return out.astype(np.float16)\n        else:\n            return out.astype(np.float32)\n\ndef process_dicom_series_safe(series_path: str, target_shape=(32,384,384)) -> np.ndarray:\n    try:\n        pre = DICOMPreprocessorKaggle(target_shape)\n        return pre.process_series(series_path)\n    finally:\n        try:\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        except Exception:\n            pass\n        try:\n            gc.collect()\n        except Exception:\n            pass\n\n\n# ====================================================\n# CELL 2: DATA LOADING & ROI EXTRACTION\n# ====================================================\n\nclass Simple3DSegmentationNet(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        self.dummy = nn.Identity()\n    def forward(self, x):\n        return self.dummy(x)\n\nclass Stage1Predictor:\n    def __init__(self, *args, **kwargs):\n        pass\n    def predict_segmentation_with_volume(self, series_path):\n        # Not used in direct-volume path; kept minimal for compatibility\n        return np.zeros((1,1,1), dtype=np.float32), np.zeros((32,384,384), dtype=np.float32)\n\nclass SimpleDICOMProcessor:\n    def __init__(self, *args, **kwargs):\n        pass\n        \nclass ROIExtractor:\n    \"\"\"Research-backed ROI extraction with adaptive count and quality filtering\"\"\"\n    def __init__(self, stage1_predictor, roi_size=(224, 224)):\n        self.stage1_predictor = stage1_predictor\n        self.roi_size = roi_size\n        self.processor = SimpleDICOMProcessor()\n\n        # Research-backed thresholds\n        # Relaxed thresholds to avoid over-pruning when Stage 1 is weak\n        self.min_confidence_threshold = 0.15\n        self.high_confidence_threshold = 0.5\n        self.max_rois_per_series = getattr(Config, 'ROIS_PER_SERIES', 3)\n        # Post-process controls\n        self.border_margin = 2            # suppress edge activations near skull\n        self.min_region_size = 6         # minimum connected component size (pixels)\n        self.morph_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n\n    def extract_top3_rois(self, series_path):\n        \"\"\"Extract 0-5 ROIs based on segmentation quality (research-backed)\"\"\"\n        # Cache ROI results per series to avoid recomputation\n        try:\n            # Prefer external cache dir when available\n            cache_root = getattr(Config, 'STAGE2_CACHE_EXTERNAL_DIR', '')\n            if not isinstance(cache_root, str) or not os.path.isdir(cache_root):\n                cache_root = Config.STAGE2_CACHE_DIR\n            os.makedirs(cache_root, exist_ok=True)\n            sid = os.path.basename(series_path)\n            cache_path = os.path.join(cache_root, f\"{sid}_rois.npy\")\n            if os.path.exists(cache_path):\n                arr = np.load(cache_path, allow_pickle=True)\n                return list(arr)\n        except Exception:\n            cache_path = None\n        rois = self.extract_adaptive_rois(series_path)\n        try:\n            if cache_path is not None:\n                np.save(cache_path, np.array(rois, dtype=object), allow_pickle=True)\n        except Exception:\n            pass\n        return rois\n\n    def extract_adaptive_rois(self, series_path):\n        \"\"\"Extract 0-5 ROIs based on segmentation quality (research-backed)\"\"\"\n        try:\n            print(f\"🔍 DEBUG: Quality-based ROI extraction for {os.path.basename(series_path)}\")\n            \n            # Get Stage 1 seg mask and the preprocessed volume (avoid reloading original DICOMs here)\n            seg_mask, original_volume = self.stage1_predictor.predict_segmentation_with_volume(series_path)\n            print(f\"🔍 DEBUG: Segmentation mask shape: {seg_mask.shape}; Volume shape: {original_volume.shape}\")\n            \n            # STEP 1: Assess overall segmentation quality\n            seg_quality = self._assess_segmentation_quality(seg_mask)\n            print(f\"🔍 DEBUG: Segmentation quality score: {seg_quality:.3f}\")\n            \n            # STEP 2: If segmentation is poor, still attempt candidate extraction; fallback only if none\n            low_quality = seg_quality < self.min_confidence_threshold\n            if low_quality:\n                print(f\"🔍 DEBUG: Low segmentation quality ({seg_quality:.3f} < {self.min_confidence_threshold}), attempting candidate extraction anyway\")\n            \n            # STEP 4: Extract ROIs with confidence-based filtering\n            roi_candidates = self._find_quality_based_rois(seg_mask, original_volume)\n            \n            if low_quality and not roi_candidates:\n                print(\"🔍 DEBUG: No candidates under low-quality mask, using volume-based fallback\")\n                return self._get_quality_fallback_rois_from_volume(original_volume, self.max_rois_per_series)\n\n            # STEP 5: Adaptive ROI count\n            selected_rois = self._select_adaptive_rois(roi_candidates, seg_quality, original_volume)\n            \n            print(f\"🔍 DEBUG: Selected {len(selected_rois)} ROIs based on quality assessment\")\n            return selected_rois\n            \n        except Exception as e:\n            print(f\"❌ Error in quality-based ROI extraction: {e}\")\n            return self._get_emergency_fallback_rois()\n    \n    def _assess_segmentation_quality(self, seg_mask):\n        \"\"\"Assess segmentation quality using connected components and border penalties.\"\"\"\n        try:\n            D, H, W = seg_mask.shape\n            largest_area_frac = 0.0\n            largest_mean_conf = 0.0\n            total_components = 0\n            border_touch_penalty = 0.0\n\n            for z in range(D):\n                sm = seg_mask[z]\n                # suppress borders\n                sm_proc = sm.copy()\n                sm_proc[:self.border_margin, :] = 0\n                sm_proc[-self.border_margin:, :] = 0\n                sm_proc[:, :self.border_margin] = 0\n                sm_proc[:, -self.border_margin:] = 0\n\n               # Adaptive thresholding based on actual max values\n                max_val = float(sm_proc.max())\n                if max_val > 0.3:\n                    thr = max(0.05, 0.3 * max_val)\n                elif max_val > 0.1:\n                    thr = max(0.03, 0.4 * max_val)\n                else:\n                    thr = max(0.02, 0.5 * max_val)\n                binmask = (sm_proc > thr).astype(np.uint8)\n                if binmask.max() == 0:\n                    continue\n                # small opening to remove speckle\n                binmask = cv2.morphologyEx(binmask, cv2.MORPH_OPEN, self.morph_kernel)\n\n                labeled, n = label(binmask)\n                if n == 0:\n                    continue\n                total_components += int(n)\n\n                # evaluate components\n                for comp_id in range(1, n + 1):\n                    comp = (labeled == comp_id)\n                    comp_size = int(comp.sum())\n                    if comp_size < self.min_region_size:\n                        continue\n                    mean_conf = float(sm[comp].mean())\n                    area_frac = comp_size / float(H * W)\n                    if area_frac > largest_area_frac:\n                        largest_area_frac = area_frac\n                    if mean_conf > largest_mean_conf:\n                        largest_mean_conf = mean_conf\n\n                    # simple border-touch penalty if component abuts image edge\n                    ys, xs = np.where(comp)\n                    if ys.size > 0:\n                        if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                            xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                            border_touch_penalty += 0.02\n\n            # compose quality score\n            area_score = min(largest_area_frac / 0.02, 1.0)  # cap around ~2% of slice (aneurysm-sized)\n            comp_penalty = min(0.1, 0.0015 * total_components) + min(0.1, border_touch_penalty)\n            quality_score = max(0.0, 0.6 * largest_mean_conf + 0.4 * area_score - comp_penalty)\n\n            # robust floor based on global mask stats to avoid spurious 0.0 quality\n            max_val = float(seg_mask.max())\n            mean_val = float(seg_mask.mean())\n            if max_val >= 0.55:\n                quality_score = max(quality_score, 0.35)\n            elif max_val >= 0.45:\n                quality_score = max(quality_score, 0.25)\n            elif mean_val >= 0.25:\n                quality_score = max(quality_score, 0.22)\n\n            return float(quality_score)\n        except Exception:\n            return 0.1\n    \n    def _find_quality_based_rois(self, seg_mask, original_volume):\n        \"\"\"Find ROI candidates with confidence scores (no hardcoded count)\"\"\"\n        print(\"🔍 DEBUG: Finding quality-based ROI candidates...\")\n        \n        # Resize segmentation mask to match original volume\n        if seg_mask.shape != original_volume.shape:\n            print(\"🔍 DEBUG: Resizing segmentation mask with cv2...\")\n            seg_mask_resized = np.zeros(original_volume.shape, dtype=np.float32)\n            for i in range(min(seg_mask.shape[0], original_volume.shape[0])):\n                if i < seg_mask.shape[0]:\n                    resized_slice = cv2.resize(\n                        seg_mask[i],\n                        (original_volume.shape[2], original_volume.shape[1])\n                    )\n                    seg_mask_resized[i] = resized_slice\n        else:\n            seg_mask_resized = seg_mask\n        \n        # 3D peak proposals first (relative peak logic; does not lower thresholds)\n        roi_candidates = self._proposals_from_3d_peaks(seg_mask_resized)\n        if len(roi_candidates) == 0:\n            # Fall back to 2D slice-wise CC method\n            roi_candidates = []\n        \n        H, W = original_volume.shape[1], original_volume.shape[2]\n        for slice_idx in range(seg_mask_resized.shape[0]):\n            slice_mask = seg_mask_resized[slice_idx].copy()\n\n            # Suppress borders to avoid skull/edge activations\n            slice_mask[:self.border_margin, :] = 0\n            slice_mask[-self.border_margin:, :] = 0\n            slice_mask[:, :self.border_margin] = 0\n            slice_mask[:, -self.border_margin:] = 0\n\n            # Adaptive dynamic threshold tied to local max (aligned with quality assessment)\n            max_val = float(slice_mask.max())\n            if max_val > 0.2:\n                thr = max(self.min_confidence_threshold, 0.25 * max_val)\n            elif max_val > 0.1:\n                thr = max(0.03, 0.30 * max_val)\n            else:\n                thr = max(0.02, 0.25 * max_val)\n            high_conf_regions = (slice_mask > thr).astype(np.uint8)\n            if high_conf_regions.max() == 0:\n                # Percentile-based fallback with small dilation to form blobs\n                p90 = float(np.percentile(slice_mask, 90))\n                if p90 > 0:\n                    mask_peaks = (slice_mask >= p90).astype(np.uint8)\n                    # small dilation to merge nearby high pixels\n                    mask_peaks = cv2.dilate(mask_peaks, self.morph_kernel, iterations=1)\n                    labeled_regions, num_regions = label(mask_peaks)\n                    for region_id in range(1, num_regions + 1):\n                        region_mask = (labeled_regions == region_id)\n                        region_size = int(region_mask.sum())\n                        if region_size < 3:\n                            continue\n                        ys, xs = np.where(region_mask)\n                        if ys.size == 0:\n                            continue\n                        # Skip borders\n                        if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                            xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                            continue\n                        com = center_of_mass(region_mask)\n                        y, x = int(com[0]), int(com[1])\n                        region_confidence = float(slice_mask[region_mask].mean())\n                        roi_candidates.append({\n                            'slice_idx': slice_idx,\n                            'y': y,\n                            'x': x,\n                            'confidence': region_confidence,\n                            'region_size': region_size\n                        })\n                continue\n            # Apply opening only if region is sufficiently large; avoid eroding tiny blobs\n            if int(high_conf_regions.sum()) > 50:\n                high_conf_regions = cv2.morphologyEx(high_conf_regions, cv2.MORPH_OPEN, self.morph_kernel)\n\n            labeled_regions, num_regions = label(high_conf_regions)\n            for region_id in range(1, num_regions + 1):\n                region_mask = (labeled_regions == region_id)\n                region_size = int(region_mask.sum())\n                if region_size < self.min_region_size:\n                    continue\n                ys, xs = np.where(region_mask)\n                if ys.size == 0:\n                    continue\n                # Skip border-touching components\n                if (ys.min() <= self.border_margin or ys.max() >= H - self.border_margin - 1 or\n                    xs.min() <= self.border_margin or xs.max() >= W - self.border_margin - 1):\n                    continue\n\n                com = center_of_mass(region_mask)\n                y, x = int(com[0]), int(com[1])\n                region_confidence = float(slice_mask[region_mask].mean())\n\n                roi_candidates.append({\n                    'slice_idx': slice_idx,\n                    'y': y,\n                    'x': x,\n                    'confidence': region_confidence,\n                    'region_size': region_size\n                })\n        \n        # Sort by confidence (descending)\n        if not roi_candidates:\n            # Volume-wise peak fallback: pick top maxima per slice (excluding borders)\n            print(\"🔍 DEBUG: No ROI components found; using volume-wise peak fallback\")\n            D = seg_mask_resized.shape[0]\n            peak_candidates = []\n            for z in range(D):\n                m = seg_mask_resized[z].copy()\n                # suppress borders\n                m[:self.border_margin, :] = 0\n                m[-self.border_margin:, :] = 0\n                m[:, :self.border_margin] = 0\n                m[:, -self.border_margin:] = 0\n                yx = np.unravel_index(np.argmax(m), m.shape)\n                y, x = int(yx[0]), int(yx[1])\n                conf = float(m[y, x])\n                if conf > 0:\n                    peak_candidates.append({\n                        'slice_idx': z,\n                        'y': y,\n                        'x': x,\n                        'confidence': conf,\n                        'region_size': 1\n                    })\n            # Keep strongest few peaks across volume\n            peak_candidates.sort(key=lambda c: c['confidence'], reverse=True)\n            roi_candidates.extend(peak_candidates[: max( self.max_rois_per_series * 3, 6)])\n\n        roi_candidates.sort(key=lambda x: x['confidence'], reverse=True)\n        \n        print(f\"🔍 DEBUG: Found {len(roi_candidates)} ROI candidates\")\n        return roi_candidates\n\n    def _proposals_from_3d_peaks(self, seg_mask_zyx: np.ndarray):\n        \"\"\"3D local-max proposals with seeded relative growth (no absolute threshold lowering).\"\"\"\n        try:\n            D, H, W = seg_mask_zyx.shape\n            # Light 3D smoothing to stabilize local maxima\n            try:\n                sm = ndimage.gaussian_filter(seg_mask_zyx.astype(np.float32), sigma=0.75)\n            except Exception:\n                sm = seg_mask_zyx.astype(np.float32)\n            # 3D local maxima via maximum filter\n            footprint = np.ones((3,3,3), dtype=np.uint8)\n            max_f = ndimage.maximum_filter(sm, footprint=footprint, mode='nearest')\n            peaks = (sm == max_f)\n            # Suppress borders\n            b = self.border_margin\n            if b > 0:\n                peaks[:, :b, :] = False; peaks[:, -b:, :] = False\n                peaks[:, :, :b] = False; peaks[:, :, -b:] = False\n            coords = np.argwhere(peaks)\n            if coords.shape[0] == 0:\n                return []\n            # Rank peaks by value and keep top-K to control cost\n            values = sm[peaks]\n            order = np.argsort(values)[::-1]\n            top_k = min(64, order.size)\n            selected = coords[order[:top_k]]\n            # Non-maximum suppression by 3D distance\n            kept = []\n            min_dist = 4.0\n            for (cz, cy, cx) in selected:\n                if any(((cz-kz)**2 + (cy-ky)**2 + (cx-kx)**2) ** 0.5 < min_dist for kz,ky,kx in kept):\n                    continue\n                kept.append((int(cz), int(cy), int(cx)))\n                if len(kept) >= 64:\n                    break\n            # Seeded relative growth\n            proposals = []\n            for cz, cy, cx in kept:\n                peak = float(sm[cz, cy, cx])\n                if peak <= 0:\n                    continue\n                rel_thr = max(0.6*peak, 1e-6)  # relative to each peak\n                # collect voxels that descend from the peak (thresholded region)\n                region = sm >= rel_thr\n                labeled, num = ndimage.label(region)\n                cid = int(labeled[cz, cy, cx])\n                if cid == 0:\n                    continue\n                comp = (labeled == cid)\n                size = int(comp.sum())\n                if size < self.min_region_size:\n                    continue\n                # score = peak * mean(comp)\n                conf = peak * float(sm[comp].mean() + 1e-6)\n                # project to a representative slice (peak slice)\n                ys, xs = np.where(comp[cz])\n                if ys.size == 0:\n                    # fallback to COM over full comp\n                    zc, yc, xc = ndimage.center_of_mass(comp)\n                    zc = int(round(zc)); yc = int(round(yc)); xc = int(round(xc))\n                    if yc <= self.border_margin or yc >= H - self.border_margin - 1 or xc <= self.border_margin or xc >= W - self.border_margin - 1:\n                        continue\n                    proposals.append({\n                        'slice_idx': int(zc),\n                        'y': int(yc),\n                        'x': int(xc),\n                        'confidence': float(conf),\n                        'region_size': size,\n                    })\n                else:\n                    y = int(ys.mean()); x = int(xs.mean())\n                    if y <= self.border_margin or y >= H - self.border_margin - 1 or x <= self.border_margin or x >= W - self.border_margin - 1:\n                        continue\n                    proposals.append({\n                        'slice_idx': int(cz),\n                        'y': y,\n                        'x': x,\n                        'confidence': float(conf),\n                        'region_size': size,\n                    })\n            proposals.sort(key=lambda c: c['confidence'], reverse=True)\n            return proposals\n        except Exception:\n            return []\n    \n    def _select_adaptive_rois(self, roi_candidates, seg_quality, original_volume):\n        \"\"\"Adaptively select ROIs based on segmentation quality (research-backed)\"\"\"\n        if not roi_candidates:\n            print(\"🔍 DEBUG: No candidates found, using fallback\")\n            return self._get_quality_fallback_rois_from_volume(original_volume)\n        \n        # Adaptive selection based on segmentation quality\n        if seg_quality >= self.high_confidence_threshold:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.3\n        elif seg_quality >= self.min_confidence_threshold + 0.2:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.2\n        else:\n            max_rois = self.max_rois_per_series\n            min_confidence = 0.05\n        \n        # Filter and select ROIs\n        filtered = [c for c in roi_candidates if c['confidence'] >= min_confidence]\n        selected_candidates = filtered[:max_rois]\n        # If not enough, top-off with next best candidates\n        if len(selected_candidates) < max_rois:\n            for c in roi_candidates:\n                if c in selected_candidates:\n                    continue\n                selected_candidates.append(c)\n                if len(selected_candidates) >= max_rois:\n                    break\n        \n        # Convert to ROI format\n        rois = []\n        for i, candidate in enumerate(selected_candidates):\n            roi_patch = self._extract_roi_patch(\n                original_volume,\n                candidate['slice_idx'], \n                candidate['y'], \n                candidate['x']\n            )\n            \n            rois.append({\n                'roi_image': roi_patch,\n                'slice_idx': candidate['slice_idx'],\n                'coordinates': (candidate['y'], candidate['x']),\n                'confidence': candidate['confidence'],\n                'roi_id': i\n            })\n        # Ensure at least max_rois via center-based fallback if still short\n        if len(rois) < self.max_rois_per_series:\n            needed = self.max_rois_per_series - len(rois)\n            center_fallbacks = self._get_quality_fallback_rois_from_volume(original_volume, needed)\n            rois.extend(center_fallbacks)\n        print(f\"🔍 DEBUG: Adaptively selected {len(rois)} ROIs (quality: {seg_quality:.3f})\")\n        return rois[: self.max_rois_per_series]\n    \n    def _get_quality_fallback_rois(self, series_path, seg_mask):\n        \"\"\"Fallback for poor segmentation quality: generate multiple center-based ROIs\"\"\"\n        print(\"🔍 DEBUG: Using quality-aware fallback (multi-center ROIs)\")\n        original_volume = self._load_efficient_volume(series_path)\n        return self._get_quality_fallback_rois_from_volume(original_volume, self.max_rois_per_series)\n\n    def _get_quality_fallback_rois_from_volume(self, original_volume, count: int = 3):\n        D, H, W = original_volume.shape\n        # Choose slice indices: center and quartiles\n        slices = sorted(set([D // 2, max(0, D // 4), min(D - 1, 3 * D // 4)]))\n        # Ensure desired count\n        while len(slices) < count:\n            # Add random slices if needed\n            slices.append(np.random.randint(0, D))\n            slices = list(dict.fromkeys(slices))\n        rois = []\n        cy, cx = H // 2, W // 2\n        for i, s in enumerate(slices[:count]):\n            roi_patch = self._extract_roi_patch(original_volume, s, cy, cx)\n            rois.append({\n                'roi_image': roi_patch,\n                'slice_idx': s,\n                'coordinates': (cy, cx),\n                'confidence': 0.2,\n                'roi_id': i\n            })\n        return rois\n    \n    def _get_simple_fallback_rois(self):\n        \"\"\"Simple fallback when no quality ROIs found\"\"\"\n        print(\"🔍 DEBUG: Using simple fallback (single center ROI)\")\n        dummy_roi = np.random.random((*Config.ROI_SIZE, 3)).astype(np.float32)\n        return [{\n            'roi_image': dummy_roi,\n            'slice_idx': 25,\n            'coordinates': (128, 128),\n            'confidence': 0.1,\n            'roi_id': 0\n        }]\n    \n    def _get_emergency_fallback_rois(self):\n        \"\"\"Emergency fallback when everything fails\"\"\"\n        print(\"🔍 DEBUG: Using emergency fallback ROI\")\n        dummy_roi = np.random.random((*Config.ROI_SIZE, 3)).astype(np.float32)\n        return [{\n            'roi_image': dummy_roi,\n            'slice_idx': 0,\n            'coordinates': (128, 128),\n            'confidence': 0.1,\n            'roi_id': 0\n        }]\n\n    \n    def _load_efficient_volume(self, series_path):\n        \"\"\"Load volume with smart distributed sampling to cover entire brain\"\"\"\n        try:\n            # Cache original volume slices to reduce repeated I/O\n            os.makedirs(Config.STAGE2_CACHE_DIR, exist_ok=True)\n            sid = os.path.basename(series_path)\n            vcache = os.path.join(Config.STAGE2_CACHE_DIR, f\"{sid}_vol.npy\")\n            if os.path.exists(vcache):\n                return np.load(vcache, allow_pickle=False)\n            dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n            pixel_arrays = []\n            \n            # SMART SAMPLING: Distribute 50 slices across entire volume\n            total_files = len(dicom_files)\n            if total_files > 50:\n                # Calculate step size to distribute slices evenly\n                step = total_files / 50\n                selected_indices = [int(i * step) for i in range(50)]\n                selected_files = [dicom_files[i] for i in selected_indices]\n                print(f\"🔍 DEBUG: Smart sampling - selected {len(selected_files)} files from {total_files} total (every {step:.1f})\")\n            else:\n                selected_files = dicom_files\n                print(f\"🔍 DEBUG: Using all {len(selected_files)} files (less than 50)\")\n            \n            for f in selected_files:\n                try:\n                    ds = pydicom.dcmread(os.path.join(series_path, f), force=True)\n                    if hasattr(ds, 'pixel_array'):\n                        arr = ds.pixel_array\n                        if arr.ndim == 2:\n                            pixel_arrays.append(arr)\n                except:\n                    continue\n            \n            if pixel_arrays:\n                # SMALLER target shape to reduce memory usage\n                target_shape = (256, 256)  # Reduced from (512, 512)\n                \n                resized_arrays = []\n                for arr in pixel_arrays:\n                    # Use cv2.resize instead of ndimage.zoom (more reliable)\n                    if arr.shape != target_shape:\n                        resized_arr = cv2.resize(arr.astype(np.float32), target_shape)\n                        resized_arrays.append(resized_arr)\n                    else:\n                        resized_arrays.append(arr.astype(np.float32))\n                \n                volume = np.stack(resized_arrays, axis=0)\n                \n                # Simple normalization\n                p1, p99 = np.percentile(volume, [1, 99])\n                volume = np.clip(volume, p1, p99)\n                volume = (volume - p1) / (p99 - p1 + 1e-8)\n                \n                try:\n                    np.save(vcache, volume.astype(np.float32), allow_pickle=False)\n                except Exception:\n                    pass\n                return volume\n            \n        except Exception as e:\n            print(f\"Error loading efficient volume: {e}\")\n        \n        # Fallback volume (matches our smart sampling approach)\n        return np.random.random((50, 256, 256)).astype(np.float32)\n\n    \n    def _extract_roi_patch(self, volume, slice_idx, center_y, center_x):\n        \"\"\"Extract ROI with adjacent-slice context as RGB channels (s-1, s, s+1).\"\"\"\n        D, H, W = volume.shape\n        s_indices = [max(0, slice_idx - 1), slice_idx, min(D - 1, slice_idx + 1)]\n        channels = []\n        half_size = Config.ROI_SIZE[0] // 2\n        for s in s_indices:\n            slice_data = volume[s]\n            h, w = slice_data.shape\n            y1 = max(0, center_y - half_size)\n            y2 = min(h, center_y + half_size)\n            x1 = max(0, center_x - half_size)\n            x2 = min(w, center_x + half_size)\n            patch = slice_data[y1:y2, x1:x2]\n            patch_resized = cv2.resize(patch, Config.ROI_SIZE)\n            channels.append(patch_resized)\n        patch_3ch = np.stack(channels, axis=2)\n        return patch_3ch\n    \n\ndef create_training_data(df, stage1_predictor):\n    \"\"\"Create training data. If DIRECT_VOLUME_MODE, bypass ROI extraction and use Stage0 32x384x384 volumes.\"\"\"\n    print(\"🔄 Extracting ROIs for training data...\")\n    \n    # Direct volume mode: build dataframe pointing to Stage0 32x384x384 volumes\n    if getattr(Config, 'DIRECT_VOLUME_MODE', False):\n        print(\"✅ DIRECT_VOLUME_MODE: using Stage 0 32x384x384 volumes (no ROI extraction)\")\n        # On-the-fly generation: do not depend on prebuilt volumes; dataset will read DICOMs\n        records = []\n        for _, row in df.iterrows():\n            sid = str(row[Config.ID_COL])\n            rec = {\n                'roi_id': f\"{sid}_vol32\",\n                'roi_path': '',\n                'series_id': sid,\n                'roi_confidence': 1.0,\n                'slice_idx': -1,\n            }\n            for col in Config.LABEL_COLS:\n                rec[col] = row[col]\n            records.append(rec)\n        training_df = pd.DataFrame(records)\n        print(f\"✅ DIRECT_VOLUME_MODE: built {len(training_df)} samples from {len(df)} series\")\n        return training_df\n\n    # Reuse cached ROIs/training dataframe if available\n    cache_dir = 'rois'\n    os.makedirs(cache_dir, exist_ok=True)\n    cached_df_path_parquet = os.path.join(cache_dir, 'training_df.parquet')\n    external_cached_df_path = os.path.join(getattr(Config, 'ROIS_EXTERNAL_DIR', ''), 'training_df.parquet')\n    if Config.REUSE_EXISTING_ROIS:\n        # Prefer working cache\n        if os.path.exists(cached_df_path_parquet):\n            try:\n                cached = pl.read_parquet(cached_df_path_parquet).to_pandas()\n                if len(cached) > 0 and all(c in cached.columns for c in ['roi_path', 'roi_id', 'series_id'] + Config.LABEL_COLS):\n                    print(f\"✅ Reusing cached training ROIs (working): {len(cached)} samples from {cached['series_id'].nunique()} series\")\n                    return cached\n            except Exception:\n                pass\n        # Fallback to external cache\n        if isinstance(external_cached_df_path, str) and len(external_cached_df_path) and os.path.exists(external_cached_df_path):\n            try:\n                cached = pl.read_parquet(external_cached_df_path).to_pandas()\n                if len(cached) > 0 and all(c in cached.columns for c in ['roi_path', 'roi_id', 'series_id'] + Config.LABEL_COLS):\n                    print(f\"✅ Reusing cached training ROIs (external): {len(cached)} samples from {cached['series_id'].nunique()} series\")\n                    # Optionally copy into working for faster subsequent access\n                    try:\n                        pl.from_pandas(cached).write_parquet(cached_df_path_parquet)\n                    except Exception:\n                        pass\n                    return cached\n            except Exception:\n                pass\n        # If external parquet is missing but external ROI images exist, auto-build parquet\n        ext_dir = getattr(Config, 'ROIS_EXTERNAL_DIR', '')\n        if isinstance(ext_dir, str) and os.path.isdir(ext_dir):\n            try:\n                candidates = [f for f in os.listdir(ext_dir) if f.lower().endswith('.png')]\n                if len(candidates) > 0:\n                    print(f\"🧩 Building training_df from external ROI images: {len(candidates)} files\")\n                    records = []\n                    label_cols = list(Config.LABEL_COLS)\n                    # Map labels by series_id for fast join\n                    df_labels = df[[Config.ID_COL] + label_cols].copy()\n                    df_labels[Config.ID_COL] = df_labels[Config.ID_COL].astype(str)\n                    label_map = df_labels.set_index(Config.ID_COL).to_dict('index')\n                    for fname in candidates:\n                        base = os.path.splitext(fname)[0]\n                        # Expect pattern: {series_id}_roi_{k}\n                        # Robust parse: split on '_roi_'\n                        if '_roi_' not in base:\n                            continue\n                        sid_part, roi_part = base.split('_roi_', 1)\n                        series_id = sid_part\n                        try:\n                            roi_id_int = int(roi_part)\n                        except Exception:\n                            roi_id_int = 0\n                        rec = {\n                            'roi_id': f\"{series_id}_roi_{roi_id_int}\",\n                            'roi_path': os.path.join(ext_dir, fname),\n                            'series_id': series_id,\n                            'roi_confidence': 0.2,\n                            'slice_idx': -1,\n                        }\n                        # Attach labels\n                        labs = label_map.get(series_id)\n                        if labs is None:\n                            # skip if label missing (should not happen for train)\n                            continue\n                        for col in label_cols:\n                            rec[col] = labs[col]\n                        records.append(rec)\n                    if records:\n                        training_df_ext = pd.DataFrame(records)\n                        print(f\"✅ Reconstructed training ROIs (external): {len(training_df_ext)} samples from {training_df_ext['series_id'].nunique()} series\")\n                        try:\n                            pl.from_pandas(training_df_ext).write_parquet(cached_df_path_parquet)\n                        except Exception:\n                            pass\n                        return training_df_ext\n            except Exception:\n                pass\n    roi_extractor = ROIExtractor(stage1_predictor)\n    training_data = []\n    \n    os.makedirs('rois', exist_ok=True)\n    \n    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting ROIs\"):\n        series_id = row[Config.ID_COL]\n        series_path = os.path.join(Config.SERIES_DIR, series_id)\n        \n        if not os.path.exists(series_path):\n            continue\n        \n        # Extract ROIs\n        rois = roi_extractor.extract_top3_rois(series_path)\n        \n        # Create training samples\n        for roi_data in rois:\n            roi_filename = f\"rois/{series_id}_roi_{roi_data['roi_id']}.png\"\n            \n            # Save ROI image\n            roi_image = (roi_data['roi_image'] * 255).astype(np.uint8)\n            Image.fromarray(roi_image).save(roi_filename)\n            \n            # Create training record\n            sample = {\n                'roi_id': f\"{series_id}_roi_{roi_data['roi_id']}\",\n                'roi_path': roi_filename,\n                'series_id': series_id,\n                'roi_confidence': roi_data['confidence'],\n                'slice_idx': roi_data['slice_idx']\n            }\n            \n            # Add all label columns\n            for col in Config.LABEL_COLS:\n                sample[col] = row[col]\n            \n            training_data.append(sample)\n    \n    training_df = pd.DataFrame(training_data)\n    print(f\"✅ Created {len(training_df)} training samples from {len(df)} series\")\n    # Save for reuse next runs\n    try:\n        pl.from_pandas(training_df).write_parquet(cached_df_path_parquet)\n        print(f\"💾 Saved training ROI dataframe → {cached_df_path_parquet}\")\n    except Exception:\n        pass\n    \n    return training_df\n\nprint(\"✅ Data loading and ROI extraction functions loaded\")\n\n\n\n# ====================================================\n# CELL 3: MODEL DEFINITION\n# ====================================================\n\nclass AneurysmClassificationDataset(Dataset):\n    \"\"\"Dataset for classification. In direct volume mode, builds 32x384x384 on-the-fly from DICOMs.\"\"\"\n    def __init__(self, df, mode='train'):\n        self.df = df\n        self.mode = mode\n        self.direct_volume = getattr(Config, 'DIRECT_VOLUME_MODE', False)\n        if self.direct_volume:\n            self.preprocessor = DICOMPreprocessorKaggle(target_shape=(32, 384, 384))\n            self.alb_transform = None  # Skip Albumentations in direct-volume path\n        else:\n            # ROI image pipeline (3-channel PNGs) - keep minimal and albumentations-based\n            if mode == 'train':\n                self.alb_transform = A.Compose([\n                    A.HorizontalFlip(p=0.5),\n                    A.VerticalFlip(p=0.5),\n                    A.Rotate(limit=15, p=0.5),\n                    A.ColorJitter(brightness=0.2, contrast=0.2, p=0.5),\n                    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n                    ToTensorV2(transpose_mask=False),\n                ])\n            else:\n                self.alb_transform = A.Compose([\n                    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n                    ToTensorV2(transpose_mask=False),\n                ])\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        if self.direct_volume:\n            # Build volume directly from series path (already normalized [0,1])\n            series_id = str(row['series_id'])\n            series_path = os.path.join(Config.SERIES_DIR, series_id)\n            arr = process_dicom_series_safe(series_path, target_shape=(32,384,384))  # (32,384,384) fp16/fp32\n            # Train-time slice subsample: keep quality by using full slices at val/test\n            if self.mode == 'train':\n                k = int(getattr(Config, 'SLICE_SUBSAMPLE_TRAIN', 0) or 0)\n                if k and arr.shape[0] > k:\n                    idx_keep = np.sort(np.random.choice(arr.shape[0], size=k, replace=False))\n                    arr = arr[idx_keep]\n            # Keep CPU tensor in fp16 if cache dtype is fp16\n            if getattr(Config, 'CACHE_DTYPE', 'float16') == 'float16' and arr.dtype == np.float16:\n                image = torch.as_tensor(arr, dtype=torch.float16)\n            else:\n                image = torch.as_tensor(arr, dtype=torch.float32)\n            try:\n                del arr\n            except Exception:\n                pass\n        else:\n            # Load ROI image\n            roi_path = row['roi_path']\n            try:\n                pil_img = Image.open(roi_path).convert('RGB')\n            except:\n                pil_img = Image.fromarray(np.random.randint(0, 255, (*Config.ROI_SIZE, 3), dtype=np.uint8))\n            np_img = np.array(pil_img)\n            try:\n                pil_img.close()\n            except Exception:\n                pass\n            out = self.alb_transform(image=np_img)\n            image = out['image']\n            try:\n                del np_img\n            except Exception:\n                pass\n        \n        # Get labels\n        labels = torch.tensor([row[col] for col in Config.LABEL_COLS], dtype=torch.float32)\n        \n        return {\n            'image': image,\n            'labels': labels,\n            'roi_id': row['roi_id'],\n            'confidence': torch.tensor(row['roi_confidence'], dtype=torch.float32)\n        }\n\n\nclass Normalize(nn.Module):\n    \"\"\"ImageNet normalization for 3-channel images.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n    \n    def forward(self, x):\n        return (x - self.mean) / self.std\n\nclass SliceMixer(nn.Module):\n    \"\"\"Mix 32 depth slices -> 3 channels via a learnable 1x1 conv.\"\"\"\n    def __init__(self, in_slices=32, out_ch=3, init='gaussian'):\n        super().__init__()\n        self.proj = nn.Conv2d(in_slices, out_ch, kernel_size=1, bias=False)\n        nn.init.kaiming_uniform_(self.proj.weight, a=math.sqrt(5))\n        if init == 'gaussian':\n            with torch.no_grad():\n                z = torch.linspace(-1, 1, in_slices)\n                sig = 0.35\n                centers = [-0.5, 0.0, 0.5]\n                for c, mu in enumerate(centers[:out_ch]):\n                    w = torch.exp(-0.5 * ((z - mu) / sig) ** 2)\n                    w = w / w.sum()\n                    self.proj.weight[c, :, 0, 0] = w\n    def forward(self, x):\n        return self.proj(x)\n\n\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, clip=0.05, eps=1e-8):\n        super().__init__()\n        self.gp = float(gamma_pos)\n        self.gn = float(gamma_neg)\n        self.clip = float(clip) if clip is not None else None\n        self.eps = float(eps)\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        x = torch.sigmoid(logits)\n        xs = x\n        if self.clip is not None and self.clip > 0:\n            xs = torch.clamp(x, self.clip, 1.0 - self.clip)\n        pos = targets\n        neg = 1.0 - targets\n        loss_pos = -pos * torch.log(xs + self.eps) * ((1.0 - x) ** self.gp)\n        loss_neg = -neg * torch.log(1.0 - xs + self.eps) * (x ** self.gn)\n        return (loss_pos + loss_neg).mean()\n\n\nclass Simple2D(nn.Module):\n    \"\"\"\n    Simple 2D model matching Run 1 (best: 0.6279 AUC).\n    Takes 32-slice volume, extracts 3 center slices as RGB channels.\n    Uses EfficientNetV2-S (exact match to working model).\n    \"\"\"\n    def __init__(self, num_classes=len(Config.LABEL_COLS)):\n        super().__init__()\n        \n        # Use EfficientNetV2-S with 3 input channels\n        self.backbone = timm.create_model(\n            'tf_efficientnetv2_s.in21k_ft_in1k',\n            pretrained=False,\n            in_chans=3,\n            num_classes=num_classes,\n            drop_rate=0.2,\n            drop_path_rate=0.2\n        )\n        \n        # Load offline weights from HuggingFace checkpoint\n        weights_path = \"/kaggle/input/tf_efficientnetv2_s.in21k_ft_in1k/pytorch/default/1/pytorch_model.bin\"\n        print(f\"🔄 Loading EfficientNetV2-S weights from: {weights_path}\")\n        sd = torch.load(weights_path, map_location=\"cpu\")\n        \n        # Clean up state dict keys if needed\n        if isinstance(sd, dict) and \"state_dict\" in sd:\n            sd = sd[\"state_dict\"]\n        \n        clean = {}\n        for k, v in sd.items():\n            # Remove common prefixes\n            if k.startswith(\"module.\"):\n                k = k[7:]\n            if k.startswith(\"model.\"):\n                k = k[6:]\n            # Skip classifier weights (1000 classes vs our 14 classes)\n            if k.startswith(\"classifier.\"):\n                continue\n            clean[k] = v\n        \n        # Load weights directly (3-ch to 3-ch, no adaptation needed)\n        missing, unexpected = self.backbone.load_state_dict(clean, strict=False)\n        print(f\"✅ EfficientNetV2-S weights loaded: Missing={len(missing)}, Unexpected={len(unexpected)}\")\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: [B, 32, H, W] - 32-slice volume in [0,1]\n        Returns:\n            logits: [B, num_classes]\n        \"\"\"\n        B, D, H, W = x.shape\n        \n        # Extract 3 center slices as RGB channels\n        center = D // 2\n        x_3ch = x[:, center-1:center+2, :, :]  # [B, 3, H, W]\n        \n        # Normalize for EfficientNet (ImageNet stats)\n        mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1, 3, 1, 1)\n        std = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1, 3, 1, 1)\n        x_3ch = (x_3ch.float() - mean) / std\n        x_3ch = x_3ch.half() if x.dtype == torch.float16 else x_3ch\n        \n        # Forward through backbone\n        logits = self.backbone(x_3ch)\n        return logits\n        \n\nclass RSNA2p5D(nn.Module):\n    \"\"\"2.5D model: 32-slice mixer -> 3ch ImageNet backbone (offline weights).\"\"\"\n    def __init__(self, num_classes=len(Config.LABEL_COLS), backbone_name='tf_efficientnet_b3'):\n        super().__init__()\n        self.mixer = SliceMixer(in_slices=32, out_ch=3, init='gaussian')\n        self.norm = Normalize()\n        # Build 3-ch backbone (feature extractor)\n        self.backbone = timm.create_model(backbone_name, pretrained=False, in_chans=3, num_classes=0, global_pool='avg')\n        # ---- Offline weights: single fixed path (no fallback) ----\n        weights_path = \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b3/1/tf_efficientnet_b3_aa-84b4657e.pth\"\n        if backbone_name.startswith(\"tf_efficientnet_b3\"):\n            if os.path.exists(weights_path):\n                try:\n                    print(f\"🔄 Loading offline TF-EfficientNet-B3 weights from: {weights_path}\")\n                    state = torch.load(weights_path, map_location=\"cpu\")\n                    # Unwrap common formats\n                    if isinstance(state, dict) and \"state_dict\" in state:\n                        state = state[\"state_dict\"]\n                    clean = {}\n                    for k, v in state.items():\n                        if k.startswith(\"module.\"): k = k[7:]\n                        if k.startswith(\"model.\"):  k = k[6:]\n                        clean[k] = v\n                    missing, unexpected = self.backbone.load_state_dict(clean, strict=False)\n                    print(f\"✅ Weights loaded. Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n                except Exception as e:\n                    print(f\"❌ Error loading offline TF-EfficientNet-B3 weights: {e}\")\n            else:\n                print(f\"⚠️ Offline weights not found at {weights_path}; using random init for backbone.\")\n        else:\n            print(f\"⚠️ Backbone '{backbone_name}' is not tf_efficientnet_b3; skipping offline load.\")\n        # Robust feature dim detection\n        feature_dim = getattr(self.backbone, \"num_features\", None)\n        if not isinstance(feature_dim, int) or feature_dim <= 0:\n            try:\n                feature_dim = self.backbone.get_classifier().in_features\n            except Exception:\n                feature_dim = 1536 if \"efficientnet_b3\" in backbone_name else 1024\n\n        self.head = nn.Linear(int(feature_dim), num_classes)\n    \n    def forward(self, x):  # x: (B,32,H,W) in [0,1]\n        x = self.mixer(x)\n        x = torch.clamp(x, 0, 1)\n        x = self.norm(x)\n        x = x.to(memory_format=torch.channels_last)\n        feats = self.backbone(x)\n        return self.head(feats)\n\n# ====================================================\n# MIL 2.5D MODEL: Shared 2D encoder per slice + Transformer over depth\n# ====================================================\nclass PositionalEncoding1D(nn.Module):\n    def __init__(self, d_model, max_len=128):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n        pe[:, 0::2] = torch.sin(pos * div)\n        pe[:, 1::2] = torch.cos(pos * div)\n        self.register_buffer('pe', pe[None])  # (1, L, C)\n    def forward(self, x):  # x: (B, L, C)\n        return x + self.pe[:, :x.size(1)]\n\nclass SliceTriChannel(nn.Module):\n    \"\"\"Make each token a tri-slice [z-1, z, z+1] to inject tiny depth context per slice.\"\"\"\n    def forward(self, x):  # x: (B, D, H, W)\n        # Pad depth by 1 on each side, then slice and stack\n        xp = F.pad(x, (0, 0, 0, 0, 1, 1), mode='replicate')  # (B, D+2, H, W)\n        tri = torch.stack([xp[:, :-2], xp[:, 1:-1], xp[:, 2:]], dim=2)  # (B, D, 3, H, W)\n        return tri\n\nclass MIL2p5D(nn.Module):\n    \"\"\"\n    OPTIMIZED: Shared 2D ImageNet encoder per slice -> Transformer over tokens -> gated attention pooling -> logits.\n    Speed optimizations:\n      - Smaller backbone (B0 instead of B3): 3-4x faster\n      - Reduced spatial resolution (224 instead of 320): 2x faster\n      - Gradient checkpointing: Allows larger batches\n      - Optional encoder compilation (PyTorch 2.0+)\n    \"\"\"\n    def __init__(self, num_classes=len(Config.LABEL_COLS), \n                 backbone=None, d_model=None, nhead=None, n_layers=None, \n                 spatial_size=None, use_grad_checkpoint=None):\n        super().__init__()\n        # Use Config defaults if not provided\n        backbone = backbone or getattr(Config, 'MIL_BACKBONE', 'tf_efficientnet_b0')\n        d_model = d_model or getattr(Config, 'MIL_D_MODEL', 512)\n        nhead = nhead or getattr(Config, 'MIL_NHEAD', 8)\n        n_layers = n_layers or getattr(Config, 'MIL_N_LAYERS', 2)\n        self.spatial_size = spatial_size or getattr(Config, 'MIL_SPATIAL_SIZE', 224)\n        use_grad_checkpoint = use_grad_checkpoint if use_grad_checkpoint is not None else getattr(Config, 'MIL_USE_GRAD_CHECKPOINT', True)\n        \n        self.tri = SliceTriChannel()\n        # Shared 2D encoder (lightweight for speed)\n        self.encoder = timm.create_model(backbone, pretrained=False, in_chans=3, num_classes=0, global_pool='avg')\n        \n        # Try to load offline weights (support B0, B1, B3)\n        weights_map = {\n            'tf_efficientnet_b0': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth',\n            'tf_efficientnet_b1': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b1/1/tf_efficientnet_b1_aa-ea7a7bb7.pth',\n            'tf_efficientnet_b3': '/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b3/1/tf_efficientnet_b3_aa-84b4657e.pth',\n        }\n        weights_path = weights_map.get(backbone, None)\n        if weights_path and os.path.exists(weights_path):\n            try:\n                print(f\"🔄 Loading offline {backbone} weights from: {weights_path}\")\n                state = torch.load(weights_path, map_location=\"cpu\")\n                if isinstance(state, dict) and \"state_dict\" in state:\n                    state = state[\"state_dict\"]\n                clean = {}\n                for k, v in state.items():\n                    if isinstance(k, str):\n                        if k.startswith(\"module.\"): k = k[7:]\n                        if k.startswith(\"model.\"):  k = k[6:]\n                        clean[k] = v\n                missing, unexpected = self.encoder.load_state_dict(clean, strict=False)\n                print(f\"✅ Weights loaded. Missing: {len(missing)}, Unexpected: {len(unexpected)}\")\n            except Exception as e:\n                print(f\"⚠️ Error loading weights: {e}\")\n        \n        # Enable gradient checkpointing for encoder (saves VRAM)\n        if use_grad_checkpoint and hasattr(self.encoder, 'set_grad_checkpointing'):\n            try:\n                self.encoder.set_grad_checkpointing(True)\n                print(f\"✅ Gradient checkpointing enabled for {backbone}\")\n            except Exception:\n                pass\n        \n        # Optional: Compile encoder for speed (PyTorch 2.0+)\n        if getattr(Config, 'MIL_COMPILE_ENCODER', False):\n            try:\n                self.encoder = torch.compile(self.encoder, mode='max-autotune')\n                print(\"✅ Encoder compiled with torch.compile\")\n            except Exception as e:\n                print(f\"⚠️ torch.compile not available: {e}\")\n        \n        feat_dim = int(getattr(self.encoder, 'num_features'))\n        self.proj = nn.Linear(feat_dim, d_model)\n        self.pe   = PositionalEncoding1D(d_model, max_len=128)\n        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True,\n                                               dim_feedforward=4*d_model, norm_first=True)\n        self.tx   = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n        self.gate = nn.Sequential(nn.Linear(d_model, d_model), nn.Tanh(), nn.Linear(d_model, 1))\n        self.head = nn.Linear(d_model, num_classes)\n        \n        print(f\"🏗️  MIL2p5D: backbone={backbone}, spatial={self.spatial_size}, d_model={d_model}, layers={n_layers}\")\n\n    def forward(self, x):  # x: (B, D, H, W) in [0,1]\n        B, D, H, W = x.shape\n        x = self.tri(x)                      # (B, D, 3, H, W)\n        x = x.view(B*D, 3, H, W)\n        x = x.to(memory_format=torch.channels_last)\n        # Downscale to target spatial size for speed\n        if x.shape[-2] != self.spatial_size or x.shape[-1] != self.spatial_size:\n            x = F.interpolate(x, size=(self.spatial_size, self.spatial_size), mode='bilinear', align_corners=False)\n        feats = self.encoder(x)              # (B*D, feat_dim)\n        feats = feats.view(B, D, -1)         # (B, D, feat_dim)\n        z = self.proj(feats)                 # (B, D, d_model)\n        z = self.pe(z)\n        z = self.tx(z)                       # (B, D, d_model)\n        a = torch.softmax(self.gate(z), dim=1)  # (B, D, 1)\n        bag = (a * z).sum(dim=1)             # (B, d_model)\n        logits = self.head(bag)              # (B, C)\n        return logits\n\n\n# Using original EfficientNet approach\n\ndef calculate_class_weights(df):\n    \"\"\"Calculate class weights with 13x multiplier for Aneurysm Present\"\"\"\n    pos_counts = df[Config.LABEL_COLS].sum()\n    neg_counts = len(df) - pos_counts\n    \n    # Standard frequency-based weights\n    class_weights = neg_counts / (pos_counts + 1e-8)\n    \n    # Apply weight cap if configured (prevents extreme weights like 93.5)\n    weight_cap = getattr(Config, 'CLASS_WEIGHT_CAP', 100.0)\n    class_weights = np.minimum(class_weights, weight_cap)\n    \n    # Apply 13x multiplier to \"Aneurysm Present\" (matches competition metric)\n    # But also respect the cap\n    class_weights.iloc[-1] = min(class_weights.iloc[-1] * 13.0, weight_cap)\n    \n    return torch.tensor(class_weights.values, dtype=torch.float32)\n\ntry:\n    torch.backends.cudnn.benchmark = True  # speed: autotune best cudnn algorithms for fixed input sizes\nexcept Exception:\n    pass\nprint(\"✅ Model definition loaded\")\n\n# ====================================================\n# CELL 4: TRAINING PIPELINE\n# ====================================================\n\ndef compute_hierarchical_penalty(logits: torch.Tensor) -> torch.Tensor:\n    \"\"\"Penalty to enforce sites' probabilities <= main (Aneurysm Present).\n    logits: (B, C=14) with last index being 'Aneurysm Present'.\n    Returns a scalar tensor on the same device/dtype.\n    \"\"\"\n    try:\n        if logits.ndim != 2 or logits.size(1) < 2:\n            return torch.zeros((), device=logits.device, dtype=logits.dtype)\n        sites = logits[:, :-1]\n        main = logits[:, -1:]\n        p_sites = torch.sigmoid(sites)\n        p_main = torch.sigmoid(main)\n        return F.relu(p_sites - p_main).mean()\n    except Exception:\n        # Safe fallback: no penalty if anything goes wrong\n        return torch.zeros((), device=logits.device, dtype=logits.dtype)\n\ndef compute_primary_loss(logits: torch.Tensor, labels: torch.Tensor, bce_criterion: nn.Module) -> torch.Tensor:\n    \"\"\"Compute supervised loss: ASL for site logits + BCE for main logit, or fallback to BCE for all.\n    Assumes last class is 'Aneurysm Present'.\n    \"\"\"\n    try:\n        if getattr(Config, 'USE_ASL', False) and logits.size(1) >= 2:\n            # ASL for site logits (all except last)\n            asl = AsymmetricLoss(\n                gamma_pos=getattr(Config, 'ASL_GAMMA_POS', 0.0),\n                gamma_neg=getattr(Config, 'ASL_GAMMA_NEG', 4.0),\n                clip=getattr(Config, 'ASL_CLIP', 0.05),\n            )\n            sites_logits = logits[:, :-1]\n            sites_targets = labels[:, :-1]\n            loss_sites = asl(sites_logits, sites_targets)\n            # BCE for main logit (last column), keep pos_weight emphasis\n            main_logits = logits[:, -1]\n            main_targets = labels[:, -1]\n            try:\n                pw_main = None\n                if hasattr(bce_criterion, 'pos_weight') and bce_criterion.pos_weight is not None:\n                    pw_main = bce_criterion.pos_weight[-1].to(main_logits.device)\n                if pw_main is not None:\n                    loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets, pos_weight=pw_main)\n                else:\n                    loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets)\n            except Exception:\n                loss_main = F.binary_cross_entropy_with_logits(main_logits, main_targets)\n            w_sites = float(getattr(Config, 'ASL_WEIGHT_SITES', 1.0))\n            w_main  = float(getattr(Config, 'MAIN_BCE_WEIGHT', 1.0))\n            return w_sites * loss_sites + w_main * loss_main\n        else:\n            return bce_criterion(logits, labels)\n    except Exception:\n        return bce_criterion(logits, labels)\n\n\ndef _val_forward_in_chunks(model, images, *, max_tokens:int, mixed_precision:bool):\n    \"\"\"\n    images:\n      • mil2p5d: (B, D, H, W) before tri-stacking in the model\n      • 2D ROI: (B, C, H, W)\n    We compute a chunk size so that (b_chunk * D) <= max_tokens for mil2p5d,\n    or (b_chunk) <= max_tokens for 2D ROI, and concatenate outputs.\n    \"\"\"\n    import torch\n    from torch import nn\n\n    if images.dim() == 4:\n        B = images.size(0)\n        second = images.size(1)\n        D = 1 if second in (1, 3) else second\n    elif images.dim() == 5:\n        B = images.size(0)\n        D = images.size(1)\n    else:\n        B, D = images.size(0), 1\n\n    b_chunk = max(1, int(max_tokens // max(D, 1)))\n    outs = []\n    for i in range(0, B, b_chunk):\n        x = images[i:i + b_chunk]\n        with torch.cuda.amp.autocast(enabled=mixed_precision):\n            outs.append(model(x))\n    return torch.cat(outs, dim=0)\n\n\n\ndef compute_validation_auc(logits: torch.Tensor, labels: torch.Tensor) -> float:\n    \"\"\"Compute weighted AUC (13x on 'Aneurysm Present') mirroring validate_epoch behavior.\"\"\"\n    try:\n        probs = torch.sigmoid(logits).float().cpu().numpy()\n        y_true = labels.float().cpu().numpy()\n        auc_scores = []\n        valid_aucs = 0\n        for i in range(len(Config.LABEL_COLS)):\n            if len(np.unique(y_true[:, i])) > 1:\n                auc = roc_auc_score(y_true[:, i], probs[:, i])\n                auc_scores.append(auc)\n                valid_aucs += 1                \n            else:\n                auc_scores.append(0.5)\n\n        # DEBUG: Print stats on first validation\n        if not hasattr(compute_validation_auc, '_debug_printed'):\n            print(f\"🔍 AUC DEBUG - Valid classes: {valid_aucs}/{len(Config.LABEL_COLS)}\")\n            print(f\"🔍 AUC DEBUG - Pred range: [{probs.min():.3f}, {probs.max():.3f}]\")\n            print(f\"🔍 AUC DEBUG - Pred mean: {probs.mean():.3f}\")\n            print(f\"🔍 AUC DEBUG - Positive rate: {y_true.mean():.3f}\")\n            compute_validation_auc._debug_printed = True\n            \n        weights = [1.0] * (len(Config.LABEL_COLS) - 1) + [13.0]\n        weighted_auc = float(np.average(auc_scores, weights=weights))\n        return weighted_auc\n    except Exception as e:\n        print(f\"⚠️ AUC computation failed: {e}\")\n        return 0.5\n\n\ndef _run_validation(model, loader, criterion, device, *, max_tokens:int):\n    import torch\n    model.eval()\n    # Temporarily disable encoder/backbone grad-checkpointing for eval (if available)\n    core = model.module if isinstance(model, nn.DataParallel) else model\n    enc_ref = getattr(core, 'encoder', None)\n    if enc_ref is None:\n        enc_ref = getattr(core, 'backbone', None)\n    restore_gc = None\n    if enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n        try:\n            restore_gc = True\n            enc_ref.set_grad_checkpointing(False)\n        except Exception:\n            restore_gc = None\n\n    total_loss = 0.0\n    num_batches = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.inference_mode():\n        for batch in tqdm(loader, desc=\"Validating (proxy)\" if int(max_tokens) < int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384)) else \"Validating (full)\"):\n            if isinstance(batch, dict):\n                images = batch['image'].to(device, non_blocking=True)\n                labels = batch['labels'].to(device, non_blocking=True)\n            else:\n                images, labels = batch\n                images = images.to(device, non_blocking=True)\n                labels = labels.to(device, non_blocking=True)\n\n            logits = _val_forward_in_chunks(\n                model,\n                images,\n                max_tokens=int(max_tokens),\n                mixed_precision=bool(getattr(Config, 'MIXED_PRECISION', True)),\n            )\n            # Compute supervised loss (same routine as training)\n            primary_loss = compute_primary_loss(logits, labels, criterion)\n            if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                hier_pen = compute_hierarchical_penalty(logits)\n                batch_loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n            else:\n                batch_loss = primary_loss\n            total_loss += float(batch_loss.detach().cpu())\n            num_batches += 1\n\n            # Collect predictions for AUC on CPU\n            all_preds.append(torch.sigmoid(logits).float().cpu())\n            all_labels.append(labels.float().cpu())\n\n    if restore_gc and enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n        try:\n            enc_ref.set_grad_checkpointing(True)\n        except Exception:\n            pass\n\n    logits_cat = torch.cat(all_preds, dim=0)\n    labels_cat = torch.cat(all_labels, dim=0)\n    val_loss = total_loss / max(1, num_batches)\n    val_auc = compute_validation_auc(logits_cat, labels_cat)\n    return val_loss, val_auc\n\n\ndef autotune_micro_batch(model, train_loader, criterion, device):\n    \"\"\"\n    Try a few micro-batch sizes on a single mini-iteration to find the largest safe one.\n    No weights are updated. Returns chosen micro size.\n    \"\"\"\n    import torch\n    model.eval()\n    \n    # Safety: Try to get batch with timeout protection\n    try:\n        print(\"[AutoTune] Fetching test batch...\", flush=True)\n        batch = next(iter(train_loader))\n        if isinstance(batch, dict):\n            imgs = batch['image']\n            labels = batch['labels']\n        else:\n            imgs, labels = batch\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        print(f\"[AutoTune] Test batch loaded: {imgs.shape}\", flush=True)\n    except Exception as e:\n        print(f\"[AutoTune] ERROR loading batch: {e}\", flush=True)\n        print(\"[AutoTune] Falling back to default MICRO_BATCH_SIZE\", flush=True)\n        return getattr(Config, 'MICRO_BATCH_SIZE', 12)\n\n    candidates = [16, 14, 12, 10, 8, 6, 4]\n    chosen = None\n    scaler_local = torch.cuda.amp.GradScaler(enabled=getattr(Config, 'MIXED_PRECISION', True))\n\n    for mb in candidates:\n        try:\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n            accum = max(1, int((getattr(Config, 'BATCH_SIZE', 24) + mb - 1) // mb))\n            model.zero_grad(set_to_none=True)\n            for i in range(accum):\n                i0 = i * mb\n                i1 = min((i + 1) * mb, imgs.size(0))\n                if i0 >= i1:\n                    break\n                x = imgs[i0:i1].to(memory_format=torch.channels_last)\n                y = labels[i0:i1]\n                with torch.cuda.amp.autocast(enabled=getattr(Config, 'MIXED_PRECISION', True)):\n                    logits = model(x)\n                    loss = criterion(logits, y) / accum\n                scaler_local.scale(loss).backward()\n            # Clear grads (no optimizer step)\n            for p in model.parameters():\n                if p.grad is not None:\n                    p.grad = None\n            chosen = mb\n            break\n        except RuntimeError as e:\n            if 'CUDA out of memory' not in str(e):\n                raise\n        finally:\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n\n    model.train()\n    if chosen is None:\n        chosen = max(1, int(getattr(Config, 'MICRO_BATCH_SIZE', 12)))\n    return chosen\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    \n    for batch in tqdm(loader, desc=\"Training\"):\n        images = batch['image'].to(device, non_blocking=True)\n        labels = batch['labels'].to(device, non_blocking=True)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        # Forward pass\n        with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n            images = images.to(memory_format=torch.channels_last)\n            logits = model(images)\n            primary_loss = compute_primary_loss(logits, labels, criterion)\n            if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                hier_pen = compute_hierarchical_penalty(logits)\n                loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n            else:\n                loss = primary_loss\n        \n        # Backward pass\n        if Config.MIXED_PRECISION:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n    \n    return total_loss / num_batches\n\ndef validate_epoch(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    num_batches = 0\n    \n    with torch.inference_mode():\n        for batch in tqdm(loader, desc=\"Validating\"):\n            images = batch['image'].to(device, non_blocking=True)\n            labels = batch['labels'].to(device, non_blocking=True)\n            \n            with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n                images = images.to(memory_format=torch.channels_last)\n\n            logits = _val_forward_in_chunks(\n                model,\n                images,\n                max_tokens=int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384)),\n                mixed_precision=bool(getattr(Config, 'MIXED_PRECISION', True)),\n            )\n            primary_loss = compute_primary_loss(logits, labels, criterion)\n            if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                hier_pen = compute_hierarchical_penalty(logits)\n                loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n            else:\n                loss = primary_loss\n            \n            total_loss += loss.item()\n            num_batches += 1\n            \n            # Collect predictions for AUC on CPU only and free GPU tensors promptly\n            probs = torch.sigmoid(logits).float().cpu()\n            all_preds.append(probs.numpy())\n            all_labels.append(labels.cpu().numpy())\n            del logits, probs, images, labels\n    \n    # Calculate AUC (overall + per-class)\n    if len(all_preds) > 0:\n        all_preds = np.vstack(all_preds)\n        all_labels = np.vstack(all_labels)\n        \n        try:\n            auc_scores = []\n            for i in range(len(Config.LABEL_COLS)):\n                if len(np.unique(all_labels[:, i])) > 1:\n                    auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n                    auc_scores.append(auc)\n                else:\n                    auc_scores.append(0.5)\n\n            # DEBUG: Print stats EVERY fold to track prediction behavior\n            print(f\"🔍 AUC DEBUG - Valid classes: {valid_aucs}/{len(Config.LABEL_COLS)}\")\n            print(f\"🔍 AUC DEBUG - Pred range: [{probs.min():.3f}, {probs.max():.3f}]\")\n            print(f\"🔍 AUC DEBUG - Pred mean: {probs.mean():.3f}\")\n            print(f\"🔍 AUC DEBUG - Positive rate: {y_true.mean():.3f}\")\n            \n            # Weighted AUC (13x weight for Aneurysm Present)\n            weights = [1.0] * (len(Config.LABEL_COLS) - 1) + [13.0]\n            weighted_auc = np.average(auc_scores, weights=weights)\n\n            # Per-class AUC logging (rounded)\n            per_class_auc = {Config.LABEL_COLS[i]: (round(auc_scores[i], 4) if not np.isnan(auc_scores[i]) else None)\n                             for i in range(len(Config.LABEL_COLS))}\n            print(\"Per-class AUC:\", per_class_auc)\n        except:\n            weighted_auc = 0.5\n    else:\n        weighted_auc = 0.5\n    \n    return total_loss / num_batches, weighted_auc\n\ndef main_training():\n    print(\"🚀 STAGE 2: ANEURYSM CLASSIFICATION\")\n    print(\"📦 Data: Loading .npz shards directly (64x384x384x4 uint8)\")\n    \n    # Load data\n    train_df = pd.read_csv(Config.TRAIN_CSV_PATH)\n    \n    if Config.DEBUG_MODE:\n        train_df = train_df.head(Config.DEBUG_SAMPLES)\n    \n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Aneurysm cases: {train_df['Aneurysm Present'].sum()}\")\n    \n    # Build training index (DIRECT_VOLUME_MODE: no ROIs)\n    records = []\n    for _, r in train_df.iterrows():\n        rec = {\n            'series_id': str(r[Config.ID_COL]),\n            'roi_id': f\"{str(r[Config.ID_COL])}_vol32\",\n            'roi_path': '',\n            'roi_confidence': 1.0,\n            'slice_idx': -1,\n        }\n        for col in Config.LABEL_COLS:\n            rec[col] = r[col]\n        records.append(rec)\n    training_df = pd.DataFrame(records)\n    \n    # Calculate class weights\n    class_weights = calculate_class_weights(training_df)\n    print(f\"Class weights: {class_weights}\")\n    \n    # Create criterion with class weights\n    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(Config.DEVICE)\n    \n    # Mixed precision scaler\n    global scaler\n    scaler = torch.cuda.amp.GradScaler(enabled=Config.MIXED_PRECISION)\n    \n    # Cross-validation or single split\n    # Use Aneurysm Present for stratification\n    fold_scores = []\n    if Config.N_FOLDS <= 1:\n        idx_all = np.arange(len(training_df))\n        train_idx, val_idx = train_test_split(\n            idx_all,\n            test_size=0.2,\n            stratify=training_df['Aneurysm Present'],\n            random_state=42,\n        )\n        fold_splits = [(train_idx, val_idx)]\n    else:\n        skf = StratifiedKFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=42)\n        fold_splits = list(skf.split(training_df, training_df['Aneurysm Present']))\n    \n    for fold, (train_idx, val_idx) in enumerate(fold_splits):\n        print(f\"\\n{'='*50}\")\n        print(f\"FOLD {fold + 1}/{Config.N_FOLDS}\")\n        print(f\"{'='*50}\")\n        \n        # Split data\n        train_fold_df = training_df.iloc[train_idx].reset_index(drop=True)\n        val_fold_df = training_df.iloc[val_idx].reset_index(drop=True)\n        \n        print(f\"Train samples: {len(train_fold_df)}, Val samples: {len(val_fold_df)}\")\n        \n        # Create datasets\n        train_dataset = AneurysmClassificationDataset(train_fold_df, mode='train')\n        val_dataset = AneurysmClassificationDataset(val_fold_df, mode='val')\n\n        # DEBUG: Verify data sanity\n        if fold == 0:\n            test_sample = train_dataset[0]\n            print(f\"🔍 DATA CHECK - Image shape: {test_sample['image'].shape}, dtype: {test_sample['image'].dtype}\")\n            print(f\"🔍 DATA CHECK - Image range: [{test_sample['image'].min():.3f}, {test_sample['image'].max():.3f}]\")\n            print(f\"🔍 DATA CHECK - Image mean: {test_sample['image'].mean():.3f}, std: {test_sample['image'].std():.3f}\")\n            print(f\"🔍 DATA CHECK - Non-zero voxels: {(test_sample['image'] > 0).sum()}/{test_sample['image'].numel()}\")\n            print(f\"🔍 DATA CHECK - Labels shape: {test_sample['labels'].shape}, sum: {test_sample['labels'].sum()}\")\n\n            # Check class distribution\n            aneurysm_present = train_fold_df['Aneurysm Present'].sum()\n            total_samples = len(train_fold_df)\n            print(f\"🔍 CLASS DISTRIBUTION - Aneurysm Present: {aneurysm_present}/{total_samples} ({100*aneurysm_present/total_samples:.1f}%)\")\n            \n            # Check all label columns\n            for col in Config.LABEL_COLS:\n                if col in train_fold_df.columns:\n                    pos = train_fold_df[col].sum()\n                    print(f\"  {col}: {pos} positives\")\n\n        # WeightedRandomSampler to emphasize positives (Aneurysm Present)\n        sampler = None\n        if getattr(Config, 'USE_WEIGHTED_SAMPLER', True):\n            try:\n                pos = train_fold_df['Aneurysm Present'].values.astype(np.int64)\n                class_sample_count = np.array([np.sum(pos == 0), np.sum(pos == 1)])\n                weight = 1.0 / (class_sample_count + 1e-8)\n                samples_weight = weight[pos]\n                samples_weight = torch.from_numpy(samples_weight).double()\n                sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n            except Exception:\n                sampler = None\n        \n        # Create loaders (tuned for throughput)\n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=Config.BATCH_SIZE,\n            shuffle=(sampler is None),\n            sampler=sampler,\n            num_workers=Config.NUM_WORKERS,\n            pin_memory=Config.PIN_MEMORY,\n            persistent_workers=Config.PERSISTENT_WORKERS,\n            prefetch_factor=Config.PREFETCH_FACTOR,\n            drop_last=True,\n        )\n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=getattr(Config, 'VAL_BATCH_SIZE', 64),\n            shuffle=False,\n            num_workers=Config.NUM_WORKERS,\n            pin_memory=Config.PIN_MEMORY,\n            persistent_workers=Config.PERSISTENT_WORKERS,\n            prefetch_factor=Config.PREFETCH_FACTOR,\n        )\n        # Build fast-val loader (subset) once\n        def build_fast_val_loader(val_dataset):\n            import numpy as _np\n            from torch.utils.data import DataLoader as _DL, Subset as _Subset\n            frac = float(getattr(Config, 'FAST_VAL_SUBSET_FRAC', 0.33))\n            n = len(val_dataset)\n            k = max(1, int(n * frac))\n            rng = _np.random.RandomState(getattr(Config, 'SEED', 42))\n            idx = rng.choice(n, size=k, replace=False)\n            subset = _Subset(val_dataset, idx.tolist())\n            return _DL(\n                subset,\n                batch_size=getattr(Config, 'VAL_BATCH_SIZE', 32),\n                shuffle=False,\n                num_workers=getattr(Config, 'NUM_WORKERS', 4),\n                pin_memory=getattr(Config, 'PIN_MEMORY', True),\n                persistent_workers=getattr(Config, 'PERSISTENT_WORKERS', True),\n                prefetch_factor=getattr(Config, 'PREFETCH_FACTOR', 2),\n            )\n        val_loader_full = val_loader\n        val_loader_fast = build_fast_val_loader(val_dataset) if getattr(Config, 'FAST_VAL', True) else None\n        \n        # Initialize model with architecture-specific shard configuration\n        arch = getattr(Config, 'MODEL_ARCH', 'rsna2p5d')\n        \n        if arch == 'simple2d':\n            # Simple 2D model (matching 0.69 working architecture)\n            Config.SHARD_CHANNEL_MODE = 'cta'\n            Config.SHARD_TARGET_SPATIAL = (384, 384)\n            print(f\"🔧 Simple2D mode: 3 center slices as RGB, spatial={Config.SHARD_TARGET_SPATIAL}\")\n            \n            model = Simple2D(num_classes=len(Config.LABEL_COLS)).to(Config.DEVICE)\n        elif arch == 'mil2p5d':\n            # Override shard config for mil2p5d (multi-channel, smaller spatial)\n            Config.SHARD_CHANNEL_MODE = 'best3'  # CTA + soft + vesselness\n            Config.SHARD_TARGET_SPATIAL = (getattr(Config, 'MIL_SPATIAL_SIZE', 224), \n                                           getattr(Config, 'MIL_SPATIAL_SIZE', 224))\n            print(f\"🔧 MIL2p5D mode: shard channels={Config.SHARD_CHANNEL_MODE}, spatial={Config.SHARD_TARGET_SPATIAL}\")\n            \n            model = MIL2p5D(num_classes=len(Config.LABEL_COLS)).to(Config.DEVICE)\n        else:\n            # rsna2p5d uses single CTA channel, full resolution\n            Config.SHARD_CHANNEL_MODE = 'cta'\n            Config.SHARD_TARGET_SPATIAL = (384, 384)\n            print(f\"🔧 RSNA2p5D mode: shard channels={Config.SHARD_CHANNEL_MODE}, spatial={Config.SHARD_TARGET_SPATIAL}\")\n            \n            model = RSNA2p5D().to(Config.DEVICE)\n        try:\n            model = model.to(memory_format=torch.channels_last)\n        except Exception:\n            pass\n        \n        # Optimizer - SIMPLIFIED to match working 0.69 model\n        # Use constant LR, no weight_decay, no LR scaling\n        lr = Config.LEARNING_RATE  # 2e-4\n        \n        if isinstance(model, Simple2D):\n            # Simple2D: single LR, no weight_decay (exact match to Run 1 - best: 0.6279)\n            optimizer = optim.AdamW(model.parameters(), lr=lr)\n        elif isinstance(model, RSNA2p5D):\n            # RSNA2p5D: keep parameter groups for backward compatibility\n            optimizer = optim.AdamW([\n                {'params': model.mixer.parameters(), 'lr': lr},\n                {'params': model.head.parameters(), 'lr': lr},\n                {'params': model.backbone.parameters(), 'lr': lr},\n            ])\n        else:\n            # MIL2p5D: keep parameter groups for backward compatibility\n            optimizer = optim.AdamW([\n                {'params': model.encoder.parameters(), 'lr': lr},\n                {'params': model.proj.parameters(), 'lr': lr},\n                {'params': model.tx.parameters(), 'lr': lr},\n                {'params': model.gate.parameters(), 'lr': lr},\n                {'params': model.head.parameters(), 'lr': lr},\n            ])\n\n        # Optional: 1-epoch freeze warmup for backbone\n        freeze_backbone_for_epoch0 = True\n        # EMA (CPU, float32) to avoid extra VRAM usage\n        use_ema = bool(getattr(Config, 'USE_EMA', True))\n        ema_decay = float(getattr(Config, 'EMA_DECAY', 0.999))\n        ema_state = (\n            {\n                k: v.detach().float().cpu().clone()\n                for k, v in model.state_dict().items()\n                if isinstance(v, torch.Tensor) and torch.is_floating_point(v)\n            }\n            if use_ema else None\n        )\n        \n        # Multi-GPU if available\n        if torch.cuda.device_count() > 1:\n            model = nn.DataParallel(model)\n        \n        # Scheduler: DISABLED to match working 0.69 model (constant LR)\n        # steps_per_epoch = max(1, len(train_loader))\n        # warmup_steps = min(200, steps_per_epoch)\n        # scheduler = SequentialLR(\n        #     optimizer,\n        #     schedulers=[\n        #         LinearLR(optimizer, start_factor=0.1, total_iters=warmup_steps),\n        #         CosineAnnealingLR(optimizer, T_max=Config.EPOCHS * steps_per_epoch)\n        #     ],\n        #     milestones=[warmup_steps]\n        # )\n        scheduler = None  # No scheduler (constant LR)\n\n        # Enable grad checkpointing on encoder/backbone if supported (saves VRAM)\n        core_for_gc = model.module if isinstance(model, nn.DataParallel) else model\n        enc_ref = None\n        if isinstance(core_for_gc, RSNA2p5D):\n            enc_ref = getattr(core_for_gc, 'backbone', None)\n        else:\n            enc_ref = getattr(core_for_gc, 'encoder', None)\n        if enc_ref is not None and hasattr(enc_ref, 'set_grad_checkpointing'):\n            try:\n                enc_ref.set_grad_checkpointing(True)\n            except Exception:\n                pass\n        \n        # Auto-tune micro-batch size once before epoch 1\n        if getattr(Config, 'AUTO_TUNE_MICRO', False):  # DISABLED by default to prevent hanging\n            print(\"[AutoTune] Probing micro-batch size... this may take a few minutes on the first run\", flush=True)\n            try:\n                mb = autotune_micro_batch(model, train_loader, criterion, Config.DEVICE)\n                if mb != Config.MICRO_BATCH_SIZE:\n                    print(f\"[AutoTune] MICRO_BATCH_SIZE {Config.MICRO_BATCH_SIZE} -> {mb}\", flush=True)\n                else:\n                    print(f\"[AutoTune] MICRO_BATCH_SIZE remains {mb}\", flush=True)\n                Config.MICRO_BATCH_SIZE = mb\n            except Exception as e:\n                print(f\"[AutoTune] ERROR: {e}\", flush=True)\n                print(f\"[AutoTune] Using default MICRO_BATCH_SIZE={Config.MICRO_BATCH_SIZE}\", flush=True)\n        else:\n            print(f\"[AutoTune] Skipped (disabled). Using MICRO_BATCH_SIZE={Config.MICRO_BATCH_SIZE}\", flush=True)\n        # Training loop\n        best_auc = 0\n        patience = max(1, int(getattr(Config, 'EARLY_STOPPING_PATIENCE', 2)))\n        no_improve = 0\n        best_full_auc = -1.0\n        full_val_metrics = None\n        \n        for epoch in range(Config.EPOCHS):\n            print(f\"\\nEpoch {epoch+1}/{Config.EPOCHS}\")\n            t0 = time.time()  \n            \n            # GPU utilization tracking\n            gpu_idle_time = 0\n            gpu_active_time = 0\n            last_gpu_check = time.time()\n\n            if freeze_backbone_for_epoch0:\n                # Handle DataParallel and arch differences transparently\n                core = model.module if isinstance(model, nn.DataParallel) else model\n                # Skip freezing for Simple2D (backbone includes classifier, needs all gradients)\n                if isinstance(core, RSNA2p5D):\n                    backbone_ref = core.backbone\n                elif not isinstance(core, Simple2D):\n                    backbone_ref = getattr(core, 'encoder', None)\n                else:\n                    backbone_ref = None\n                if backbone_ref is not None:\n                    if epoch == 0:\n                        for p in backbone_ref.parameters():\n                            p.requires_grad = False\n                    elif epoch == 1:\n                        for p in backbone_ref.parameters():\n                            p.requires_grad = True\n            \n            # Train\n            train_loss = 0.0\n            model.train()\n            grad_accum_steps = getattr(Config, 'GRAD_ACCUM_STEPS', 1)\n            \n            for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n                iter_start = time.time()\n                \n                # Track GPU idle time (time waiting for data)\n                if batch_idx > 0:\n                    data_wait_time = iter_start - last_gpu_check\n                    gpu_idle_time += data_wait_time\n                    \n                images = batch['image'].to(Config.DEVICE, non_blocking=True)\n                labels = batch['labels'].to(Config.DEVICE, non_blocking=True)\n                           \n                # Zero grad only at start of accumulation cycle\n                if batch_idx % grad_accum_steps == 0:\n                    optimizer.zero_grad(set_to_none=True)\n                \n                # Forward pass with gradient accumulation scaling\n                with torch.cuda.amp.autocast(enabled=Config.MIXED_PRECISION):\n                    logits = model(images)\n\n                    # Debug: verify ImageNet normalization on first batch of first epoch\n                    if epoch == 0 and batch_idx == 0:\n                        print(f\"🔍 NORM CHECK - Input to model: range [{images.min():.3f}, {images.max():.3f}], mean {images.float().mean():.3f}\")\n                        # Extract 3 center slices like the model does\n                        center = images.shape[1] // 2\n                        x_3ch = images[:, center-1:center+2, :, :]\n                        # Apply ImageNet normalization (3 channels RGB)\n                        mean = torch.tensor([0.485, 0.456, 0.406], device=images.device).view(1, 3, 1, 1)\n                        std = torch.tensor([0.229, 0.224, 0.225], device=images.device).view(1, 3, 1, 1)\n                        x_norm = (x_3ch.float() - mean) / std\n                        print(f\"🔍 NORM CHECK - After ImageNet norm (3-ch RGB): range [{x_norm.min():.3f}, {x_norm.max():.3f}], mean {x_norm.float().mean():.3f}\")\n                    \n                    primary_loss = compute_primary_loss(logits, labels, criterion)\n                    if getattr(Config, 'ENABLE_HIER_LOSS', False):\n                        hier_pen = compute_hierarchical_penalty(logits)\n                        loss = primary_loss + float(getattr(Config, 'HIER_LOSS_LAMBDA', 0.2)) * hier_pen\n                    else:\n                        loss = primary_loss\n                    \n                    # Scale loss for gradient accumulation\n                    loss = loss / grad_accum_steps\n\n                # Backward pass\n                if Config.MIXED_PRECISION:\n                    scaler.scale(loss).backward()\n                else:\n                    loss.backward()\n\n                # Optimizer step only after accumulating gradients\n                if (batch_idx + 1) % grad_accum_steps == 0:\n                    if Config.MIXED_PRECISION:\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        optimizer.step()\n                    \n                    # Step scheduler per optimizer step (not per batch)\n                    if scheduler is not None:\n                        try:\n                            scheduler.step()\n                        except Exception:\n                            pass\n\n                train_loss += loss.item() * grad_accum_steps  # Unscale for logging\n                \n                # Track GPU active time\n                iter_end = time.time()\n                gpu_active_time += (iter_end - iter_start)\n                last_gpu_check = iter_end\n            train_loss /= max(1, len(train_loader))\n            t_train = time.time() - t0                         \n            \n            # GPU utilization report\n            total_time = gpu_active_time + gpu_idle_time\n            if total_time > 0:\n                gpu_util_pct = (gpu_active_time / total_time) * 100\n                print(f\"⚡ GPU Utilization: {gpu_util_pct:.1f}% | Active: {gpu_active_time/60:.1f}min | Idle: {gpu_idle_time/60:.1f}min\")\n\n            # DEBUG: Check if model is learning\n            print(f\"🔍 DEBUG - Epoch {epoch+1}: Train Loss = {train_loss:.4f}\")\n            \n            # Validation: run either fast or full (not both)\n            current_state = None\n            if use_ema and ema_state is not None:\n                current_state = {k: (v.detach().cpu() if torch.is_tensor(v) else v) for k, v in model.state_dict().items()}\n                try:\n                    model.load_state_dict(ema_state, strict=False)\n                except Exception:\n                    pass\n\n            do_full = False\n            if getattr(Config, 'RUN_FULL_ON_EPOCH_1', False) and (epoch == 0):\n                do_full = True\n            elif (epoch + 1) % int(getattr(Config, 'FULL_VAL_EVERY', 3)) == 0:\n                do_full = True\n\n            # Disable encoder/backbone checkpointing for eval (faster)\n            had_gc = False\n            core_tmp = model.module if isinstance(model, nn.DataParallel) else model\n            enc_tmp = getattr(core_tmp, 'encoder', None)\n            if enc_tmp is None:\n                enc_tmp = getattr(core_tmp, 'backbone', None)\n            if enc_tmp is not None and hasattr(enc_tmp, 'set_grad_checkpointing'):\n                try:\n                    enc_tmp.set_grad_checkpointing(False)\n                    had_gc = True\n                except Exception:\n                    had_gc = False\n\n            if do_full:\n                val_loss, val_auc = _run_validation(\n                    model, val_loader_full, criterion, Config.DEVICE,\n                    max_tokens=int(getattr(Config, 'VAL_MAX_ENCODER_TOKENS', 384))\n                )\n                full_val_metrics = (val_loss, val_auc)\n            else:\n                if val_loader_fast is None:\n                    val_loader_fast = build_fast_val_loader(val_dataset)\n                val_loss, val_auc = _run_validation(\n                    model, val_loader_fast, criterion, Config.DEVICE,\n                    max_tokens=int(getattr(Config, 'FAST_VAL_MAX_TOKENS', 256))\n                )\n\n            # Restore encoder/backbone checkpointing\n            if had_gc and enc_tmp is not None and hasattr(enc_tmp, 'set_grad_checkpointing'):\n                try:\n                    enc_tmp.set_grad_checkpointing(True)\n                except Exception:\n                    pass\n\n            # Restore non-EMA weights\n            if current_state is not None:\n                try:\n                    model.load_state_dict(current_state, strict=False)\n                except Exception:\n                    pass\n\n            t_total = time.time() - t0            \n            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n            print(f\"[Timing] epoch={epoch+1} | train={t_train/60:.2f} min | val_type={'full' if do_full else 'fast'} | epoch_total={t_total/60:.2f} min\")            \n            \n            # Save best model + early stopping (CPU-only tensors). Track best FULL AUC.\n            if (do_full and (val_auc > best_full_auc)) or (not do_full and best_full_auc < 0 and val_auc > best_auc):\n                if do_full:\n                    best_full_auc = val_auc\n                best_auc = val_auc\n                no_improve = 0\n                if use_ema and ema_state is not None:\n                    best_state_cpu = {k: v.detach().cpu().clone() for k, v in ema_state.items()}\n                else:\n                    best_state_cpu = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n                # Architecture-specific model naming\n                if arch == 'simple2d':\n                    arch_name = 'simple2d'\n                elif arch == 'mil2p5d':\n                    arch_name = 'mil'\n                else:\n                    arch_name = 'rsna'\n                model_filename = f'stage2_{arch_name}_fold_{fold}_best.pth'\n                \n                torch.save({\n                    'model_state_dict': best_state_cpu,\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'val_auc': val_auc,\n                    'epoch': epoch,\n                    'fold': fold,\n                    'architecture': arch  # Save architecture type for ensemble loading\n                }, model_filename)\n                print(f\"💾 Saved best model: {model_filename} (AUC: {val_auc:.4f})\")\n            else:\n                no_improve += 1\n                if do_full and no_improve >= patience:\n                    print(f\"⏹️ Early stopping (patience={patience}) at epoch {epoch+1}\")\n                    break\n\n            # EMA update (compute on CPU tensors)\n            if use_ema and ema_state is not None:\n                with torch.no_grad():\n                    for k, v in model.state_dict().items():\n                        if k in ema_state and isinstance(v, torch.Tensor) and torch.is_floating_point(v):\n                            tgt = ema_state[k]\n                            ema_state[k] = tgt.mul(ema_decay).add(\n                                v.detach().float().cpu(),\n                                alpha=(1.0 - ema_decay),\n                            )\n            train_loss /= max(1, len(train_loader))\n            try:\n                torch.cuda.empty_cache()\n            except Exception:\n                pass\n        \n        fold_scores.append(best_auc)\n        print(f\"Fold {fold + 1} best AUC: {best_auc:.4f}\")\n    \n    # Final results\n    mean_cv_score = np.mean(fold_scores)\n    print(f\"\\n✅ Cross-validation complete!\")\n    print(f\"Mean CV AUC: {mean_cv_score:.4f} ± {np.std(fold_scores):.4f}\")\n    print(f\"Individual fold scores: {fold_scores}\")\n\nprint(\"✅ Training pipeline loaded\")\n\n# ====================================================\n# CELL 5: INFERENCE & SUBMISSION\n# ====================================================\n\nclass InferenceConfig:\n    \"\"\"Configuration for inference server\"\"\"\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    ID_COL = 'SeriesInstanceUID'\n    LABEL_COLS = [\n        'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery',\n        'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n        'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Anterior Communicating Artery',\n        'Left Anterior Cerebral Artery', 'Right Anterior Cerebral Artery',\n        'Left Posterior Communicating Artery', 'Right Posterior Communicating Artery',\n        'Basilar Tip', 'Other Posterior Circulation', 'Aneurysm Present',\n    ]\n\n\n# ===============================\n# Inference-time TTA helpers\nNAME_TO_IDX = {name: i for i, name in enumerate(Config.LABEL_COLS)}\nLR_PAIRS = [\n    (\"Left Infraclinoid Internal Carotid Artery\", \"Right Infraclinoid Internal Carotid Artery\"),\n    (\"Left Supraclinoid Internal Carotid Artery\", \"Right Supraclinoid Internal Carotid Artery\"),\n    (\"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\"),\n    (\"Left Anterior Cerebral Artery\", \"Right Anterior Cerebral Artery\"),\n    (\"Left Posterior Communicating Artery\", \"Right Posterior Communicating Artery\"),\n]\nUNI_CLASSES = [\n    \"Anterior Communicating Artery\", \"Basilar Tip\", \"Other Posterior Circulation\", \"Aneurysm Present\"\n]\n\ndef swap_lr_logits(logits: torch.Tensor) -> torch.Tensor:\n    # logits: (B, C)\n    logits = logits.clone()\n    for L, R in LR_PAIRS:\n        li, ri = NAME_TO_IDX[L], NAME_TO_IDX[R]\n        tmp = logits[..., li].clone()\n        logits[..., li] = logits[..., ri]\n        logits[..., ri] = tmp\n    return logits\n\ndef predict_with_tta(models: list, x: torch.Tensor) -> torch.Tensor:\n    # x: (B,32,H,W) in [0,1]\n    x0 = x\n    xH = torch.flip(x, dims=[-1])\n    xV = torch.flip(x, dims=[-2])\n    xR2 = torch.roll(x, shifts=2, dims=[-3])\n    xR_2 = torch.roll(x, shifts=-2, dims=[-3])\n    batch = torch.cat([x0, xH, xV, xR2, xR_2], dim=0).to(device=x.device)\n    logits_models = []\n    amp_enabled = bool(getattr(Config, 'MIXED_PRECISION', True) and x.is_cuda)\n    with torch.no_grad(), torch.cuda.amp.autocast(enabled=amp_enabled):\n        b = x.size(0)\n        for m in models:\n            z = m(batch.to(memory_format=torch.channels_last))  # (5B, C)\n            z = z.view(5, b, -1)                               # (5, B, C)\n            z[1] = swap_lr_logits(z[1])                        # H-flip needs L<->R swap\n            z_mean = z.mean(0)                                 # (B, C)\n            logits_models.append(z_mean)\n    logits = torch.stack(logits_models, dim=0).mean(0)         # (B, C)\n    return torch.sigmoid(logits)\n\n\nclass ModelEnsemble:\n    \"\"\"Ensemble of Stage 2 models for inference\"\"\"\n    def __init__(self, model_paths, device):\n        self.device = device\n        self.models = []\n        \n        for path in model_paths:\n            try:\n                # Detect model type from filename\n                filename = os.path.basename(path).lower()\n                is_mil = 'mil' in filename\n                is_simple2d = 'simple2d' in filename\n                \n                if is_simple2d:\n                    # Simple2D model\n                    model = Simple2D(num_classes=len(Config.LABEL_COLS)).to(device)\n                elif is_mil:\n                    # MIL2p5D model\n                    model = MIL2p5D(num_classes=len(Config.LABEL_COLS)).to(device)\n                else:\n                    # RSNA2p5D model (default)\n                    model = RSNA2p5D().to(device)\n                checkpoint = torch.load(path, map_location=device, weights_only=False)\n                # Robustly extract state dict\n                state_dict = None\n                if isinstance(checkpoint, dict):\n                    for key in ('model', 'model_state_dict', 'state_dict'):\n                        if key in checkpoint and isinstance(checkpoint[key], dict):\n                            state_dict = checkpoint[key]\n                            break\n                    if state_dict is None:\n                        # Some checkpoints save raw weights at top-level\n                        if all(isinstance(v, torch.Tensor) for v in checkpoint.values()):\n                            state_dict = checkpoint\n                if state_dict is None:\n                    raise RuntimeError('Unsupported checkpoint format')\n                \n                # Handle DataParallel wrapper\n                if any(key.startswith('module.') for key in state_dict.keys()):\n                    state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n                # Strict load first; if it fails, relax\n                try:\n                    model.load_state_dict(state_dict, strict=True)\n                except Exception:\n                    model.load_state_dict(state_dict, strict=False)\n                model.eval()\n                try:\n                    model = model.to(memory_format=torch.channels_last)\n                except Exception:\n                    pass\n                self.models.append(model)\n                print(f\"Loaded model: {path}\")\n            except Exception as e:\n                print(f\"Error loading {path}: {e}\")\n        \n        print(f\"Loaded {len(self.models)} models for ensemble\")\n    \n    def predict_single(self, series_path):\n        \"\"\"Predict by building a 32x384x384 volume directly from DICOMs using shared preprocessor.\"\"\"\n        vol = process_dicom_series_safe(series_path, target_shape=(32,384,384))\n        x = torch.from_numpy(vol).unsqueeze(0)  # [1,32,384,384]\n        # Ensure dtype matches FP32 weights; AMP will downcast compute where safe\n        x = x.to(device=self.device, dtype=torch.float32, non_blocking=True)\n        try:\n            x = x.to(memory_format=torch.channels_last)\n        except Exception:\n            pass\n        # Vectorized TTA across models (logit averaging with L<->R swap for H-flip)\n        probs = predict_with_tta(self.models, x).cpu().numpy()[0]\n        return probs\n\nclass InferenceDICOMProcessor:\n    \"\"\"DICOM processor for inference\"\"\"\n    def __init__(self):\n        pass\n\n# Global variables for model ensemble\nmodel_ensemble = None\nprocessor = None\n\ndef initialize_models():\n    \"\"\"Initialize models - called once at startup\"\"\"\n    global model_ensemble, processor\n    \n    print(\"Initializing models...\")\n    \n    # Restrict candidates to provided MODEL_DIRS only\n    # Support both old and new naming conventions\n    candidate_names = [\n        # New naming (architecture-specific)\n        'stage2_simple2d_fold_0_best.pth', 'stage2_simple2d_fold_1_best.pth',\n        'stage2_simple2d_fold_2_best.pth', 'stage2_simple2d_fold_3_best.pth',\n        'stage2_simple2d_fold_4_best.pth',\n        'stage2_rsna_fold_0_best.pth', 'stage2_rsna_fold_1_best.pth',\n        'stage2_rsna_fold_2_best.pth', 'stage2_rsna_fold_3_best.pth',\n        'stage2_rsna_fold_4_best.pth',\n        'stage2_mil_fold_0_best.pth', 'stage2_mil_fold_1_best.pth',\n        'stage2_mil_fold_2_best.pth', 'stage2_mil_fold_3_best.pth',\n        'stage2_mil_fold_4_best.pth',\n        # Legacy naming (for backward compatibility)\n        'stage2_fold_0_best.pth', 'stage2_fold_1_best.pth',\n        'stage2_fold_2_best.pth', 'stage2_fold_3_best.pth',\n        'stage2_fold_4_best.pth',\n    ]\n    available_models = []\n    for d in getattr(Config, 'MODEL_DIRS', []):\n        if not isinstance(d, str) or not len(d):\n            continue\n        for name in candidate_names:\n            p = os.path.join(d, name)\n            if os.path.exists(p):\n                available_models.append(p)\n    \n    if not available_models:\n        print(\"Warning: No trained models found! Using dummy predictions.\")\n        model_ensemble = None\n    else:\n        try:\n            model_ensemble = ModelEnsemble(available_models, InferenceConfig.DEVICE)\n            print(\"Models initialized successfully!\")\n        except Exception as e:\n            print(f\"Error initializing models: {e}\")\n            model_ensemble = None\n    \n    processor = InferenceDICOMProcessor()\n\ndef predict(series_path: str) -> pl.DataFrame:\n    \"\"\"Make predictions for the competition API\"\"\"\n    global model_ensemble, processor\n    \n    # Initialize models on first call (lazy loading)\n    if model_ensemble is None and processor is None:\n        initialize_models()\n    \n    series_id = os.path.basename(series_path)\n    \n    try:\n        if model_ensemble is not None:\n            # Use trained ensemble\n            predictions = model_ensemble.predict_single(series_path)\n        else:\n            # Fallback: extract metadata and make informed dummy predictions\n            print(f\"Using fallback prediction for {series_id}\")\n            \n            # Load DICOM metadata\n            all_filepaths = []\n            for root, _, files in os.walk(series_path):\n                for file in files:\n                    if file.endswith('.dcm'):\n                        all_filepaths.append(os.path.join(root, file))\n            \n            if all_filepaths:\n                ds = pydicom.dcmread(all_filepaths[0], force=True)\n                modality = getattr(ds, 'Modality', 'UNKNOWN')\n                \n                # Slightly better informed predictions based on modality\n                if modality in ['CTA', 'MRA']:\n                    # Vascular imaging - slightly higher probability\n                    base_prob = 0.1\n                else:\n                    # Other modalities - lower baseline\n                    base_prob = 0.05\n                \n                # Add some noise to make predictions more realistic\n                predictions = np.random.normal(base_prob, 0.02, len(InferenceConfig.LABEL_COLS))\n                predictions = np.clip(predictions, 0.001, 0.999)\n            else:\n                # No DICOM files found\n                predictions = np.full(len(InferenceConfig.LABEL_COLS), 0.5)\n\n        # Ensure predictions is numpy array and convert to list safely\n        if not isinstance(predictions, np.ndarray):\n            predictions = np.array(predictions)\n        \n        # Create prediction DataFrame\n        prediction_df = pl.DataFrame(\n            data=[[series_id] + predictions.tolist()],\n            schema=[InferenceConfig.ID_COL, *InferenceConfig.LABEL_COLS],\n            orient='row',\n        )\n        \n    except Exception as e:\n        print(f\"Error processing {series_id}: {e}\")\n        # Return safe default predictions\n        prediction_df = pl.DataFrame(\n            data=[[series_id] + [0.5] * len(InferenceConfig.LABEL_COLS)],\n            schema=[InferenceConfig.ID_COL, *InferenceConfig.LABEL_COLS],\n            orient='row',\n        )\n    \n    # IMPORTANT: Remove SeriesInstanceUID before returning (API requirement)\n    prediction_df = prediction_df.drop(InferenceConfig.ID_COL)\n    \n    # IMPORTANT: Disk cleanup to prevent \"out of disk space\" errors\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n    \n    return prediction_df\n\n\n# ====================================================\n# SERVER EXECUTION\n# ====================================================\n\n# Initialize the inference server\ninference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nprint(\"✅ Inference and submission pipeline loaded\")\n\n# ====================================================\n# CELL 6: MAIN EXECUTION\n# ====================================================\n\nif __name__ == \"__main__\":\n    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n        # Production mode - serve the API\n        print(\"Starting inference server...\")\n        inference_server.serve()\n    else:\n        # Local/dev mode - default to inference only unless explicitly enabled\n        print(\"Ready for Stage 2 training!\")\n        print(\"Set Config.TRAIN_ON_START=True to run training.\")\n        if getattr(Config, 'TRAIN_ON_START', False):\n            main_training()\n        \n        # Or run local testing\n        print(\"Running local gateway for testing...\")\n        inference_server.run_local_gateway()\n        \n        # Display results if available + sanity checks + CSV\n        results_path = '/kaggle/working/submission.parquet'\n        if os.path.exists(results_path):\n            results_df = pl.read_parquet(results_path)\n\n            # GO / NO-GO checks\n            import pandas as pd\n            pdf = results_df.to_pandas()\n            expected_label_cols = list(Config.LABEL_COLS)\n            id_col = getattr(Config, 'ID_COL', 'SeriesInstanceUID')\n            if id_col in pdf.columns:\n                expected_cols = [id_col] + expected_label_cols\n                # Reorder to expected order if needed\n                pdf = pdf[expected_cols]\n            else:\n                expected_cols = expected_label_cols\n            assert list(pdf.columns) == expected_cols, (\n                f\"Column mismatch.\\nExpected ({len(expected_cols)}): {expected_cols}\\n\"\n                f\"Got ({len(pdf.columns)}): {list(pdf.columns)}\"\n            )\n            # Validate only label columns for NaNs and range\n            label_pdf = pdf[expected_label_cols]\n            assert not label_pdf.isna().any().any(), \"Submission contains NaNs.\"\n            vmin, vmax = label_pdf.to_numpy().min(), label_pdf.to_numpy().max()\n            assert 0.0 <= vmin <= 1.0 and 0.0 <= vmax <= 1.0, (\n                f\"Out-of-range probabilities: min={vmin}, max={vmax}\"\n            )\n            test_meta = '/kaggle/working/test_series.parquet'\n            if os.path.exists(test_meta):\n                test_n = int(pl.read_parquet(test_meta).height)\n                assert len(pdf) == test_n, f\"Row count mismatch: got {len(pdf)}, expected {test_n}\"\n\n            print(\"Submission preview:\")\n            print(results_df.head())\n            out_csv = '/kaggle/working/submission.csv'\n            pdf.to_csv(out_csv, index=False)\n            print(f\"💾 Saved: {out_csv}\")\n        else:\n            print(\"⚠️ submission.parquet not found. Did inference write it?\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}